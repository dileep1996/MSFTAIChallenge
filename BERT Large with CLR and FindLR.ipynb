{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disks/extra\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/disks/extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://competitions.codalab.org/my/datasets/download/69a3e8d0-b836-48b8-8795-36a6865a1c04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mv 69a3e8d0-b836-48b8-8795-36a6865a1c04 data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install zipfile36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir msaic\n",
    "#!mv data.zip msaic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disks/extra/msaic\n"
     ]
    }
   ],
   "source": [
    "%cd msaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport zipfile\\nzipref = zipfile.ZipFile('data.zip', 'r')\\nzipref.extractall()\\nzipref.close()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import zipfile\n",
    "zipref = zipfile.ZipFile('data.zip', 'r')\n",
    "zipref.extractall()\n",
    "zipref.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"data.tsv\", sep= '\\t',header=None)\n",
    "#df.columns = ['index','Question', 'Sentence', 'Label','seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrow_list = []\\nfor i in tqdm(range(0,len(df)//5, 10), total = len(df)//50, position = 0):\\n  slice = df.iloc[i:i+10]\\n  row = []\\n  row.append(list(slice['index'])[0])\\n  row.append(list(slice['Question'])[0])\\n  if len(slice[slice.Label == 1]['seq']) == 0:\\n    continue\\n  row.append(list(slice[slice.Label == 1]['seq'])[0])\\n  row += list(slice['Sentence'])\\n  row_list.append(row)\\n  \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "row_list = []\n",
    "for i in tqdm(range(0,len(df)//5, 10), total = len(df)//50, position = 0):\n",
    "  slice = df.iloc[i:i+10]\n",
    "  row = []\n",
    "  row.append(list(slice['index'])[0])\n",
    "  row.append(list(slice['Question'])[0])\n",
    "  if len(slice[slice.Label == 1]['seq']) == 0:\n",
    "    continue\n",
    "  row.append(list(slice[slice.Label == 1]['seq'])[0])\n",
    "  row += list(slice['Sentence'])\n",
    "  row_list.append(row)\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rowdf = pd.DataFrame(row_list, columns = ['qid', 'question', 'label', '0','1','2','3','4','5','6','7','8','9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rowdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rowdf.to_csv('cleaned_data.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowdf = pd.read_csv('cleaned_data.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>. what is a corporation?</td>\n",
       "      <td>5</td>\n",
       "      <td>A company is incorporated in a specific nation...</td>\n",
       "      <td>Today, there is a growing community of more th...</td>\n",
       "      <td>Corporation definition, an association of indi...</td>\n",
       "      <td>Examples of corporation in a Sentence. 1  He w...</td>\n",
       "      <td>1: a government-owned corporation (as a utilit...</td>\n",
       "      <td>McDonald's Corporation is one of the most reco...</td>\n",
       "      <td>Corporations are owned by their stockholders (...</td>\n",
       "      <td>An Association is an organized group of people...</td>\n",
       "      <td>B Corp certification shines a light on the com...</td>\n",
       "      <td>LLCs offer greater flexibility when it comes t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>226969</td>\n",
       "      <td>symptoms of a dying mouse</td>\n",
       "      <td>5</td>\n",
       "      <td>This can be fatal quite quickly to mice. 1  It...</td>\n",
       "      <td>The symptoms of mites include: 1  excessive sc...</td>\n",
       "      <td>Symptoms of Dog and Cat Poisoning. The symptom...</td>\n",
       "      <td>The symptoms of mites include: excessive scrat...</td>\n",
       "      <td>Seizures and neurologic symptoms are caused by...</td>\n",
       "      <td>The symptoms are similar but the mouse will be...</td>\n",
       "      <td>The symptoms are similar but the mouse will be...</td>\n",
       "      <td>Depending on the poison ingested, a poisoned d...</td>\n",
       "      <td>Some plants also cause neurologic symptoms, in...</td>\n",
       "      <td>She described symptoms caused by permethrin: d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18122</td>\n",
       "      <td>average number of lightning strikes per day</td>\n",
       "      <td>5</td>\n",
       "      <td>Lightning is a major cause of storm related de...</td>\n",
       "      <td>Quick Answer. Lightning strikes reach the grou...</td>\n",
       "      <td>An average lightning strike discharges about 3...</td>\n",
       "      <td>Lightning fatalities in the U.S.: A map of tot...</td>\n",
       "      <td>Lightning is a sudden high-voltage discharge o...</td>\n",
       "      <td>Although many lightning flashes are simply clo...</td>\n",
       "      <td>According to the NWS Storm Data, over the last...</td>\n",
       "      <td>Approximately 300,000 lightning strikes hit th...</td>\n",
       "      <td>Florida is also the state with the highest num...</td>\n",
       "      <td>There is estimated to be around 2,000 lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35300</td>\n",
       "      <td>can you burn your lawn with fertilizer</td>\n",
       "      <td>8</td>\n",
       "      <td>Verify the reason for the lawn burn. Grass wil...</td>\n",
       "      <td>These spots are generally caused by a buildup ...</td>\n",
       "      <td>Position the sprinkler over the portion of ove...</td>\n",
       "      <td>When fertilizing start with a dry lawn. Using ...</td>\n",
       "      <td>Fertilizing Tips. Watering and mowing alone wi...</td>\n",
       "      <td>A yellow burned lawn is an eye sore that can o...</td>\n",
       "      <td>Grass1950, the amount of fertilizer you would ...</td>\n",
       "      <td>Rake up the dead grass blades in the fertilize...</td>\n",
       "      <td>Fertilizer burn is the result of over fertiliz...</td>\n",
       "      <td>Preventing Fertilizer Burn. The good news is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90447</td>\n",
       "      <td>goch meaning</td>\n",
       "      <td>1</td>\n",
       "      <td>See the Goch surname, family crest &amp; coat of a...</td>\n",
       "      <td>The name Goch is derived from the Welsh word c...</td>\n",
       "      <td>The name Goch is derived from the Welsh word c...</td>\n",
       "      <td>This Slang page is designed to explain what th...</td>\n",
       "      <td>Goch Spelling Variations. Compared to other an...</td>\n",
       "      <td>Link to this slang definition To link to this ...</td>\n",
       "      <td>© 1999-2018 Urban Dictionary ® advertise terms...</td>\n",
       "      <td>The Goch Family Crest was acquired from the Ho...</td>\n",
       "      <td>Link to this slang definition. To link to this...</td>\n",
       "      <td>Link to this slang definition. To link to this...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      qid                                     question  label  \\\n",
       "0     131                     . what is a corporation?      5   \n",
       "1  226969                    symptoms of a dying mouse      5   \n",
       "2   18122  average number of lightning strikes per day      5   \n",
       "3   35300       can you burn your lawn with fertilizer      8   \n",
       "4   90447                                 goch meaning      1   \n",
       "\n",
       "                                                   0  \\\n",
       "0  A company is incorporated in a specific nation...   \n",
       "1  This can be fatal quite quickly to mice. 1  It...   \n",
       "2  Lightning is a major cause of storm related de...   \n",
       "3  Verify the reason for the lawn burn. Grass wil...   \n",
       "4  See the Goch surname, family crest & coat of a...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  Today, there is a growing community of more th...   \n",
       "1  The symptoms of mites include: 1  excessive sc...   \n",
       "2  Quick Answer. Lightning strikes reach the grou...   \n",
       "3  These spots are generally caused by a buildup ...   \n",
       "4  The name Goch is derived from the Welsh word c...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  Corporation definition, an association of indi...   \n",
       "1  Symptoms of Dog and Cat Poisoning. The symptom...   \n",
       "2  An average lightning strike discharges about 3...   \n",
       "3  Position the sprinkler over the portion of ove...   \n",
       "4  The name Goch is derived from the Welsh word c...   \n",
       "\n",
       "                                                   3  \\\n",
       "0  Examples of corporation in a Sentence. 1  He w...   \n",
       "1  The symptoms of mites include: excessive scrat...   \n",
       "2  Lightning fatalities in the U.S.: A map of tot...   \n",
       "3  When fertilizing start with a dry lawn. Using ...   \n",
       "4  This Slang page is designed to explain what th...   \n",
       "\n",
       "                                                   4  \\\n",
       "0  1: a government-owned corporation (as a utilit...   \n",
       "1  Seizures and neurologic symptoms are caused by...   \n",
       "2  Lightning is a sudden high-voltage discharge o...   \n",
       "3  Fertilizing Tips. Watering and mowing alone wi...   \n",
       "4  Goch Spelling Variations. Compared to other an...   \n",
       "\n",
       "                                                   5  \\\n",
       "0  McDonald's Corporation is one of the most reco...   \n",
       "1  The symptoms are similar but the mouse will be...   \n",
       "2  Although many lightning flashes are simply clo...   \n",
       "3  A yellow burned lawn is an eye sore that can o...   \n",
       "4  Link to this slang definition To link to this ...   \n",
       "\n",
       "                                                   6  \\\n",
       "0  Corporations are owned by their stockholders (...   \n",
       "1  The symptoms are similar but the mouse will be...   \n",
       "2  According to the NWS Storm Data, over the last...   \n",
       "3  Grass1950, the amount of fertilizer you would ...   \n",
       "4  © 1999-2018 Urban Dictionary ® advertise terms...   \n",
       "\n",
       "                                                   7  \\\n",
       "0  An Association is an organized group of people...   \n",
       "1  Depending on the poison ingested, a poisoned d...   \n",
       "2  Approximately 300,000 lightning strikes hit th...   \n",
       "3  Rake up the dead grass blades in the fertilize...   \n",
       "4  The Goch Family Crest was acquired from the Ho...   \n",
       "\n",
       "                                                   8  \\\n",
       "0  B Corp certification shines a light on the com...   \n",
       "1  Some plants also cause neurologic symptoms, in...   \n",
       "2  Florida is also the state with the highest num...   \n",
       "3  Fertilizer burn is the result of over fertiliz...   \n",
       "4  Link to this slang definition. To link to this...   \n",
       "\n",
       "                                                   9  \n",
       "0  LLCs offer greater flexibility when it comes t...  \n",
       "1  She described symptoms caused by permethrin: d...  \n",
       "2  There is estimated to be around 2,000 lightnin...  \n",
       "3  Preventing Fertilizer Burn. The good news is t...  \n",
       "4  Link to this slang definition. To link to this...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_choices = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(rowdf)) < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96382"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = rowdf[msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_answers(row):\n",
    "  label = row[0]\n",
    "  numbers = list(range(0, label)) + list(range(label+1, 10))\n",
    "  items = random.sample(numbers, num_choices-1)\n",
    "  items.append(label)\n",
    "  items.sort()\n",
    "  label = items.index(label)\n",
    "  answers = [row[item+1] for item in items]\n",
    "  return [label]+answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>226969</td>\n",
       "      <td>symptoms of a dying mouse</td>\n",
       "      <td>5</td>\n",
       "      <td>This can be fatal quite quickly to mice. 1  It...</td>\n",
       "      <td>The symptoms of mites include: 1  excessive sc...</td>\n",
       "      <td>Symptoms of Dog and Cat Poisoning. The symptom...</td>\n",
       "      <td>The symptoms of mites include: excessive scrat...</td>\n",
       "      <td>Seizures and neurologic symptoms are caused by...</td>\n",
       "      <td>The symptoms are similar but the mouse will be...</td>\n",
       "      <td>The symptoms are similar but the mouse will be...</td>\n",
       "      <td>Depending on the poison ingested, a poisoned d...</td>\n",
       "      <td>Some plants also cause neurologic symptoms, in...</td>\n",
       "      <td>She described symptoms caused by permethrin: d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18122</td>\n",
       "      <td>average number of lightning strikes per day</td>\n",
       "      <td>5</td>\n",
       "      <td>Lightning is a major cause of storm related de...</td>\n",
       "      <td>Quick Answer. Lightning strikes reach the grou...</td>\n",
       "      <td>An average lightning strike discharges about 3...</td>\n",
       "      <td>Lightning fatalities in the U.S.: A map of tot...</td>\n",
       "      <td>Lightning is a sudden high-voltage discharge o...</td>\n",
       "      <td>Although many lightning flashes are simply clo...</td>\n",
       "      <td>According to the NWS Storm Data, over the last...</td>\n",
       "      <td>Approximately 300,000 lightning strikes hit th...</td>\n",
       "      <td>Florida is also the state with the highest num...</td>\n",
       "      <td>There is estimated to be around 2,000 lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35300</td>\n",
       "      <td>can you burn your lawn with fertilizer</td>\n",
       "      <td>8</td>\n",
       "      <td>Verify the reason for the lawn burn. Grass wil...</td>\n",
       "      <td>These spots are generally caused by a buildup ...</td>\n",
       "      <td>Position the sprinkler over the portion of ove...</td>\n",
       "      <td>When fertilizing start with a dry lawn. Using ...</td>\n",
       "      <td>Fertilizing Tips. Watering and mowing alone wi...</td>\n",
       "      <td>A yellow burned lawn is an eye sore that can o...</td>\n",
       "      <td>Grass1950, the amount of fertilizer you would ...</td>\n",
       "      <td>Rake up the dead grass blades in the fertilize...</td>\n",
       "      <td>Fertilizer burn is the result of over fertiliz...</td>\n",
       "      <td>Preventing Fertilizer Burn. The good news is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90447</td>\n",
       "      <td>goch meaning</td>\n",
       "      <td>1</td>\n",
       "      <td>See the Goch surname, family crest &amp; coat of a...</td>\n",
       "      <td>The name Goch is derived from the Welsh word c...</td>\n",
       "      <td>The name Goch is derived from the Welsh word c...</td>\n",
       "      <td>This Slang page is designed to explain what th...</td>\n",
       "      <td>Goch Spelling Variations. Compared to other an...</td>\n",
       "      <td>Link to this slang definition To link to this ...</td>\n",
       "      <td>© 1999-2018 Urban Dictionary ® advertise terms...</td>\n",
       "      <td>The Goch Family Crest was acquired from the Ho...</td>\n",
       "      <td>Link to this slang definition. To link to this...</td>\n",
       "      <td>Link to this slang definition. To link to this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>226977</td>\n",
       "      <td>symptoms of a gastric ulcer in women</td>\n",
       "      <td>8</td>\n",
       "      <td>Pain from a gastric ulcer may occur shortly af...</td>\n",
       "      <td>Here are ten very evident signs that you may b...</td>\n",
       "      <td>Stomach Ulcers in Women – Gender Specific Diff...</td>\n",
       "      <td>The signs and symptoms of a gastric ulcer are ...</td>\n",
       "      <td>Peptic ulcers, or peptic ulcer disease (PUD) i...</td>\n",
       "      <td>Because of the risk associated with peptic ulc...</td>\n",
       "      <td>Peptic ulcer disease is characterized by sores...</td>\n",
       "      <td>Pain from a stomach ulcer can travel, radiatin...</td>\n",
       "      <td>Symptoms Of Stomach Ulcer In Women. stomach ul...</td>\n",
       "      <td>Besides pain, ulcers in women may sometimes sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      qid                                     question  label  \\\n",
       "1  226969                    symptoms of a dying mouse      5   \n",
       "2   18122  average number of lightning strikes per day      5   \n",
       "3   35300       can you burn your lawn with fertilizer      8   \n",
       "4   90447                                 goch meaning      1   \n",
       "5  226977         symptoms of a gastric ulcer in women      8   \n",
       "\n",
       "                                                   0  \\\n",
       "1  This can be fatal quite quickly to mice. 1  It...   \n",
       "2  Lightning is a major cause of storm related de...   \n",
       "3  Verify the reason for the lawn burn. Grass wil...   \n",
       "4  See the Goch surname, family crest & coat of a...   \n",
       "5  Pain from a gastric ulcer may occur shortly af...   \n",
       "\n",
       "                                                   1  \\\n",
       "1  The symptoms of mites include: 1  excessive sc...   \n",
       "2  Quick Answer. Lightning strikes reach the grou...   \n",
       "3  These spots are generally caused by a buildup ...   \n",
       "4  The name Goch is derived from the Welsh word c...   \n",
       "5  Here are ten very evident signs that you may b...   \n",
       "\n",
       "                                                   2  \\\n",
       "1  Symptoms of Dog and Cat Poisoning. The symptom...   \n",
       "2  An average lightning strike discharges about 3...   \n",
       "3  Position the sprinkler over the portion of ove...   \n",
       "4  The name Goch is derived from the Welsh word c...   \n",
       "5  Stomach Ulcers in Women – Gender Specific Diff...   \n",
       "\n",
       "                                                   3  \\\n",
       "1  The symptoms of mites include: excessive scrat...   \n",
       "2  Lightning fatalities in the U.S.: A map of tot...   \n",
       "3  When fertilizing start with a dry lawn. Using ...   \n",
       "4  This Slang page is designed to explain what th...   \n",
       "5  The signs and symptoms of a gastric ulcer are ...   \n",
       "\n",
       "                                                   4  \\\n",
       "1  Seizures and neurologic symptoms are caused by...   \n",
       "2  Lightning is a sudden high-voltage discharge o...   \n",
       "3  Fertilizing Tips. Watering and mowing alone wi...   \n",
       "4  Goch Spelling Variations. Compared to other an...   \n",
       "5  Peptic ulcers, or peptic ulcer disease (PUD) i...   \n",
       "\n",
       "                                                   5  \\\n",
       "1  The symptoms are similar but the mouse will be...   \n",
       "2  Although many lightning flashes are simply clo...   \n",
       "3  A yellow burned lawn is an eye sore that can o...   \n",
       "4  Link to this slang definition To link to this ...   \n",
       "5  Because of the risk associated with peptic ulc...   \n",
       "\n",
       "                                                   6  \\\n",
       "1  The symptoms are similar but the mouse will be...   \n",
       "2  According to the NWS Storm Data, over the last...   \n",
       "3  Grass1950, the amount of fertilizer you would ...   \n",
       "4  © 1999-2018 Urban Dictionary ® advertise terms...   \n",
       "5  Peptic ulcer disease is characterized by sores...   \n",
       "\n",
       "                                                   7  \\\n",
       "1  Depending on the poison ingested, a poisoned d...   \n",
       "2  Approximately 300,000 lightning strikes hit th...   \n",
       "3  Rake up the dead grass blades in the fertilize...   \n",
       "4  The Goch Family Crest was acquired from the Ho...   \n",
       "5  Pain from a stomach ulcer can travel, radiatin...   \n",
       "\n",
       "                                                   8  \\\n",
       "1  Some plants also cause neurologic symptoms, in...   \n",
       "2  Florida is also the state with the highest num...   \n",
       "3  Fertilizer burn is the result of over fertiliz...   \n",
       "4  Link to this slang definition. To link to this...   \n",
       "5  Symptoms Of Stomach Ulcer In Women. stomach ul...   \n",
       "\n",
       "                                                   9  \n",
       "1  She described symptoms caused by permethrin: d...  \n",
       "2  There is estimated to be around 2,000 lightnin...  \n",
       "3  Preventing Fertilizer Burn. The good news is t...  \n",
       "4  Link to this slang definition. To link to this...  \n",
       "5  Besides pain, ulcers in women may sometimes sh...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_choices < 10:\n",
    "    row_list = []\n",
    "    for _, row in tot.iterrows():\n",
    "      nrow = []\n",
    "      nrow.append(row[0])\n",
    "      nrow.append(row[1])\n",
    "      nrow += sample_answers(row[2:])\n",
    "      row_list.append(nrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_choices < 10:\n",
    "    sampled_df = pd.DataFrame(row_list)\n",
    "else:\n",
    "    sampled_df = pd.DataFrame(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>226969</td>\n",
       "      <td>symptoms of a dying mouse</td>\n",
       "      <td>5</td>\n",
       "      <td>This can be fatal quite quickly to mice. 1  It...</td>\n",
       "      <td>The symptoms of mites include: 1  excessive sc...</td>\n",
       "      <td>Symptoms of Dog and Cat Poisoning. The symptom...</td>\n",
       "      <td>The symptoms of mites include: excessive scrat...</td>\n",
       "      <td>Seizures and neurologic symptoms are caused by...</td>\n",
       "      <td>The symptoms are similar but the mouse will be...</td>\n",
       "      <td>The symptoms are similar but the mouse will be...</td>\n",
       "      <td>Depending on the poison ingested, a poisoned d...</td>\n",
       "      <td>Some plants also cause neurologic symptoms, in...</td>\n",
       "      <td>She described symptoms caused by permethrin: d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18122</td>\n",
       "      <td>average number of lightning strikes per day</td>\n",
       "      <td>5</td>\n",
       "      <td>Lightning is a major cause of storm related de...</td>\n",
       "      <td>Quick Answer. Lightning strikes reach the grou...</td>\n",
       "      <td>An average lightning strike discharges about 3...</td>\n",
       "      <td>Lightning fatalities in the U.S.: A map of tot...</td>\n",
       "      <td>Lightning is a sudden high-voltage discharge o...</td>\n",
       "      <td>Although many lightning flashes are simply clo...</td>\n",
       "      <td>According to the NWS Storm Data, over the last...</td>\n",
       "      <td>Approximately 300,000 lightning strikes hit th...</td>\n",
       "      <td>Florida is also the state with the highest num...</td>\n",
       "      <td>There is estimated to be around 2,000 lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35300</td>\n",
       "      <td>can you burn your lawn with fertilizer</td>\n",
       "      <td>8</td>\n",
       "      <td>Verify the reason for the lawn burn. Grass wil...</td>\n",
       "      <td>These spots are generally caused by a buildup ...</td>\n",
       "      <td>Position the sprinkler over the portion of ove...</td>\n",
       "      <td>When fertilizing start with a dry lawn. Using ...</td>\n",
       "      <td>Fertilizing Tips. Watering and mowing alone wi...</td>\n",
       "      <td>A yellow burned lawn is an eye sore that can o...</td>\n",
       "      <td>Grass1950, the amount of fertilizer you would ...</td>\n",
       "      <td>Rake up the dead grass blades in the fertilize...</td>\n",
       "      <td>Fertilizer burn is the result of over fertiliz...</td>\n",
       "      <td>Preventing Fertilizer Burn. The good news is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90447</td>\n",
       "      <td>goch meaning</td>\n",
       "      <td>1</td>\n",
       "      <td>See the Goch surname, family crest &amp; coat of a...</td>\n",
       "      <td>The name Goch is derived from the Welsh word c...</td>\n",
       "      <td>The name Goch is derived from the Welsh word c...</td>\n",
       "      <td>This Slang page is designed to explain what th...</td>\n",
       "      <td>Goch Spelling Variations. Compared to other an...</td>\n",
       "      <td>Link to this slang definition To link to this ...</td>\n",
       "      <td>© 1999-2018 Urban Dictionary ® advertise terms...</td>\n",
       "      <td>The Goch Family Crest was acquired from the Ho...</td>\n",
       "      <td>Link to this slang definition. To link to this...</td>\n",
       "      <td>Link to this slang definition. To link to this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>226977</td>\n",
       "      <td>symptoms of a gastric ulcer in women</td>\n",
       "      <td>8</td>\n",
       "      <td>Pain from a gastric ulcer may occur shortly af...</td>\n",
       "      <td>Here are ten very evident signs that you may b...</td>\n",
       "      <td>Stomach Ulcers in Women – Gender Specific Diff...</td>\n",
       "      <td>The signs and symptoms of a gastric ulcer are ...</td>\n",
       "      <td>Peptic ulcers, or peptic ulcer disease (PUD) i...</td>\n",
       "      <td>Because of the risk associated with peptic ulc...</td>\n",
       "      <td>Peptic ulcer disease is characterized by sores...</td>\n",
       "      <td>Pain from a stomach ulcer can travel, radiatin...</td>\n",
       "      <td>Symptoms Of Stomach Ulcer In Women. stomach ul...</td>\n",
       "      <td>Besides pain, ulcers in women may sometimes sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      qid                                     question  label  \\\n",
       "1  226969                    symptoms of a dying mouse      5   \n",
       "2   18122  average number of lightning strikes per day      5   \n",
       "3   35300       can you burn your lawn with fertilizer      8   \n",
       "4   90447                                 goch meaning      1   \n",
       "5  226977         symptoms of a gastric ulcer in women      8   \n",
       "\n",
       "                                                   0  \\\n",
       "1  This can be fatal quite quickly to mice. 1  It...   \n",
       "2  Lightning is a major cause of storm related de...   \n",
       "3  Verify the reason for the lawn burn. Grass wil...   \n",
       "4  See the Goch surname, family crest & coat of a...   \n",
       "5  Pain from a gastric ulcer may occur shortly af...   \n",
       "\n",
       "                                                   1  \\\n",
       "1  The symptoms of mites include: 1  excessive sc...   \n",
       "2  Quick Answer. Lightning strikes reach the grou...   \n",
       "3  These spots are generally caused by a buildup ...   \n",
       "4  The name Goch is derived from the Welsh word c...   \n",
       "5  Here are ten very evident signs that you may b...   \n",
       "\n",
       "                                                   2  \\\n",
       "1  Symptoms of Dog and Cat Poisoning. The symptom...   \n",
       "2  An average lightning strike discharges about 3...   \n",
       "3  Position the sprinkler over the portion of ove...   \n",
       "4  The name Goch is derived from the Welsh word c...   \n",
       "5  Stomach Ulcers in Women – Gender Specific Diff...   \n",
       "\n",
       "                                                   3  \\\n",
       "1  The symptoms of mites include: excessive scrat...   \n",
       "2  Lightning fatalities in the U.S.: A map of tot...   \n",
       "3  When fertilizing start with a dry lawn. Using ...   \n",
       "4  This Slang page is designed to explain what th...   \n",
       "5  The signs and symptoms of a gastric ulcer are ...   \n",
       "\n",
       "                                                   4  \\\n",
       "1  Seizures and neurologic symptoms are caused by...   \n",
       "2  Lightning is a sudden high-voltage discharge o...   \n",
       "3  Fertilizing Tips. Watering and mowing alone wi...   \n",
       "4  Goch Spelling Variations. Compared to other an...   \n",
       "5  Peptic ulcers, or peptic ulcer disease (PUD) i...   \n",
       "\n",
       "                                                   5  \\\n",
       "1  The symptoms are similar but the mouse will be...   \n",
       "2  Although many lightning flashes are simply clo...   \n",
       "3  A yellow burned lawn is an eye sore that can o...   \n",
       "4  Link to this slang definition To link to this ...   \n",
       "5  Because of the risk associated with peptic ulc...   \n",
       "\n",
       "                                                   6  \\\n",
       "1  The symptoms are similar but the mouse will be...   \n",
       "2  According to the NWS Storm Data, over the last...   \n",
       "3  Grass1950, the amount of fertilizer you would ...   \n",
       "4  © 1999-2018 Urban Dictionary ® advertise terms...   \n",
       "5  Peptic ulcer disease is characterized by sores...   \n",
       "\n",
       "                                                   7  \\\n",
       "1  Depending on the poison ingested, a poisoned d...   \n",
       "2  Approximately 300,000 lightning strikes hit th...   \n",
       "3  Rake up the dead grass blades in the fertilize...   \n",
       "4  The Goch Family Crest was acquired from the Ho...   \n",
       "5  Pain from a stomach ulcer can travel, radiatin...   \n",
       "\n",
       "                                                   8  \\\n",
       "1  Some plants also cause neurologic symptoms, in...   \n",
       "2  Florida is also the state with the highest num...   \n",
       "3  Fertilizer burn is the result of over fertiliz...   \n",
       "4  Link to this slang definition. To link to this...   \n",
       "5  Symptoms Of Stomach Ulcer In Women. stomach ul...   \n",
       "\n",
       "                                                   9  \n",
       "1  She described symptoms caused by permethrin: d...  \n",
       "2  There is estimated to be around 2,000 lightnin...  \n",
       "3  Preventing Fertilizer Burn. The good news is t...  \n",
       "4  Link to this slang definition. To link to this...  \n",
       "5  Besides pain, ulcers in women may sometimes sh...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76912"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sampled_df[:5000]\n",
    "dev = sampled_df[5000:7500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/NVIDIA/apex.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%cd apex/\\n!python setup.py install --cuda_ext --cpp_ext\\n%cd ..\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%cd apex/\n",
    "!python setup.py install --cuda_ext --cpp_ext\n",
    "%cd ..\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytorch-pretrained-bert==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertModel, PreTrainedBertModel\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import logging\n",
    "import tarfile\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss, L1Loss\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "loss_fct = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disks/extra\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceClassification(PreTrainedBertModel):\n",
    "    def __init__(self, config, num_labels=2):\n",
    "        super(BertForSequenceClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.fc1 = nn.Linear(config.hidden_size, 100)\n",
    "        self.classifier = nn.Linear(100, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        layer1 = self.dropout(F.relu(self.fc1(pooled_output)))\n",
    "        logits = self.classifier(layer1)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "classification_bert = torch.load(\"bert_large_1to3_79_68_val_acc_1200k_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss2(reshaped_logits, labels,lf):\n",
    "    crl = reshaped_logits.detach().cpu().numpy()\n",
    "    cl = labels.detach().cpu().numpy()\n",
    "    for i in range(len(cl)):\n",
    "        for j in range(len(crl[i])):\n",
    "            if crl[i][j] < crl[i][cl[i]]:\n",
    "                reshaped_logits[i][j] = -200#torch.Tensor(np.inf).cuda().half()\n",
    "    loss = lf(reshaped_logits,labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "def calculate_weights(reshaped_logits, labels):\n",
    "    weights = []\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    reshaped_logits = reshaped_logits.detach().cpu().numpy()\n",
    "    for i in range(len(labels)):\n",
    "        weights.append(np.sqrt(num_choices - rankdata(reshaped_logits[i,:], method = 'max')[labels[i]] +1))\n",
    "    return torch.Tensor(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UsePretrainedBERTForMultipleChoice(nn.Module):\n",
    "    def __init__(self, model, num_choices=10):\n",
    "        super(UsePretrainedBERTForMultipleChoice, self).__init__()\n",
    "        self.num_choices = num_choices\n",
    "        self.bert = model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.size = 1024\n",
    "        self.fc1 = nn.Linear(self.size*self.num_choices, 200)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.classifier = nn.Linear(100, self.num_choices)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        flat_input_ids = input_ids.view(-1, input_ids.size(-1))\n",
    "        flat_token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1))\n",
    "        flat_attention_mask = attention_mask.view(-1, attention_mask.size(-1))\n",
    "        _, pooled_output = self.bert(flat_input_ids, flat_token_type_ids, flat_attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = pooled_output.view(-1, self.size*self.num_choices)\n",
    "        layer1 = self.dropout(F.relu(self.fc1(pooled_output)))\n",
    "        layer2 = self.dropout(F.relu(self.fc2(layer1)))\n",
    "        logits = self.classifier(layer2)\n",
    "        reshaped_logits = logits.view(-1, self.num_choices)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss(reduce = False)\n",
    "            lf = my_loss2\n",
    "            weights = calculate_weights(reshaped_logits, labels)\n",
    "            loss = lf(reshaped_logits, labels,loss_fct)*weights.cuda().half()\n",
    "            return torch.mean(loss)\n",
    "        else:\n",
    "            return reshaped_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#best_bert = torch.load(\"bert_best_large_trained_with_fc_head_69_val_mrr_200k_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()\n",
    " \n",
    "class InputFeatures(object):\n",
    "    def __init__(self,\n",
    "                 example_id,\n",
    "                 choices_features,\n",
    "                 label\n",
    "\n",
    "    ):\n",
    "        self.example_id = example_id\n",
    "        self.choices_features = [\n",
    "            {\n",
    "                'input_ids': input_ids,\n",
    "                'input_mask': input_mask,\n",
    "                'segment_ids': segment_ids\n",
    "            }\n",
    "              for _, input_ids, input_mask, segment_ids in choices_features\n",
    "          ]\n",
    "        self.label = label\n",
    "\n",
    "def select_field(features, field):\n",
    "    return [\n",
    "        [\n",
    "            choice[field]\n",
    "            for choice in feature.choices_features\n",
    "        ]\n",
    "        for feature in features\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(df, tokenizer, max_seq_length):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    # Swag is a multiple choice task. To perform this task using Bert,\n",
    "    # we will use the formatting proposed in \"Improving Language\n",
    "    # Understanding by Generative Pre-Training\" and suggested by\n",
    "    # @jacobdevlin-google in this issue\n",
    "    # https://github.com/google-research/bert/issues/38.\n",
    "    #\n",
    "    # Each choice will correspond to a sample on which we run the\n",
    "    # inference. For a given Swag example, we will create the 4\n",
    "    # following inputs:\n",
    "    # - [CLS] context [SEP] choice_1 [SEP]\n",
    "    # - [CLS] context [SEP] choice_2 [SEP]\n",
    "    # - [CLS] context [SEP] choice_3 [SEP]\n",
    "    # - [CLS] context [SEP] choice_4 [SEP]\n",
    "    # The model will output a single value for each input. To get the\n",
    "    # final decision of the model, we will run a softmax over these 4\n",
    "    # outputs.\n",
    "    features = []\n",
    "    for example_index, example in df.iterrows():\n",
    "        context_tokens = tokenizer.tokenize(example[1])\n",
    "        choices_features = []\n",
    "        for ending_index, ending in enumerate(example[3:]):\n",
    "            # We create a copy of the context tokens in order to be\n",
    "            # able to shrink it according to ending_tokens\n",
    "            context_tokens_choice = context_tokens[:]\n",
    "            ending_tokens = tokenizer.tokenize(ending)\n",
    "            # Modifies `context_tokens_choice` and `ending_tokens` in\n",
    "            # place so that the total length is less than the\n",
    "            # specified length.  Account for [CLS], [SEP], [SEP] with\n",
    "            # \"- 3\"\n",
    "            _truncate_seq_pair(context_tokens_choice, ending_tokens, max_seq_length - 3)\n",
    "\n",
    "            tokens = [\"[CLS]\"] + context_tokens_choice + [\"[SEP]\"] + ending_tokens + [\"[SEP]\"]\n",
    "            segment_ids = [0] * (len(context_tokens_choice) + 2) + [1] * (len(ending_tokens) + 1)\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "            input_mask = [1] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            padding = [0] * (max_seq_length - len(input_ids))\n",
    "            input_ids += padding\n",
    "            input_mask += padding\n",
    "            segment_ids += padding\n",
    "\n",
    "            assert len(input_ids) == max_seq_length\n",
    "            assert len(input_mask) == max_seq_length\n",
    "            assert len(segment_ids) == max_seq_length\n",
    "\n",
    "            choices_features.append((tokens, input_ids, input_mask, segment_ids))\n",
    "\n",
    "        label = example[2]\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                example_id = example[0],\n",
    "                choices_features = choices_features,\n",
    "                label = label\n",
    "            )\n",
    "        )\n",
    "    return features\n",
    "\n",
    "\n",
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp16 = True\n",
    "local_rank = -1 \n",
    "gradient_accumulation_steps = 8\n",
    "train_batch_size = 32\n",
    "seed = 111\n",
    "bert_model = 'bert-large-uncased'\n",
    "do_lower_case = True\n",
    "warmup_proportion = 0.1\n",
    "num_choices = num_choices\n",
    "learning_rate = 2e-5 * gradient_accumulation_steps\n",
    "loss_scale = 128\n",
    "num_train_epochs = 5\n",
    "start_lr = 2e-7\n",
    "end_lr = 2e-3\n",
    "use_fp16 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import apex\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = convert_examples_to_features(train, tokenizer,80)\n",
    "dev_features = convert_examples_to_features(dev, tokenizer,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_input_ids = torch.tensor(select_field(train_features, 'input_ids'), dtype=torch.long)\n",
    "all_train_input_mask = torch.tensor(select_field(train_features, 'input_mask'), dtype=torch.long)\n",
    "all_train_segment_ids = torch.tensor(select_field(train_features, 'segment_ids'), dtype=torch.long)\n",
    "all_train_label = torch.tensor([f.label for f in train_features], dtype=torch.long)\n",
    "train_data = TensorDataset(all_train_input_ids, all_train_input_mask, all_train_segment_ids, all_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eval_input_ids = torch.tensor(select_field(dev_features, 'input_ids'), dtype=torch.long)\n",
    "all_eval_input_mask = torch.tensor(select_field(dev_features, 'input_mask'), dtype=torch.long)\n",
    "all_eval_segment_ids = torch.tensor(select_field(dev_features, 'segment_ids'), dtype=torch.long)\n",
    "all_eval_label = torch.tensor([f.label for f in dev_features], dtype=torch.long)\n",
    "eval_data = TensorDataset(all_eval_input_ids, all_eval_input_mask, all_eval_segment_ids, all_eval_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    outputs = np.argmax(out, axis=1)\n",
    "    return np.sum(outputs == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata \n",
    "def accuracy(out, labels):\n",
    "    mrr = 0\n",
    "    for i in range(len(out)):\n",
    "        mrr += 1.0/(num_choices - rankdata(out[i], method='max')[labels[i]] +1)\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UsePretrainedBERTForMultipleChoice(classification_bert.bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "class CyclicLR(object):\n",
    "    \"\"\"Sets the learning rate of each parameter group according to\n",
    "    cyclical learning rate policy (CLR). The policy cycles the learning\n",
    "    rate between two boundaries with a constant frequency, as detailed in\n",
    "    the paper `Cyclical Learning Rates for Training Neural Networks`_.\n",
    "    The distance between the two boundaries can be scaled on a per-iteration\n",
    "    or per-cycle basis.\n",
    "    Cyclical learning rate policy changes the learning rate after every batch.\n",
    "    `batch_step` should be called after a batch has been used for training.\n",
    "    To resume training, save `last_batch_iteration` and use it to instantiate `CycleLR`.\n",
    "    This class has three built-in policies, as put forth in the paper:\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n",
    "        cycle iteration.\n",
    "    This implementation was adapted from the github repo: `bckenstler/CLR`_\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        base_lr (float or list): Initial learning rate which is the\n",
    "            lower boundary in the cycle for eachparam groups.\n",
    "            Default: 0.001\n",
    "        max_lr (float or list): Upper boundaries in the cycle for\n",
    "            each parameter group. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore\n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function. Default: 0.006\n",
    "        step_size (int): Number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch. Default: 2000\n",
    "        mode (str): One of {triangular, triangular2, exp_range}.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "            Default: 'triangular'\n",
    "        gamma (float): Constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "            Default: 1.0\n",
    "        scale_fn (function): Custom scaling policy defined by a single\n",
    "            argument lambda function, where\n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored\n",
    "            Default: None\n",
    "        scale_mode (str): {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on\n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle).\n",
    "            Default: 'cycle'\n",
    "        last_batch_iteration (int): The index of the last batch. Default: -1\n",
    "    Example:\n",
    "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "        >>> scheduler = torch.optim.CyclicLR(optimizer)\n",
    "        >>> data_loader = torch.utils.data.DataLoader(...)\n",
    "        >>> for epoch in range(10):\n",
    "        >>>     for batch in data_loader:\n",
    "        >>>         scheduler.batch_step()\n",
    "        >>>         train_batch(...)\n",
    "    .. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
    "    .. _bckenstler/CLR: https://github.com/bckenstler/CLR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
    "                 step_size=2000, mode='triangular', gamma=1.,\n",
    "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
    "\n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise TypeError('{} is not an Optimizer'.format(\n",
    "                type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
    "            if len(base_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(base_lr)))\n",
    "            self.base_lrs = list(base_lr)\n",
    "        else:\n",
    "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
    "            if len(max_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(max_lr)))\n",
    "            self.max_lrs = list(max_lr)\n",
    "        else:\n",
    "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        self.step_size = step_size\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
    "                and scale_fn is None:\n",
    "            raise ValueError('mode is invalid and scale_fn is None')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = self._triangular_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = self._triangular2_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = self._exp_range_scale_fn\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "\n",
    "        self.batch_step(last_batch_iteration + 1)\n",
    "        self.last_batch_iteration = last_batch_iteration\n",
    "\n",
    "    def batch_step(self, batch_iteration=None):\n",
    "        if batch_iteration is None:\n",
    "            batch_iteration = self.last_batch_iteration + 1\n",
    "        self.last_batch_iteration = batch_iteration\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _triangular_scale_fn(self, x):\n",
    "        return 1.\n",
    "\n",
    "    def _triangular2_scale_fn(self, x):\n",
    "        return 1 / (2. ** (x - 1))\n",
    "\n",
    "    def _exp_range_scale_fn(self, x):\n",
    "        return self.gamma ** (x)\n",
    "\n",
    "    def get_lr(self):\n",
    "        step_size = float(self.step_size)\n",
    "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
    "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
    "\n",
    "        lrs = []\n",
    "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
    "        for param_group, base_lr, max_lr in param_lrs:\n",
    "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
    "            if self.scale_mode == 'cycle':\n",
    "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
    "            else:\n",
    "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
    "            lrs.append(lr)\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef find_lr(train_dataloader, model, optim_func=BertAdam, min_lr=0.000001, max_lr=2,\\n            device):\\n    lr_list = np.linspace(start=min_lr, stop=max_lr, num=len(train_dataloader))\\n    loss_list = []\\n    curr_loss = 0\\n    for step, batch in enumerate(tqdm(train_dataloader, total=len(train_dataloader), desc=\"Iteration\", position=0)):\\n        param_optimizer = [(n, param.clone().detach().to(\\'cpu\\').float().requires_grad_())                            for n, param in model.named_parameters()]\\n        no_decay = [\\'bias\\', \\'gamma\\', \\'beta\\']\\n        optimizer_grouped_parameters = [\\n            {\\n                \\'params\\': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\\n                \\'weight_decay_rate\\': 0.01},\\n            {\\'params\\': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \\'weight_decay_rate\\': 0.0}\\n        ]\\n        optimizer = optim_func(optimizer_grouped_parameters, lr=lr_list[step])\\n        batch = tuple(t.to(device) for t in batch)\\n        input_ids, input_mask, segment_ids, label_ids = batch\\n        loss, _ = model(input_ids, segment_ids, input_mask, label_ids)\\n        loss.backward()\\n        curr_loss += loss.item()\\n        loss_list.append(curr_loss / (step + 1))\\n        optimizer.step()\\n        model.zero_grad()\\n    plt.plot(lr_list, loss_list)\\n    plt.show()\\n    return lr_list[np.argmin(loss_list)]\\n    '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(min_lr, max_lr,train_batch_size = train_batch_size ):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "\n",
    "    train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=do_lower_case)\n",
    "\n",
    "    num_train_steps = int(len(train_data) / train_batch_size / gradient_accumulation_steps * num_train_epochs)\n",
    "\n",
    "    # Prepare model\n",
    "    model = UsePretrainedBERTForMultipleChoice(classification_bert.bert)\n",
    "    if fp16:\n",
    "        model.half()\n",
    "    model.to(device)\n",
    "    if local_rank != -1:\n",
    "        try:\n",
    "            from apex.parallel import DistributedDataParallel as DDP\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "        model = DDP(model)\n",
    "    elif n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Prepare optimizer\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "\n",
    "    # hack to remove pooler, which is not used\n",
    "    # thus it produce None grad that break apex\n",
    "    param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "    global_step = 0\n",
    "    if local_rank == -1:\n",
    "        train_sampler = RandomSampler(train_data)\n",
    "    else:\n",
    "        train_sampler = DistributedSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "    t_total = num_train_steps\n",
    "    if local_rank != -1:\n",
    "        t_total = t_total // torch.distributed.get_world_size()\n",
    "    if fp16:\n",
    "        try:\n",
    "            from apex.optimizers import FP16_Optimizer\n",
    "            from apex.optimizers import FusedAdam\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "        optimizer = FusedAdam(optimizer_grouped_parameters,\n",
    "                              lr=learning_rate,\n",
    "                              bias_correction=False,\n",
    "                              max_grad_norm=1.0)\n",
    "        if loss_scale == 0:\n",
    "            optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
    "        else:\n",
    "            optimizer = FP16_Optimizer(optimizer, static_loss_scale=loss_scale)\n",
    "    else:\n",
    "        optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                             lr=learning_rate,\n",
    "                             warmup=warmup_proportion,\n",
    "                             t_total=t_total)\n",
    "    lr_list = np.linspace(start=min_lr, stop=max_lr, num=len(train_dataloader)//gradient_accumulation_steps)\n",
    "    loss_list = []\n",
    "    curr_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, total=len(train_dataloader), desc=\"Iteration\", position=0)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "        loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "        if fp16:\n",
    "            optimizer.backward(loss)\n",
    "        else:\n",
    "            loss.backward()\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            # modify learning rate with special warm up BERT uses\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_list[global_step]\n",
    "            curr_loss += loss.item()\n",
    "            loss_list.append(curr_loss/ (global_step+1))\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "    plt.plot(lr_list, loss_list)\n",
    "    plt.show()\n",
    "    return lr_list[np.argmin(loss_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 0/7500 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Iteration: 100%|██████████| 7500/7500 [20:15<00:00,  6.20it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get_list_out = find_lr(2e-7, 2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_batch_size = train_batch_size):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "\n",
    "    train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=do_lower_case)\n",
    "\n",
    "    num_train_steps = int(len(train_data) / train_batch_size / gradient_accumulation_steps * num_train_epochs)\n",
    "\n",
    "    # Prepare model\n",
    "    model = UsePretrainedBERTForMultipleChoice(classification_bert.bert)\n",
    "    if fp16:\n",
    "        model.half()\n",
    "    model.to(device)\n",
    "    if local_rank != -1:\n",
    "        try:\n",
    "            from apex.parallel import DistributedDataParallel as DDP\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "        model = DDP(model)\n",
    "    elif n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Prepare optimizer\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "\n",
    "    # hack to remove pooler, which is not used\n",
    "    # thus it produce None grad that break apex\n",
    "    param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "    t_total = num_train_steps\n",
    "    if local_rank != -1:\n",
    "        t_total = t_total // torch.distributed.get_world_size()\n",
    "    if fp16 and use_fp16:\n",
    "        try:\n",
    "            from apex.optimizers import FP16_Optimizer\n",
    "            from apex.optimizers import FusedAdam\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "        optimizer = FusedAdam(optimizer_grouped_parameters,\n",
    "                              lr=learning_rate,\n",
    "                              bias_correction=False,\n",
    "                              max_grad_norm=1.0)\n",
    "        optimizer = CyclicLR(optimizer,base_lr = start_lr, max_lr = end_lr)\n",
    "        if loss_scale == 0:\n",
    "            optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
    "        else:\n",
    "            optimizer = FP16_Optimizer(optimizer, static_loss_scale=loss_scale)\n",
    "    else:\n",
    "        optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                             lr=learning_rate,\n",
    "                             warmup=warmup_proportion,\n",
    "                             t_total=t_total)\n",
    "    optimizer = CyclicLR(optimizer,base_lr = start_lr, max_lr = end_lr)\n",
    "    global_step = 0\n",
    "    if local_rank == -1:\n",
    "        train_sampler = RandomSampler(train_data)\n",
    "    else:\n",
    "        train_sampler = DistributedSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=train_batch_size)\n",
    "    for _ in trange(int(num_train_epochs), desc=\"Epoch\", position = 0):\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\", position = 0)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids = batch\n",
    "            loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            if n_gpu > 1:\n",
    "                loss = loss.mean() # mean() to average on multi-gpu.\n",
    "            if gradient_accumulation_steps > 1:\n",
    "                loss = loss / gradient_accumulation_steps\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "\n",
    "            if fp16 and use_fp16:\n",
    "                optimizer.backward(loss)\n",
    "            else:\n",
    "                loss.backward()\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                # modify learning rate with special warm up BERT uses\n",
    "                lr_this_step = learning_rate * warmup_linear(global_step/t_total,warmup_proportion)\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr_this_step\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "            \n",
    "        model.eval()\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "        for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "            with torch.no_grad():\n",
    "                tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "                logits = model(input_ids, segment_ids, input_mask)\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = label_ids.to('cpu').numpy()\n",
    "            tmp_eval_accuracy = accuracy(logits, label_ids)\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "            nb_eval_examples += input_ids.size(0)\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        eval_accuracy = eval_accuracy / nb_eval_examples\n",
    "\n",
    "        result = {'eval_loss': eval_loss,\n",
    "                  'eval_mrr': eval_accuracy,\n",
    "                  'global_step': global_step,\n",
    "                  'loss': tr_loss/nb_tr_steps}\n",
    "        print(result)\n",
    "        torch.save(model, 'checkpoint' + str(eval_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1250/1250 [03:22<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8187203125, 'eval_mrr': 0.31181777777777786, 'global_step': 156, 'loss': 0.48493837890625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type UsePretrainedBERTForMultipleChoice. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "Iteration: 100%|██████████| 1250/1250 [03:22<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8187203125, 'eval_mrr': 0.31181777777777786, 'global_step': 312, 'loss': 0.47849423828125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1250/1250 [03:22<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8187203125, 'eval_mrr': 0.31181777777777786, 'global_step': 468, 'loss': 0.482462841796875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1250/1250 [03:22<00:00,  6.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-6f7f5e102983>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_batch_size)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mlabel_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mtmp_eval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = best_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disks/extra/msaic\n"
     ]
    }
   ],
   "source": [
    "%cd msaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Question</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie Canal Distance Tables The Erie Canal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>What is the distance between Erie AND Buffalo?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>The distance between Erie and Buffalo in a str...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie Canal Distances. Erie Canal Distance Tabl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie's Metropolitan Area consists of approxima...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                   Question  \\\n",
       "0  1135787  distance between erie in buffalo new york   \n",
       "1  1135787  distance between erie in buffalo new york   \n",
       "2  1135787  distance between erie in buffalo new york   \n",
       "3  1135787  distance between erie in buffalo new york   \n",
       "4  1135787  distance between erie in buffalo new york   \n",
       "\n",
       "                                            Sentence  seq  \n",
       "0  Erie Canal Distance Tables The Erie Canal is t...    0  \n",
       "1  What is the distance between Erie AND Buffalo?...    1  \n",
       "2  The distance between Erie and Buffalo in a str...    2  \n",
       "3  Erie Canal Distances. Erie Canal Distance Tabl...    3  \n",
       "4  Erie's Metropolitan Area consists of approxima...    4  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv(\"eval1_unlabelled.tsv\", sep= '\\t',header=None)\n",
    "df3 = df2.copy()\n",
    "df3.columns = ['index','Question', 'Sentence','seq']\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10417/10417 [00:02<00:00, 3767.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "row_list = []\n",
    "for i in tqdm(range(0,len(df3), 10), total = len(df3)//10, position = 0):\n",
    "  slice = df3.iloc[i:i+10]\n",
    "  row = []\n",
    "  row.append(list(slice['index'])[0])\n",
    "  row.append(list(slice['Question'])[0])\n",
    "  row.append(0)\n",
    "  row += list(slice['Sentence'])\n",
    "  row_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.DataFrame(row_list, columns = ['qid', 'question', 'label', '0','1','2','3','4','5','6','7','8','9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = convert_examples_to_features(testdf, tokenizer,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eval_input_ids = torch.tensor(select_field(test_features, 'input_ids'), dtype=torch.long)\n",
    "all_eval_input_mask = torch.tensor(select_field(test_features, 'input_mask'), dtype=torch.long)\n",
    "all_eval_segment_ids = torch.tensor(select_field(test_features, 'segment_ids'), dtype=torch.long)\n",
    "#all_eval_label = torch.tensor([f.label for f in test_features], dtype=torch.long)\n",
    "test_data = TensorDataset(all_eval_input_ids, all_eval_input_mask, all_eval_segment_ids)#, all_eval_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "outputs_list = []\n",
    "for input_ids, input_mask, segment_ids in tqdm(test_dataloader, total = len(test_dataloader), position = 0):\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, segment_ids, input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        outputs_list.append(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs =[]\n",
    "for item in outputs_list:\n",
    "  for i in item:\n",
    "    outputs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for item in outputs:\n",
    "  for i in item:\n",
    "    outs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['pred'] = outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Question</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>seq</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie Canal Distance Tables The Erie Canal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>What is the distance between Erie AND Buffalo?...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.162109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>The distance between Erie and Buffalo in a str...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.925781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie Canal Distances. Erie Canal Distance Tabl...</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie's Metropolitan Area consists of approxima...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.584961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>This will help you estimate how much time you ...</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.371094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>As a general guide, Albany to Oswego, NY will ...</td>\n",
       "      <td>6</td>\n",
       "      <td>-2.101562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie, PA. {{::location.tagLine.value.text}}. C...</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.597656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>You start your flight Distance from Buffalo, N...</td>\n",
       "      <td>8</td>\n",
       "      <td>-2.619141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>What is the distance between Erie AND Buffalo?...</td>\n",
       "      <td>9</td>\n",
       "      <td>3.078125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                   Question  \\\n",
       "0  1135787  distance between erie in buffalo new york   \n",
       "1  1135787  distance between erie in buffalo new york   \n",
       "2  1135787  distance between erie in buffalo new york   \n",
       "3  1135787  distance between erie in buffalo new york   \n",
       "4  1135787  distance between erie in buffalo new york   \n",
       "5  1135787  distance between erie in buffalo new york   \n",
       "6  1135787  distance between erie in buffalo new york   \n",
       "7  1135787  distance between erie in buffalo new york   \n",
       "8  1135787  distance between erie in buffalo new york   \n",
       "9  1135787  distance between erie in buffalo new york   \n",
       "\n",
       "                                            Sentence  seq      pred  \n",
       "0  Erie Canal Distance Tables The Erie Canal is t...    0  0.811035  \n",
       "1  What is the distance between Erie AND Buffalo?...    1  3.162109  \n",
       "2  The distance between Erie and Buffalo in a str...    2  2.925781  \n",
       "3  Erie Canal Distances. Erie Canal Distance Tabl...    3 -0.003242  \n",
       "4  Erie's Metropolitan Area consists of approxima...    4 -1.584961  \n",
       "5  This will help you estimate how much time you ...    5 -2.371094  \n",
       "6  As a general guide, Albany to Oswego, NY will ...    6 -2.101562  \n",
       "7  Erie, PA. {{::location.tagLine.value.text}}. C...    7 -0.597656  \n",
       "8  You start your flight Distance from Buffalo, N...    8 -2.619141  \n",
       "9  What is the distance between Erie AND Buffalo?...    9  3.078125  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "outfilename = 'answer.tsv'\n",
    "with open(outfilename,\"w\",encoding=\"utf-8\") as fw:\n",
    "  import math\n",
    "  linelist = []\n",
    "  tempscores = []\n",
    "  for idx, row in df3.iterrows():\n",
    "      tempscores.append(math.exp(row['pred']))\n",
    "      if((idx +1)%10==0):\n",
    "          expsum = sum(tempscores)\n",
    "          tempscores = [str(s/expsum) for s in tempscores]\n",
    "          scoreString = \"\\t\".join(tempscores)\n",
    "          qid = str(row[0])\n",
    "          fw.write(qid+\"\\t\"+scoreString+\"\\n\")\n",
    "          tempscores=[]\n",
    "      if(idx%5000==0):\n",
    "          print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1135787</th>\n",
       "      <th>0.032957278743477876</th>\n",
       "      <th>0.345947267712741</th>\n",
       "      <th>0.2731328298244241</th>\n",
       "      <th>0.014598729294635408</th>\n",
       "      <th>0.0030018118173541566</th>\n",
       "      <th>0.001367635358668276</th>\n",
       "      <th>0.0017907141074189321</th>\n",
       "      <th>0.008056834464135701</th>\n",
       "      <th>0.0010671978248448933</th>\n",
       "      <th>0.31807970085229975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>281922</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.015919</td>\n",
       "      <td>0.316326</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.117972</td>\n",
       "      <td>0.048867</td>\n",
       "      <td>0.031981</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.020905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120233</td>\n",
       "      <td>0.027486</td>\n",
       "      <td>0.017434</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>0.014556</td>\n",
       "      <td>0.018980</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.376139</td>\n",
       "      <td>0.044814</td>\n",
       "      <td>0.014379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>319757</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.099061</td>\n",
       "      <td>0.023783</td>\n",
       "      <td>0.048930</td>\n",
       "      <td>0.093196</td>\n",
       "      <td>0.021867</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.012994</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.533431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193633</td>\n",
       "      <td>0.010344</td>\n",
       "      <td>0.281637</td>\n",
       "      <td>0.015389</td>\n",
       "      <td>0.012338</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.621188</td>\n",
       "      <td>0.029655</td>\n",
       "      <td>0.007120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50229</td>\n",
       "      <td>0.164240</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.647051</td>\n",
       "      <td>0.031696</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>0.047010</td>\n",
       "      <td>0.066359</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0.013299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1135787  0.032957278743477876  0.345947267712741  0.2731328298244241  \\\n",
       "0   281922              0.410156           0.015919            0.316326   \n",
       "1   120233              0.027486           0.017434            0.015731   \n",
       "2   319757              0.020785           0.099061            0.023783   \n",
       "3   193633              0.010344           0.281637            0.015389   \n",
       "4    50229              0.164240           0.006654            0.008129   \n",
       "\n",
       "   0.014598729294635408  0.0030018118173541566  0.001367635358668276  \\\n",
       "0              0.018341               0.010491              0.117972   \n",
       "1              0.014556               0.018980              0.467200   \n",
       "2              0.048930               0.093196              0.021867   \n",
       "3              0.012338               0.009322              0.006827   \n",
       "4              0.647051               0.031696              0.010087   \n",
       "\n",
       "   0.0017907141074189321  0.008056834464135701  0.0010671978248448933  \\\n",
       "0               0.048867              0.031981               0.009044   \n",
       "1               0.003280              0.376139               0.044814   \n",
       "2               0.017383              0.012994               0.128571   \n",
       "3               0.006180              0.621188               0.029655   \n",
       "4               0.047010              0.066359               0.005474   \n",
       "\n",
       "   0.31807970085229975  \n",
       "0             0.020905  \n",
       "1             0.014379  \n",
       "2             0.533431  \n",
       "3             0.007120  \n",
       "4             0.013299  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.read_csv('answer.tsv', sep = '\\t')\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp answer.tsv /home/jupyter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
