{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HyperQA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tYpR5CXhVfD1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Obtain Data"
      ]
    },
    {
      "metadata": {
        "id": "LPcElNkpTp1E",
        "colab_type": "code",
        "outputId": "96da9ebc-fa2a-43ce-8508-a923699c9013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install cntk\n",
        "!pip install -U scikit-learn\n",
        "!pip install zipfile36"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cntk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/42/38e37601611bd10f2cb6efffceb35bc5dc44e9aef5a10471ec914b02ef89/cntk-2.6-cp36-cp36m-manylinux1_x86_64.whl (74.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 74.8MB 566kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from cntk) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from cntk) (1.14.6)\n",
            "Installing collected packages: cntk\n",
            "Successfully installed cntk-2.6\n",
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/26/d04320c3edf2d59b1fcd0720b46753d4d603a76e68d8ad10a9b92ab06db2/scikit_learn-0.20.1-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.4MB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.1.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Found existing installation: scikit-learn 0.19.2\n",
            "    Uninstalling scikit-learn-0.19.2:\n",
            "      Successfully uninstalled scikit-learn-0.19.2\n",
            "Successfully installed scikit-learn-0.20.1\n",
            "Collecting zipfile36\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/8a/3b7da0b0bd87d1ef05b74207827c72d348b56a0d6d83242582be18a81e02/zipfile36-0.1.3-py3-none-any.whl\n",
            "Installing collected packages: zipfile36\n",
            "Successfully installed zipfile36-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uF5axD1FeFOJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir msaic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6BEV8YFdYDOP",
        "colab_type": "code",
        "outputId": "936f467c-e419-45ef-cc4e-8cc948794e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://competitions.codalab.org/my/datasets/download/2c6a99a5-b071-4f1d-a3b1-d49a923e0c68 \n",
        "!mv 2c6a99a5-b071-4f1d-a3b1-d49a923e0c68 data.zip\n",
        "!mv data.zip msaic/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-29 17:12:50--  https://competitions.codalab.org/my/datasets/download/2c6a99a5-b071-4f1d-a3b1-d49a923e0c68\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 134.158.75.178\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|134.158.75.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/ba53c/data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=04b1c451ef1afaa4812138f6096b912592a0447edb96e406ee983415dbf2681e&X-Amz-Date=20181129T171249Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20181129%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2018-11-29 17:12:50--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/ba53c/data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=04b1c451ef1afaa4812138f6096b912592a0447edb96e406ee983415dbf2681e&X-Amz-Date=20181129T171249Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20181129%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 608893981 (581M) [application/zip]\n",
            "Saving to: ‘2c6a99a5-b071-4f1d-a3b1-d49a923e0c68’\n",
            "\n",
            "2c6a99a5-b071-4f1d- 100%[===================>] 580.69M  38.5MB/s    in 15s     \n",
            "\n",
            "2018-11-29 17:13:05 (38.6 MB/s) - ‘2c6a99a5-b071-4f1d-a3b1-d49a923e0c68’ saved [608893981/608893981]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oIc5WKkpaosL",
        "colab_type": "code",
        "outputId": "f215dbd4-aca1-41a9-a9e9-e9b4df014dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!mv glove.6B.zip msaic/\n",
        "glove_zip = r'glove.6B.zip';\n",
        "#!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "#!mv glove.840B.300d.zip msaic/\n",
        "#glove_zip = r'glove.840B.300d.zip';"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-29 17:13:21--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2018-11-29 17:13:21--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  20.7MB/s    in 42s     \n",
            "\n",
            "2018-11-29 17:14:04 (19.5 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8rfcJb2VemQD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!wget https://competitions.codalab.org/my/datasets/download/a6b5bd16-db6f-4cbe-9670-04ecb7504a7a\n",
        "#!mv a6b5bd16-db6f-4cbe-9670-04ecb7504a7a Starting_Kit.zip\n",
        "#!mv Starting_Kit.zip msaic/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4NiLurmJd8Kp",
        "colab_type": "code",
        "outputId": "791c175f-f79a-4a77-b7bf-88c7ff704048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd msaic"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/msaic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SQPWL6Hutcw9",
        "colab_type": "code",
        "outputId": "6e3d51e2-f6cb-44ab-e022-470e3a5457e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zipref = zipfile.ZipFile('data.zip', 'r')\n",
        "zipref.extractall()\n",
        "zipref.close()\n",
        "print('Raw Data Extracted')\n",
        "\n",
        "zipref = zipfile.ZipFile(glove_zip, 'r')\n",
        "zipref.extractall()\n",
        "zipref.close()\n",
        "print('Glove Data Extracted')\n",
        "\n",
        "'''\n",
        "zipref = zipfile.ZipFile('Starting_Kit.zip', 'r')\n",
        "zipref.extractall()\n",
        "zipref.close()\n",
        "print('Starting Kit unzipped')\n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw Data Extracted\n",
            "Glove Data Extracted\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nzipref = zipfile.ZipFile('Starting_Kit.zip', 'r')\\nzipref.extractall()\\nzipref.close()\\nprint('Starting Kit unzipped')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "evEnVCATnvOG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# HyperQA\n",
        "\n",
        "https://arxiv.org/pdf/1707.07847.pdf"
      ]
    },
    {
      "metadata": {
        "id": "e6NDTUayiViU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d5f81fc-d859-4fbc-cd85-8f650c87edc5"
      },
      "cell_type": "code",
      "source": [
        "%cd msaic"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/msaic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c1Bxe-0mBk34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a960f535-d513-49e2-a269-31289cee03ad"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "import sys\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize\n",
        "#nltk.download('punkt')\n",
        "import re\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f3h-kqCe13PG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "# Notes\n",
        "# Different queries have same query id. Ex: 7977\n",
        "# Some queries donot have right answers. Ex: 280200\n",
        "##############################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Ch7Xt6jFeLZ",
        "colab_type": "code",
        "outputId": "6740513f-9218-4c9a-83e5-914b9e0d62bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Utility Funcs\n",
        "\n",
        "def progressBar(value, endvalue, print_vars=[''], print_values=[-1], bar_length=20):\n",
        "        percent = float(value) / endvalue\n",
        "        arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
        "        spaces = ' ' * (bar_length - len(arrow))\n",
        "        assert(len(print_vars)==len(print_values));\n",
        "        strg = '';\n",
        "        for var, val in zip(print_vars,print_values):\n",
        "          strg+=' {}: '.format(var.upper());\n",
        "          strg+='{:5f} |'.format(val);\n",
        "        sys.stdout.write(\"\\rPercent: [{0}][{1}/{2}] {3}% || {4} \".format(arrow + spaces, int(value), int(endvalue), int(round(percent * 100)), strg))\n",
        "        sys.stdout.flush()\n",
        "        return\n",
        "progressBar(5,25,['loss','acc'],[5,6])\n",
        "\n",
        "def cleanText(str):\n",
        "  #new_str = word_tokenize(str)\n",
        "  new_str = [x for x in re.split('\\W+', str) if x]\n",
        "  return new_str, len(new_str)\n",
        "\n",
        "def make_batch_data(batch, infer_max_len=False, max_len=0):\n",
        "  arr = [];\n",
        "  b_masks = [];\n",
        "  cstrg_, cstrg_len_ = [], [];\n",
        "  for row in batch:\n",
        "    cstrg, cstrg_len = cleanText(row);\n",
        "    cstrg_.append(cstrg);\n",
        "    cstrg_len_.append(cstrg_len);\n",
        "  max_len = np.max(cstrg_len_) if infer_max_len else max_len;\n",
        "  for i, cstrg in enumerate(cstrg_):\n",
        "    if cstrg_len_[i]>max_len:\n",
        "      cstrg = cstrg[:max_len];\n",
        "    elif cstrg_len_[i]<max_len:\n",
        "      cstrg+=[UNKNOWN]*(max_len-cstrg_len_[i])\n",
        "    cstrg = [word if word in word2id.keys() else UNKNOWN for word in cstrg];\n",
        "    bmask = [0.0 if word==UNKNOWN else 1.0 for word in cstrg];\n",
        "    cstrg = [word2id[word] for word in cstrg];\n",
        "    arr.append(cstrg);\n",
        "    b_masks.append(bmask);\n",
        "  return np.vstack(arr), np.vstack(b_masks);   \n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rPercent: [--->                ][5/25] 20% ||  LOSS: 5.000000 | ACC: 6.000000 | "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "on2GDbkShMDA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model save \n",
        "!mkdir new_model\n",
        "dfile = open('./new_model/dummy.txt','w',encoding='utf-8');\n",
        "dfile.write('Checking...');\n",
        "dfile.close();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-GyI3Y8LljOn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# some global vars\n",
        "EMB_DIMS = 300;\n",
        "PROJ_DIMS = 300;\n",
        "UNKNOWN = '_unk_';\n",
        "TRAINING_PERCENT = 0.8\n",
        "VAL_PERCENT = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5rNCyi2U1JE7",
        "colab_type": "code",
        "outputId": "e8ed9f99-886a-473c-a593-20373f892a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Get train and valid data\n",
        "\n",
        "data_dict = {};\n",
        "id2passage = {};\n",
        "n_queries = -1;\n",
        "n_passages = -1;\n",
        "running_query = '';\n",
        "passage_len_counter = np.zeros(1000, dtype='int32');\n",
        "\n",
        "f = open('data.tsv','r',encoding='utf-8');\n",
        "for i, line in enumerate(tqdm(f)):\n",
        "  tokens = line.strip().lower().split(\"\\t\")\n",
        "  query,passage,label = tokens[1],tokens[2],tokens[3];\n",
        "  _, cpassage_len = cleanText(passage);\n",
        "  passage_len_counter[np.min([999,cpassage_len])]+=1;\n",
        "  n_passages+=1;\n",
        "  id2passage[n_passages] = passage;\n",
        "  if running_query!=query:\n",
        "    running_query = query;\n",
        "    n_queries+=1;\n",
        "    data_dict[n_queries] = {};\n",
        "    _, cquery_len = cleanText(query);\n",
        "    data_dict[n_queries]['query'] = query;\n",
        "    data_dict[n_queries]['query_len'] = cquery_len;\n",
        "  if int(label)==1:\n",
        "    data_dict[n_queries]['pos'] = n_passages;\n",
        "    data_dict[n_queries]['pos_len'] = cpassage_len;\n",
        "  else:\n",
        "    if 'negs' not in data_dict[n_queries]:\n",
        "      data_dict[n_queries]['negs']=[];\n",
        "      data_dict[n_queries]['negs_len']=[];\n",
        "    data_dict[n_queries]['negs'].append(n_passages);\n",
        "    data_dict[n_queries]['negs_len'].append(cpassage_len);\n",
        "print('\\nTotal No.of Queries: {}, Passages: {}'.format(n_queries+1,n_passages+1));\n",
        "\n",
        "unique_query_ids = list(data_dict.keys())\n",
        "np.random.shuffle(unique_query_ids) #in-place\n",
        "n_train = int(np.floor(len(unique_query_ids)*TRAINING_PERCENT))\n",
        "n_val = int(np.floor(len(unique_query_ids)*VAL_PERCENT))\n",
        "training_query_ids, validation_query_ids = unique_query_ids[:n_train],unique_query_ids[n_train:n_train+n_val]\n",
        "print('TRAINING QUERIES: {}, VALIDATION EQURIES: {}'.format(n_train,n_val))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5241880it [04:41, 18617.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total No.of Queries: 524193, Passages: 5241880\n",
            "TRAINING QUERIES: 419354, VALIDATION EQURIES: 104838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CoTsyhguifLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "27427ed0-f02a-4249-bad5-a6e1db4ed86e"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(passage_len_counter);\n",
        "plt.show()\n",
        "avg_len = np.sum([(i+1)*val for i, val in enumerate(passage_len_counter)])/np.sum(passage_len_counter);\n",
        "print('Avg length of passages: {}'.format(avg_len))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFKCAYAAAAE1MaxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4f371e8550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Avg length of passages: 58.581255580059064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fE4lN_vSpbCw",
        "colab_type": "code",
        "outputId": "f5d35e98-4904-4679-f963-2a0545c3baff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Obtain Glove Embeddings\n",
        "glove_file = r'glove.6B.{}d.txt'.format(EMB_DIMS)\n",
        "#glove_file = r'glove.840B.{}d.txt'.format(EMB_DIMS)\n",
        "dfg = pd.read_csv(glove_file, sep=\" \", quoting=3, header=None, index_col=0)\n",
        "dfg.loc[UNKNOWN]=[0.0]*EMB_DIMS;\n",
        "print(dfg.shape)\n",
        "\n",
        "# make a hash dict\n",
        "word2id = {};\n",
        "id2word = {};\n",
        "for i, word in tqdm(enumerate(dfg.index.values)):\n",
        "  word2id[word] = i;\n",
        "  id2word[i] = word;"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99896it [00:00, 998958.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(400001, 300)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "400001it [00:00, 907027.36it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "dZ8BmSbxKsNb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# HyperQA Tensorflow model\n",
        "\n",
        "class HyperQA(object):\n",
        "    def __init__(self, vocab_embedding, emb_dim, projection_dim, margin, lr=0.001):\n",
        "        # parameters\n",
        "        self.projection_dim = projection_dim;\n",
        "        self.margin = margin;\n",
        "        self.emb_dim = emb_dim;\n",
        "        # placeholder\n",
        "        self.keep_prob = tf.placeholder(tf.float32, [])\n",
        "        self.reg_lambda = tf.placeholder(tf.float32, [])\n",
        "        self.query = tf.placeholder(tf.int32, [None, None])\n",
        "        self.query_bmask = tf.placeholder(tf.float32, [None, None])\n",
        "        self.pos_ans = tf.placeholder(tf.int32, [None, None])\n",
        "        self.pos_ans_bmask = tf.placeholder(tf.float32, [None, None])\n",
        "        self.neg_ans = tf.placeholder(tf.int32, [None, None])\n",
        "        self.neg_ans_bmask = tf.placeholder(tf.float32, [None, None])\n",
        "        # embedding lookup\n",
        "        self.embedding = tf.Variable(vocab_embedding, trainable=False, dtype=tf.float32, name='embeddings')\n",
        "        #self.embedding = tf.get_variable('embeddings', shape=[400001,self.emb_dim], initializer=tf.contrib.layers.xavier_initializer(), trainable=True, dtype=tf.float32)\n",
        "        self.query_emb = tf.nn.embedding_lookup(self.embedding, self.query) # [None,None,emb_dim]\n",
        "        self.pos_ans_emb = tf.nn.embedding_lookup(self.embedding, self.pos_ans) # [None,None,emb_dim]\n",
        "        self.neg_ans_emb = tf.nn.embedding_lookup(self.embedding, self.neg_ans) # [None,None,emb_dim]\n",
        "        # weight vars # a shared variable\n",
        "        self.w_p = tf.get_variable(\"w_p\", shape=[self.emb_dim,self.projection_dim],\n",
        "                                   initializer=tf.contrib.layers.xavier_initializer(), trainable=True, dtype=tf.float32)\n",
        "        self.b_p = tf.get_variable('b_p', shape=[self.projection_dim], initializer=tf.zeros_initializer(), trainable=True, dtype=tf.float32)\n",
        "        self.w_f = tf.get_variable(\"w_f\", shape=[1], initializer=tf.contrib.layers.xavier_initializer(), trainable=True, dtype=tf.float32)\n",
        "        self.b_f = tf.get_variable('b_f', shape=[1], initializer=tf.zeros_initializer(), trainable=True, dtype=tf.float32)\n",
        "        # projections with input # [None,None,emb_dim] and output # [None,None,proj_emb]\n",
        "        self.query_proj_ = self.project_fn(self.query_emb, self.query_bmask);\n",
        "        self.pos_ans_proj_ = self.project_fn(self.pos_ans_emb, self.pos_ans_bmask);\n",
        "        self.neg_ans_proj_ = self.project_fn(self.neg_ans_emb, self.neg_ans_bmask);\n",
        "        # dropout\n",
        "        self.query_proj = tf.nn.dropout(self.query_proj_, self.keep_prob);\n",
        "        self.pos_ans_proj = tf.nn.dropout(self.pos_ans_proj_, self.keep_prob);\n",
        "        self.neg_ans_proj = tf.nn.dropout(self.neg_ans_proj_, self.keep_prob);\n",
        "        # unit normalized representations with output #[None,proj_emb]\n",
        "        self.query_vec = tf.clip_by_norm(tf.reduce_sum(self.query_proj,axis=1), 1.0, axes=1) \n",
        "        self.pos_ans_vec = tf.clip_by_norm(tf.reduce_sum(self.pos_ans_proj,axis=1), 1.0, axes=1)\n",
        "        self.neg_ans_vec = tf.clip_by_norm(tf.reduce_sum(self.neg_ans_proj,axis=1), 1.0, axes=1)\n",
        "        # hyperbolic distance\n",
        "        self.p_distance = self.hyperbolic_ball(self.query_vec, self.pos_ans_vec) #[None,1]\n",
        "        self.n_distance = self.hyperbolic_ball(self.query_vec, self.neg_ans_vec) #[None,1]\n",
        "        # loss\n",
        "        self.p_score = self.p_distance*self.w_f+self.b_f; \n",
        "        self.n_score = self.n_distance*self.w_f+self.b_f;\n",
        "        self.losses = tf.nn.relu(self.margin + self.n_score - self.p_score) #[None,1]\n",
        "        self.reg_losses = self.reg_lambda*tf.reduce_sum(tf.abs(self.w_p));\n",
        "        self.loss = self.reg_losses+tf.reduce_sum(self.losses) #[]\n",
        "        # print loss ops\n",
        "        self.print_p_distance = tf.reduce_mean(self.p_distance)\n",
        "        self.print_n_distance = tf.reduce_mean(self.n_distance)\n",
        "        self.print_p_score_loss = tf.reduce_mean(self.p_score)\n",
        "        self.print_n_score_loss = tf.reduce_mean(self.n_score)\n",
        "        self.print_losses = tf.reduce_mean(self.losses)\n",
        "        # optimizer\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
        "        # adjust gradient\n",
        "        gradients = self.optimizer.compute_gradients(self.loss)\n",
        "        reim_gradients = [(self._to_riemannian_gradient(grad), var) for grad, var in gradients]\n",
        "        clip_gradients = [(self._ClipIfNotNone(grad), var) for grad, var in reim_gradients]\n",
        "        self.train_op = self.optimizer.apply_gradients(clip_gradients)       \n",
        "    def project_fn(self, inp_emb, bmask): # Input Shape [None,None,emb_dim], [None,None]\n",
        "        runtime_shape = tf.shape(inp_emb);\n",
        "        dim1 = runtime_shape[0];\n",
        "        dim2 = runtime_shape[1];\n",
        "        dense_output = tf.nn.xw_plus_b(tf.reshape(inp_emb, [-1,self.emb_dim]), self.w_p, self.b_p);\n",
        "        activated_output = tf.nn.relu(dense_output);\n",
        "        proj_emb = tf.reshape(activated_output,[dim1,dim2,self.projection_dim]);\n",
        "        bmask = tf.tile(tf.expand_dims(bmask,axis=-1),[1,1,self.projection_dim]);\n",
        "        masked_proj_emb = bmask*proj_emb;\n",
        "        return masked_proj_emb\n",
        "    def hyperbolic_ball(self, x, y, neg=False, eps=1E-6):\n",
        "        \"\"\" Poincare Distance Function \"\"\"\n",
        "        z = x - y\n",
        "        z = tf.norm(z, ord='euclidean', keep_dims=True, axis=1)\n",
        "        z = tf.square(z)\n",
        "        x_d = 1 - tf.square(tf.norm(x, ord='euclidean', keep_dims=True, axis=1))\n",
        "        y_d = 1 - tf.square(tf.norm(y, ord='euclidean', keep_dims=True, axis=1))\n",
        "        d = x_d * y_d\n",
        "        z = z / (d + eps)\n",
        "        z  = (2 * z) + 1\n",
        "        arcosh = z + tf.sqrt(tf.square(z) - 1 + eps)\n",
        "        arcosh = tf.log(arcosh)\n",
        "        if(neg):\n",
        "            arcosh = -arcosh\n",
        "        return arcosh\n",
        "    def _ClipIfNotNone(self, grad):\n",
        "        if grad is None:\n",
        "          return grad\n",
        "        grad = tf.clip_by_value(grad, -10, 10, name=None)\n",
        "        #grad = tf.clip_by_norm(grad, 1.0)\n",
        "        return grad\n",
        "    def _to_riemannian_gradient(self, ge):\n",
        "      if ge is None:\n",
        "        return None\n",
        "      try:\n",
        "        shape = ge.get_shape().as_list()\n",
        "        if len(shape) >= 3:\n",
        "            grad_scale = 1 - tf.square(tf.norm(ge, axis=[-2, -1], keepdims=True))\n",
        "        elif len(shape) == 2:\n",
        "            grad_scale = 1 - tf.square(tf.norm(ge, keepdims=True))\n",
        "        else:\n",
        "            return ge\n",
        "      except:\n",
        "        print('Exception handled!')\n",
        "        grad_scale = 1 - tf.square(tf.norm(ge, keep_dims=True))\n",
        "      grad_scale = (tf.square(grad_scale) + 1e-10) / 4.0\n",
        "      gr = ge * grad_scale\n",
        "      # gr = tf.clip_by_norm(gr, 1.0, axes=0)\n",
        "      return gr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fdp6sEWOoc2U",
        "colab_type": "code",
        "outputId": "b5524ced-aa9d-40c6-d487-b606714606a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1526
        }
      },
      "cell_type": "code",
      "source": [
        "# args\n",
        "MARGIN = 2.0;\n",
        "LEARNING_RATE = 0.001;\n",
        "#QL_MAX = 15;\n",
        "#PL_MAX = 300;\n",
        "TRAINING_BATCH_SIZE = 256;\n",
        "VALIDATION_BATCH_SIZE = 1024;\n",
        "VALIDATION_EVERY = 1;\n",
        "N_EPOCHS = 100;\n",
        "START_EPOCH = -1;\n",
        "RESUME_TRAINING = False;\n",
        "\n",
        "\n",
        "# Create a graph with above connections\n",
        "tf.reset_default_graph();\n",
        "hyperQA_Graph = tf.Graph();\n",
        "with hyperQA_Graph.as_default():\n",
        "  hyperQA = HyperQA(dfg.as_matrix(), EMB_DIMS, PROJ_DIMS, MARGIN, LEARNING_RATE)\n",
        "  print('graph built')\n",
        "  \n",
        "# epochs\n",
        "with tf.Session(graph=hyperQA_Graph) as sess:\n",
        "  saver = tf.train.Saver();\n",
        "  if not RESUME_TRAINING:\n",
        "    sess.run(tf.global_variables_initializer());\n",
        "    START_EPOCH = 0;\n",
        "  else:\n",
        "    saver.restore(sess, './new_model/epoch_model_{}.ckpt'.format(START_EPOCH-1));\n",
        "  for epoch in np.arange(START_EPOCH, N_EPOCHS):\n",
        "    # Loss and optimization on Training Data\n",
        "    print('beginning epoch: {}'.format(epoch));\n",
        "    n_batches = int(np.floor(n_train/TRAINING_BATCH_SIZE));\n",
        "    cum_loss = 0;\n",
        "    cum_pos_loss = 0;\n",
        "    cum_neg_loss = 0;\n",
        "    frm=0;\n",
        "    for i in range(n_batches):\n",
        "      batch_query_ids = training_query_ids[frm:frm+TRAINING_BATCH_SIZE];\n",
        "      batch_queries = [];\n",
        "      batch_pos = [];\n",
        "      batch_neg = [];\n",
        "      for query_id in batch_query_ids:\n",
        "        if 'pos' in data_dict[query_id].keys():\n",
        "          batch_queries.append(data_dict[query_id]['query']);\n",
        "          batch_pos.append(id2passage[data_dict[query_id]['pos']]);\n",
        "          j = np.random.choice(len(data_dict[query_id]['negs']));\n",
        "          batch_neg.append(id2passage[data_dict[query_id]['negs'][j]]);\n",
        "      x, x1 = make_batch_data(batch_queries,infer_max_len=True)\n",
        "      y, y1 = make_batch_data(batch_pos,infer_max_len=True) \n",
        "      z, z1 = make_batch_data(batch_neg,infer_max_len=True)\n",
        "      result = sess.run([hyperQA.train_op, hyperQA.print_losses, hyperQA.print_p_score_loss, hyperQA.print_n_score_loss],\n",
        "                        feed_dict={hyperQA.keep_prob: 0.8,\n",
        "                                   hyperQA.reg_lambda: 0.00001,\n",
        "                                   hyperQA.query:x,\n",
        "                                   hyperQA.query_bmask:x1,\n",
        "                                   hyperQA.pos_ans:y,\n",
        "                                   hyperQA.pos_ans_bmask:y1,\n",
        "                                   hyperQA.neg_ans:z,\n",
        "                                   hyperQA.neg_ans_bmask:z1})\n",
        "      cum_loss+=result[1];\n",
        "      cum_pos_loss+=result[2];\n",
        "      cum_neg_loss+=result[3];\n",
        "      frm+=TRAINING_BATCH_SIZE;\n",
        "      progressBar(frm,n_train,['loss','pos_loss','neg_loss'],[result[1],result[2],result[3]]);\n",
        "    print('\\nTRAINING || mean loss: {} | mean pos loss: {} | mean neg loss: {}'.format(cum_loss/n_batches,cum_pos_loss/n_batches,cum_neg_loss/n_batches))\n",
        "    saver.save(sess, './new_model/epoch_model_{}.ckpt'.format(epoch));\n",
        "    # Loss on Validation Data\n",
        "    if epoch%VALIDATION_EVERY==0:\n",
        "      #saver = tf.train.Saver();\n",
        "      #saver.restore(val_sess, './new_model/epoch_model_20.ckpt');\n",
        "      n_batches = int(np.floor(n_val/VALIDATION_BATCH_SIZE));\n",
        "      cum_loss = 0;\n",
        "      cum_pos_loss = 0;\n",
        "      cum_neg_loss = 0;\n",
        "      frm=0;\n",
        "      for i in range(n_batches):\n",
        "        batch_query_ids = validation_query_ids[frm:frm+VALIDATION_BATCH_SIZE];\n",
        "        batch_queries = [];\n",
        "        batch_pos = [];\n",
        "        batch_neg = [];\n",
        "        for query_id in batch_query_ids:\n",
        "          if 'pos' in data_dict[query_id].keys():\n",
        "            batch_queries.append(data_dict[query_id]['query']);\n",
        "            batch_pos.append(id2passage[data_dict[query_id]['pos']]);\n",
        "            j = np.random.choice(len(data_dict[query_id]['negs']));\n",
        "            batch_neg.append(id2passage[data_dict[query_id]['negs'][j]]);\n",
        "        x, x1 = make_batch_data(batch_queries,infer_max_len=True)\n",
        "        y, y1 = make_batch_data(batch_pos,infer_max_len=True) \n",
        "        z, z1 = make_batch_data(batch_neg,infer_max_len=True)\n",
        "        result = sess.run([hyperQA.print_losses, hyperQA.print_p_score_loss, hyperQA.print_n_score_loss],\n",
        "                          feed_dict={hyperQA.keep_prob:1.0,\n",
        "                                     hyperQA.reg_lambda:0.0,\n",
        "                                     hyperQA.query:x,\n",
        "                                     hyperQA.query_bmask:x1,\n",
        "                                     hyperQA.pos_ans:y,\n",
        "                                     hyperQA.pos_ans_bmask:y1,\n",
        "                                     hyperQA.neg_ans:z,\n",
        "                                     hyperQA.neg_ans_bmask:z1})\n",
        "        cum_loss+=result[0];\n",
        "        cum_pos_loss+=result[1];\n",
        "        cum_neg_loss+=result[2];\n",
        "        frm+=VALIDATION_BATCH_SIZE;\n",
        "        progressBar(frm,n_val,['loss','pos_loss','neg_loss'],[result[0],result[1],result[2]]);\n",
        "      print('\\nVALIDATION || mean loss: {} | mean pos loss: {} | mean neg loss: {}'.format(cum_loss/n_batches,cum_pos_loss/n_batches,cum_neg_loss/n_batches))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "graph built\n",
            "beginning epoch: 0\n",
            "Percent: [------------------->][419328/419354] 100% ||  LOSS: 1.347870 | POS_LOSS: -42.829426 | NEG_LOSS: -43.725037 | \n",
            "TRAINING || mean loss: 1.5007738120972165 | mean pos loss: -30.98366159455389 | mean neg loss: -31.60083461360908\n",
            "Percent: [------------------->][104448/104838] 100% ||  LOSS: 1.362320 | POS_LOSS: -42.357773 | NEG_LOSS: -43.312511 | \n",
            "VALIDATION || mean loss: 1.3473800923310073 | mean pos loss: -42.29008655922085 | mean neg loss: -43.3003371369605\n",
            "beginning epoch: 1\n",
            "Percent: [------------------->][419328/419354] 100% ||  LOSS: 1.196759 | POS_LOSS: -64.893936 | NEG_LOSS: -66.125313 | \n",
            "TRAINING || mean loss: 1.3124471700526275 | mean pos loss: -54.25786472502209 | mean neg loss: -55.28275502383054\n",
            "Percent: [------------------->][104448/104838] 100% ||  LOSS: 1.275912 | POS_LOSS: -64.351746 | NEG_LOSS: -65.647896 | \n",
            "VALIDATION || mean loss: 1.2725302366649403 | mean pos loss: -64.27721831377815 | mean neg loss: -65.6181105071423\n",
            "beginning epoch: 2\n",
            "Percent: [------------------->][419328/419354] 100% ||  LOSS: 1.295288 | POS_LOSS: -81.521652 | NEG_LOSS: -82.726883 | \n",
            "TRAINING || mean loss: 1.2440571377420018 | mean pos loss: -73.63132904853867 | mean neg loss: -74.90580305162366\n",
            "Percent: [------------------->][104448/104838] 100% ||  LOSS: 1.274679 | POS_LOSS: -80.755058 | NEG_LOSS: -82.217575 | \n",
            "VALIDATION || mean loss: 1.2460162651305104 | mean pos loss: -80.68813338934207 | mean neg loss: -82.21911269543217\n",
            "beginning epoch: 3\n",
            "Percent: [------------------->][419328/419354] 100% ||  LOSS: 1.145794 | POS_LOSS: -94.712166 | NEG_LOSS: -96.206848 | \n",
            "TRAINING || mean loss: 1.2111265778323232 | mean pos loss: -88.37146465594952 | mean neg loss: -89.79990021329515\n",
            "Percent: [------------------->][104448/104838] 100% ||  LOSS: 1.279921 | POS_LOSS: -93.929420 | NEG_LOSS: -95.455154 | \n",
            "VALIDATION || mean loss: 1.234148712719188 | mean pos loss: -93.84589655259076 | mean neg loss: -95.4992961509555\n",
            "beginning epoch: 4\n",
            "Percent: [------------------->][419328/419354] 100% ||  LOSS: 1.192752 | POS_LOSS: -104.076035 | NEG_LOSS: -105.667419 | \n",
            "TRAINING || mean loss: 1.1898992305055207 | mean pos loss: -99.70428256266574 | mean neg loss: -101.25019219739679\n",
            "Percent: [------------------->][104448/104838] 100% ||  LOSS: 1.265137 | POS_LOSS: -103.290466 | NEG_LOSS: -105.025093 | \n",
            "VALIDATION || mean loss: 1.2290792839199889 | mean pos loss: -103.20065846162684 | mean neg loss: -104.97124533559762\n",
            "beginning epoch: 5\n",
            "Percent: [------------------->][419328/419354] 100% ||  LOSS: 1.144001 | POS_LOSS: -110.936020 | NEG_LOSS: -112.569641 | \n",
            "TRAINING || mean loss: 1.178482542471717 | mean pos loss: -107.97112346365047 | mean neg loss: -109.58724488851061\n",
            "Percent: [------------------->][104448/104838] 100% ||  LOSS: 1.295836 | POS_LOSS: -110.099167 | NEG_LOSS: -111.818985 | \n",
            "VALIDATION || mean loss: 1.2356891398336374 | mean pos loss: -109.98516606349571 | mean neg loss: -111.79785844391468\n",
            "beginning epoch: 6\n",
            "Percent: [------------->      ][299520/419354] 71% ||  LOSS: 1.116712 | POS_LOSS: -114.374863 | NEG_LOSS: -116.112915 | "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-8abdd48ca3e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m                                    \u001b[0mhyperQA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ans_bmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                                    \u001b[0mhyperQA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_ans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                                    hyperQA.neg_ans_bmask:z1})\n\u001b[0m\u001b[1;32m     59\u001b[0m       \u001b[0mcum_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m       \u001b[0mcum_pos_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "FAFtgzOG47ch",
        "colab_type": "code",
        "outputId": "a26b3d22-2e5a-4971-fb7a-78a531f23548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "cell_type": "code",
      "source": [
        "# args\n",
        "MARGIN = 2.0;\n",
        "LEARNING_RATE = 0.001;\n",
        "#QL_MAX = 15;\n",
        "#PL_MAX = 300;\n",
        "TRAINING_BATCH_SIZE = 256;\n",
        "VALIDATION_BATCH_SIZE = 1024;\n",
        "VALIDATION_EVERY = 1;\n",
        "N_EPOCHS = 100;\n",
        "START_EPOCH = 9;\n",
        "RESUME_TRAINING = True;\n",
        "\n",
        "\n",
        "# Create a graph with above connections\n",
        "tf.reset_default_graph();\n",
        "hyperQA_Graph = tf.Graph();\n",
        "with hyperQA_Graph.as_default():\n",
        "  hyperQA = HyperQA(dfg.as_matrix(), EMB_DIMS, PROJ_DIMS, MARGIN, LEARNING_RATE)\n",
        "  print('graph built')\n",
        "  \n",
        "# epochs\n",
        "with tf.Session(graph=hyperQA_Graph) as sess:\n",
        "  saver = tf.train.Saver();\n",
        "  if not RESUME_TRAINING:\n",
        "    sess.run(tf.global_variables_initializer());\n",
        "    START_EPOCH = 0;\n",
        "  else:\n",
        "    saver.restore(sess, './new_model/epoch_model_{}.ckpt'.format(START_EPOCH-1));\n",
        "  for epoch in np.arange(START_EPOCH, N_EPOCHS):\n",
        "    # Loss and optimization on Training Data\n",
        "    print('beginning epoch: {}'.format(epoch));\n",
        "    n_batches = int(np.floor(n_train/TRAINING_BATCH_SIZE));\n",
        "    cum_loss = 0;\n",
        "    cum_pos_loss = 0;\n",
        "    cum_neg_loss = 0;\n",
        "    frm=0;\n",
        "    for i in range(n_batches):\n",
        "      batch_query_ids = training_query_ids[frm:frm+TRAINING_BATCH_SIZE];\n",
        "      batch_queries = [];\n",
        "      batch_pos = [];\n",
        "      batch_neg = [];\n",
        "      for query_id in batch_query_ids:\n",
        "        if 'pos' in data_dict[query_id].keys():\n",
        "          batch_queries.append(data_dict[query_id]['query']);\n",
        "          batch_pos.append(id2passage[data_dict[query_id]['pos']]);\n",
        "          j = np.random.choice(len(data_dict[query_id]['negs']));\n",
        "          batch_neg.append(id2passage[data_dict[query_id]['negs'][j]]);\n",
        "      x, x1 = make_batch_data(batch_queries,infer_max_len=True)\n",
        "      y, y1 = make_batch_data(batch_pos,infer_max_len=True) \n",
        "      z, z1 = make_batch_data(batch_neg,infer_max_len=True)\n",
        "      result = sess.run([hyperQA.train_op, hyperQA.print_losses, hyperQA.print_p_score_loss, hyperQA.print_n_score_loss],\n",
        "                        feed_dict={hyperQA.keep_prob: 0.75,\n",
        "                                   hyperQA.reg_lambda: 0.00003,\n",
        "                                   hyperQA.query:x,\n",
        "                                   hyperQA.query_bmask:x1,\n",
        "                                   hyperQA.pos_ans:y,\n",
        "                                   hyperQA.pos_ans_bmask:y1,\n",
        "                                   hyperQA.neg_ans:z,\n",
        "                                   hyperQA.neg_ans_bmask:z1})\n",
        "      cum_loss+=result[1];\n",
        "      cum_pos_loss+=result[2];\n",
        "      cum_neg_loss+=result[3];\n",
        "      frm+=TRAINING_BATCH_SIZE;\n",
        "      progressBar(frm,n_train,['loss','pos_loss','neg_loss'],[result[1],result[2],result[3]]);\n",
        "    print('\\nTRAINING || mean loss: {} | mean pos loss: {} | mean neg loss: {}'.format(cum_loss/n_batches,cum_pos_loss/n_batches,cum_neg_loss/n_batches))\n",
        "    saver.save(sess, './new_model/epoch_model_{}.ckpt'.format(epoch));\n",
        "    # Loss on Validation Data\n",
        "    if epoch%VALIDATION_EVERY==0:\n",
        "      #saver = tf.train.Saver();\n",
        "      #saver.restore(val_sess, './new_model/epoch_model_20.ckpt');\n",
        "      n_batches = int(np.floor(n_val/VALIDATION_BATCH_SIZE));\n",
        "      cum_loss = 0;\n",
        "      cum_pos_loss = 0;\n",
        "      cum_neg_loss = 0;\n",
        "      frm=0;\n",
        "      for i in range(n_batches):\n",
        "        batch_query_ids = validation_query_ids[frm:frm+VALIDATION_BATCH_SIZE];\n",
        "        batch_queries = [];\n",
        "        batch_pos = [];\n",
        "        batch_neg = [];\n",
        "        for query_id in batch_query_ids:\n",
        "          if 'pos' in data_dict[query_id].keys():\n",
        "            batch_queries.append(data_dict[query_id]['query']);\n",
        "            batch_pos.append(id2passage[data_dict[query_id]['pos']]);\n",
        "            j = np.random.choice(len(data_dict[query_id]['negs']));\n",
        "            batch_neg.append(id2passage[data_dict[query_id]['negs'][j]]);\n",
        "        x, x1 = make_batch_data(batch_queries,infer_max_len=True)\n",
        "        y, y1 = make_batch_data(batch_pos,infer_max_len=True) \n",
        "        z, z1 = make_batch_data(batch_neg,infer_max_len=True)\n",
        "        result = sess.run([hyperQA.print_losses, hyperQA.print_p_score_loss, hyperQA.print_n_score_loss],\n",
        "                          feed_dict={hyperQA.keep_prob:1.0,\n",
        "                                     hyperQA.query:x,\n",
        "                                     hyperQA.query_bmask:x1,\n",
        "                                     hyperQA.pos_ans:y,\n",
        "                                     hyperQA.pos_ans_bmask:y1,\n",
        "                                     hyperQA.neg_ans:z,\n",
        "                                     hyperQA.neg_ans_bmask:z1})\n",
        "        cum_loss+=result[0];\n",
        "        cum_pos_loss+=result[1];\n",
        "        cum_neg_loss+=result[2];\n",
        "        frm+=VALIDATION_BATCH_SIZE;\n",
        "        progressBar(frm,n_val,['loss','pos_loss','neg_loss'],[result[0],result[1],result[2]]);\n",
        "      print('\\nVALIDATION || mean loss: {} | mean pos loss: {} | mean neg loss: {}'.format(cum_loss/n_batches,cum_pos_loss/n_batches,cum_neg_loss/n_batches))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "graph built\n",
            "INFO:tensorflow:Restoring parameters from ./new_model/epoch_model_8.ckpt\n",
            "beginning epoch: 9\n",
            "Percent: [------------------->][419328/419354] 100% ||  LOSS: 1.155277 | POS_LOSS: -141.729645 | NEG_LOSS: -143.497879 | \n",
            "TRAINING || mean loss: 1.1852229673128862 | mean pos loss: -138.66556055350765 | mean neg loss: -140.25747811081064\n",
            "Percent: [------------------->][104448/104838] 100% ||  LOSS: 1.354126 | POS_LOSS: -138.989944 | NEG_LOSS: -140.999435 | \n",
            "VALIDATION || mean loss: 1.251983283781538 | mean pos loss: -138.89062873989928 | mean neg loss: -141.10842715992646\n",
            "beginning epoch: 10\n",
            "Percent: [------------------->][419328/419354] 100% ||  LOSS: 1.174914 | POS_LOSS: -145.352341 | NEG_LOSS: -147.121872 | \n",
            "TRAINING || mean loss: 1.1769780606868356 | mean pos loss: -143.69969574086394 | mean neg loss: -145.34281351278116\n",
            "Percent: [------------------->][104448/104838] 100% ||  LOSS: 1.330918 | POS_LOSS: -142.462006 | NEG_LOSS: -144.559601 | \n",
            "VALIDATION || mean loss: 1.2544198807548075 | mean pos loss: -142.37324419208602 | mean neg loss: -144.62263473809935\n",
            "beginning epoch: 11\n",
            "Percent: [---------->         ][231168/419354] 55% ||  LOSS: 1.230650 | POS_LOSS: -146.336670 | NEG_LOSS: -147.861084 | "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-224526cb1f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m           \u001b[0mbatch_neg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid2passage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'negs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_queries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfer_max_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfer_max_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m       \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfer_max_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       result = sess.run([hyperQA.train_op, hyperQA.print_losses, hyperQA.print_p_score_loss, hyperQA.print_n_score_loss],\n",
            "\u001b[0;32m<ipython-input-2-a34a33829b2e>\u001b[0m in \u001b[0;36mmake_batch_data\u001b[0;34m(batch, infer_max_len, max_len)\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mcstrg\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUNKNOWN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcstrg_len_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mcstrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mUNKNOWN\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcstrg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mbmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mUNKNOWN\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcstrg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mcstrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcstrg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcstrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-a34a33829b2e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mcstrg\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUNKNOWN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcstrg_len_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mcstrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mUNKNOWN\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcstrg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mbmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mUNKNOWN\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcstrg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mcstrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcstrg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcstrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "PNWGQgpj3AgS",
        "colab_type": "code",
        "outputId": "e764f796-abe3-4832-a7b7-3ab5e64e35d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# args\n",
        "EVAL_BATCH_SIZE = 1024;\n",
        "\n",
        "# load data\n",
        "df_test = pd.read_csv(\"eval1_unlabelled.tsv\", sep= '\\t', header=None)\n",
        "print('Eval Data Loaded.')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eval Data Loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YwGZqV6uwdvr",
        "colab_type": "code",
        "outputId": "9df301d8-2a20-47e4-845e-7ba52e7753aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "outputs = [];\n",
        "\n",
        "# get scores\n",
        "with tf.Session(graph=hyperQA_Graph) as sess:\n",
        "  saver = tf.train.Saver();\n",
        "  saver.restore(sess, r'./new_model/epoch_model_6.ckpt');\n",
        "  for i, row in df_test.iterrows():\n",
        "    if i==0:\n",
        "      batch_queries = [];\n",
        "      batch_passages = [];\n",
        "      batch_ql_max = -1;\n",
        "      batch_pl_max = -1;\n",
        "    if i!=0 and i%EVAL_BATCH_SIZE==0:\n",
        "      x, x1 = make_batch_data(batch_queries,infer_max_len=True);\n",
        "      y, y1 = make_batch_data(batch_passages,infer_max_len=True);\n",
        "      result = sess.run([hyperQA.p_score],feed_dict={hyperQA.keep_prob: 1.0,\n",
        "                                                     hyperQA.query:x,\n",
        "                                                     hyperQA.query_bmask:x1,\n",
        "                                                     hyperQA.pos_ans:y,\n",
        "                                                     hyperQA.pos_ans_bmask:y1})\n",
        "      outputs.append(result[0].tolist());\n",
        "      progressBar(i,df_test.shape[0]);\n",
        "      batch_queries = [];\n",
        "      batch_passages = [];\n",
        "      batch_ql_max = -1;\n",
        "      batch_pl_max = -1;\n",
        "    query, passage = row[1], row[2];\n",
        "    batch_queries.append(query);\n",
        "    batch_passages.append(passage);\n",
        "  if batch_queries:\n",
        "    x, x1 = make_batch_data(batch_queries,infer_max_len=True);\n",
        "    y, y1 = make_batch_data(batch_passages,infer_max_len=True);\n",
        "    result = sess.run([hyperQA.p_score],feed_dict={hyperQA.keep_prob: 1.0,\n",
        "                                                   hyperQA.query:x,\n",
        "                                                   hyperQA.query_bmask:x1,\n",
        "                                                   hyperQA.pos_ans:y,\n",
        "                                                   hyperQA.pos_ans_bmask:y1})\n",
        "    outputs.append(result[0].tolist());\n",
        "    progressBar(i,df_test.shape[0]);\n",
        "    batch_queries = [];\n",
        "    batch_passages = [];\n",
        "    batch_ql_max = -1;\n",
        "    batch_pl_max = -1;"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./new_model/epoch_model_6.ckpt\n",
            "Percent: [------------------->][104169/104170] 100% ||  : -1.000000 | "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bQbYvqBQ-4BZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "outputs = np.vstack(outputs)\n",
        "df_test['pred'] = outputs; # the smaller the score, the more positive_answer it is"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5_ns9RMjB62",
        "colab_type": "code",
        "outputId": "335de526-5ce1-4540-87af-5a2277d9f62e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# re-using code from Dileep\n",
        "\n",
        "outfilename = 'answer.tsv'\n",
        "with open(outfilename,\"w\",encoding=\"utf-8\") as fw:\n",
        "  import math\n",
        "  linelist = []\n",
        "  tempscores = []\n",
        "  for idx, row in tqdm(df_test.iterrows()):\n",
        "      tempscores.append(row['pred'])\n",
        "      #tempscores.append(str(row['pred']))\n",
        "      if((idx +1)%10==0):\n",
        "          tempscores-=np.min(tempscores);\n",
        "          tempscores = [math.exp(s) for s in tempscores];\n",
        "          expsum = sum(tempscores)\n",
        "          tempscores = [str(s/expsum) for s in tempscores]\n",
        "          scoreString = \"\\t\".join(tempscores)\n",
        "          qid = str(row[0])\n",
        "          fw.write(qid+\"\\t\"+scoreString+\"\\n\")\n",
        "          tempscores=[]\n",
        "      #if(idx%10000==0):\n",
        "      #    print(idx)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104170it [00:09, 10517.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "I33QMqEwh_Kv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "TRAINING_BATCH_SIZE = 128;\n",
        "N_EPOCHS = 1;\n",
        "\n",
        "# Training\n",
        "with tf.Session(graph=hyperQA_Graph) as sess:\n",
        "  # Init weights and biases\n",
        "  saver = tf.train.Saver();\n",
        "  sess.run(tf.global_variables_initializer());\n",
        "  # Obtain bathces and perform loss_optimization\n",
        "  # np.random.shuffle(training_query_ids)\n",
        "  total_batches = 0;\n",
        "  for epoch in range(N_EPOCHS):\n",
        "    print('beginning epoch: {}'.format(epoch));\n",
        "    n_batches = 0;\n",
        "    cum_loss = 0;\n",
        "    frm = 0;\n",
        "    while(frm<n_train):\n",
        "      batch_query_ids = training_query_ids[frm:frm+TRAINING_BATCH_SIZE];\n",
        "      # make batch data for queries\n",
        "      ql_max = -1;\n",
        "      batch_queries = [];\n",
        "      for query_id in batch_query_ids:\n",
        "        batch_queries.append(data_dict[query_id]['query']);\n",
        "        if data_dict[query_id]['query_len']>ql_max:\n",
        "          ql_max = data_dict[query_id]['query_len'];\n",
        "      x, x1 = make_batch_data(batch_queries,ql_max)    \n",
        "      # make batch data for positives\n",
        "      pl_max = -1;\n",
        "      batch_pos = [];\n",
        "      for query_id in batch_query_ids:\n",
        "        batch_pos.append(id2passage[data_dict[query_id]['pos']]);\n",
        "        if data_dict[query_id]['pos_len']>pl_max:\n",
        "          pl_max = data_dict[query_id]['pos_len'];\n",
        "      y, y1 = make_batch_data(batch_pos,pl_max) \n",
        "      # select radom neatives and make batch data for negatives\n",
        "      nl_max = -1;\n",
        "      batch_neg = [];\n",
        "      for query_id in batch_query_ids:\n",
        "        j = np.random.choice(len(data_dict[query_id]['negs']));\n",
        "        batch_neg.append(id2passage[data_dict[query_id]['negs'][j]]);\n",
        "        if data_dict[query_id]['negs_len'][j]>nl_max:\n",
        "          nl_max = data_dict[query_id]['negs_len'][j];\n",
        "        z, z1 = make_batch_data(batch_neg,nl_max) \n",
        "      # run trains ops and print loss values\n",
        "      result = sess.run([hyperQA.train_op, hyperQA.print_losses, hyperQA.print_p_score_loss, hyperQA.print_n_score_loss],\n",
        "                        feed_dict={hyperQA.query:x,\n",
        "                                   hyperQA.query_bmask:x1,\n",
        "                                   hyperQA.pos_ans:y,\n",
        "                                   hyperQA.pos_ans_bmask:y1,\n",
        "                                   hyperQA.neg_ans:z,\n",
        "                                   hyperQA.neg_ans_bmask:z1})\n",
        "      # update frm\n",
        "      cum_loss+=result[1];\n",
        "      n_batches+=1;\n",
        "      total_batches+=1;\n",
        "      frm+=TRAINING_BATCH_SIZE;\n",
        "      progressBar(frm,n_train,['loss','pos_loss','neg_loss'],[result[1],result[2],result[3]]);\n",
        "      if total_batches%1000 and total_batches!=0:\n",
        "        saver.save(sess, './model_{}.ckpt'.format(total_batches));\n",
        "    # End of epoch\n",
        "    print('\\n');\n",
        "    print('Mean Loss: {}'.format(cum_loss/n_batches))\n",
        "    saver.save(sess, 'model_{}.ckpt'.format(epoch));\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oLsTADG74FQd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Baseline2_DL"
      ]
    },
    {
      "metadata": {
        "id": "bRvwFxaJjXJo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "!cp \"./Starting Kit/Baseline2_DL/readme.txt\" .\n",
        "!cp \"./Starting Kit/Baseline2_DL/PassageRanking.py\" .\n",
        "!cp \"./Starting Kit/Baseline2_DL/text2ctf.py\" .\n",
        "!cp \"./Starting Kit/evaluate.py\" .\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}