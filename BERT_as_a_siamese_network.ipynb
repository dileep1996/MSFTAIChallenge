{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT as a siamese network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "sLU0izgQU3vE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Save our data in a format understandable by HyperQA**"
      ]
    },
    {
      "metadata": {
        "id": "EA2uY88lU2nH",
        "colab_type": "code",
        "outputId": "ff68577b-d5c8-477a-87c8-7f848983f022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://competitions.codalab.org/my/datasets/download/69a3e8d0-b836-48b8-8795-36a6865a1c04"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-12 06:30:23--  https://competitions.codalab.org/my/datasets/download/69a3e8d0-b836-48b8-8795-36a6865a1c04\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 134.158.75.178\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|134.158.75.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/ec355/data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=7a300ad6357db7f6d03564d91a7a2b231349d587dcf46bfbbfff213833a12a60&X-Amz-Date=20181212T063018Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20181212%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2018-12-12 06:30:24--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/ec355/data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=7a300ad6357db7f6d03564d91a7a2b231349d587dcf46bfbbfff213833a12a60&X-Amz-Date=20181212T063018Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20181212%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 610505204 (582M) [application/zip]\n",
            "Saving to: ‘69a3e8d0-b836-48b8-8795-36a6865a1c04’\n",
            "\n",
            "69a3e8d0-b836-48b8- 100%[===================>] 582.22M  26.6MB/s    in 23s     \n",
            "\n",
            "2018-12-12 06:30:47 (25.5 MB/s) - ‘69a3e8d0-b836-48b8-8795-36a6865a1c04’ saved [610505204/610505204]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jrF0nHQmVa0N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv 69a3e8d0-b836-48b8-8795-36a6865a1c04 data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FNE9e-O5Vhfh",
        "colab_type": "code",
        "outputId": "d400f0ec-402b-4831-d108-9376ba880264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install zipfile36"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting zipfile36\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/8a/3b7da0b0bd87d1ef05b74207827c72d348b56a0d6d83242582be18a81e02/zipfile36-0.1.3-py3-none-any.whl\n",
            "Installing collected packages: zipfile36\n",
            "Successfully installed zipfile36-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "km_iDLqCVhiy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir msaic\n",
        "!mv data.zip msaic/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UbAPkPrBVhce",
        "colab_type": "code",
        "outputId": "1cfab594-80ba-4e2c-bae4-b9ce63bd832d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd msaic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/msaic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "55OSVNeLVoor",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zipref = zipfile.ZipFile('data.zip', 'r')\n",
        "zipref.extractall()\n",
        "zipref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ITF_RrByVosM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iaEviMZAveIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oWy73P4WVo8H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data.tsv\", sep= '\\t',header=None)\n",
        "df.columns = ['index','Question', 'Sentence', 'Label','seq']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ekM56qWgc0Fl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2B5BKtWEVpCG",
        "colab_type": "code",
        "outputId": "76e56d55-45b4-4068-c3af-880529aab50b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Question</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>A company is incorporated in a specific nation...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>Today, there is a growing community of more th...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>Corporation definition, an association of indi...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>Examples of corporation in a Sentence. 1  He w...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>1: a government-owned corporation (as a utilit...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                  Question  \\\n",
              "0    131  . what is a corporation?   \n",
              "1    131  . what is a corporation?   \n",
              "2    131  . what is a corporation?   \n",
              "3    131  . what is a corporation?   \n",
              "4    131  . what is a corporation?   \n",
              "\n",
              "                                            Sentence  Label  seq  \n",
              "0  A company is incorporated in a specific nation...      0    0  \n",
              "1  Today, there is a growing community of more th...      0    1  \n",
              "2  Corporation definition, an association of indi...      0    2  \n",
              "3  Examples of corporation in a Sentence. 1  He w...      0    3  \n",
              "4  1: a government-owned corporation (as a utilit...      0    4  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DZB633addR_h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WjdB8-jMbBVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unique_question_list = df.Question.unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ot75KibTWXQU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R5_XzQ2WZugB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rand_seed = 200\n",
        "import numpy as np\n",
        "np.random.seed(rand_seed)\n",
        "train_len = 20000\n",
        "dev_len = 4000\n",
        "idlist = np.arange(len(unique_question_list))\n",
        "np.random.shuffle(idlist)\n",
        "shuffled_questions = unique_question_list[idlist]\n",
        "train, dev = shuffled_questions[:train_len], shuffled_questions[train_len:train_len+dev_len],"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UBVGP3Jt8FAY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#shuffle df\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K9fhm8GMZuk9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_pos_neg(qdf, odf):\n",
        "    result = []\n",
        "    for item in qdf:\n",
        "      qs = odf[odf.Question == item]\n",
        "      pos = list(qs[qs.Label == 1][:1]['Sentence'])[0]\n",
        "      neg = list(qs[qs.Label == 0][:1]['Sentence'])[:1]\n",
        "      for i in neg:\n",
        "        result.append([item, pos, i])\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y9ed-_Is207y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "balHlJxCb02x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_list = get_pos_neg(train, df[df.Question.isin(train)])\n",
        "dev_list = get_pos_neg(dev, df[df.Question.isin(dev)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dXaZ9xjOb0xt",
        "colab_type": "code",
        "outputId": "49799f06-c617-41a2-ff8c-a9bbca27b626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "vpAtUlgSb0to",
        "colab_type": "code",
        "outputId": "9717a044-b6d1-4c3a-f60a-d104a4cbb599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "train_list[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what team did earl campbell play for',\n",
              " \"Running back Earl Campbell of the New Orleans Saints retired Monday after nine seasons in pro football. He ended his career with 9,407 yards rushing. I'm a man; I'm not a little boy, Campbell said during a news conference at the Saints' training camp in Hammond, La. I believe this is the best thing--not only for myself, but for the Saints.. Saints' Coach Jim Mora said: He's a cinch for the Hall of Fame.. Campbell, 31, spent six seasons with the Houston Oilers after winning the Heisman Trophy in 1977.\",\n",
              " 'In 1981 the legislature enshrined Earl Campbell as an Official State Hero Of Texas. Only three other favorite sons—Davy Crockett, Stephen F. Austin, and Sam Houston—had been previous recipients of that honor, so the proclamation was a fair measure of Campbell’s popularity and fame at the time.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "_g8PTWSOjzLq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d4QTcLc8jzd6",
        "colab_type": "code",
        "outputId": "4f45b4aa-29bc-4dba-e3c9-4ab39a9fc198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.2.0\n",
        "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "#!pip3 install allennlp\n",
        "!pip install tqdm\n",
        "#!pip install spacy\n",
        "#!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/6e/5084627fee802fa6a13741ff988e34f2d2ee25e8a6a276b4832f278c5654/Pillow-4.2.0-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.8MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.2.0) (0.46)\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed Pillow-4.2.0\n",
            "Collecting torch==0.4.1 from http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl (512.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 512.6MB 6.0MB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x57ce6000 @  0x7f290a0142a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AErqYBlKjza4",
        "colab_type": "code",
        "outputId": "0f67b1e3-152a-4511-96d4-03f553886f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert==0.2.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/24/47/057e7998e5ac9c9a1b1f1c5a65895accec23ed414ae264af7db4fe2d5b2f/pytorch_pretrained_bert-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.2.0) (1.9.62)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.2.0) (2.18.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.2.0) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.2.0) (1.14.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.2.0) (4.28.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.62 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.2.0) (1.12.62)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.2.0) (0.1.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.2.0) (0.9.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.2.0) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.2.0) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.2.0) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.2.0) (3.0.4)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->pytorch-pretrained-bert==0.2.0) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->pytorch-pretrained-bert==0.2.0) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.62->boto3->pytorch-pretrained-bert==0.2.0) (1.11.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yvE5x7n2jzIK",
        "colab_type": "code",
        "outputId": "a1ea9eb0-1b41-4cc4-c118-c13a559915c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dileep1996/pytorch-pretrained-BERT.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-pretrained-BERT'...\n",
            "remote: Enumerating objects: 1, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1)   \u001b[K\rremote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 922 (delta 0), reused 0 (delta 0), pack-reused 921\u001b[K\n",
            "Receiving objects: 100% (922/922), 543.08 KiB | 5.12 MiB/s, done.\n",
            "Resolving deltas: 100% (579/579), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E6ZF6tZNk0HM",
        "colab_type": "code",
        "outputId": "ffc254e9-315a-4c11-b416-673ce339e59f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd pytorch-pretrained-BERT/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/msaic/pytorch-pretrained-BERT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3IXqENOepoGI",
        "colab_type": "code",
        "outputId": "6d81cf08-3908-44fd-966c-210e0ff7bafc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/dileep1996/pytorch-pretrained-BERT\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RjnNrpz1k2hV",
        "colab_type": "code",
        "outputId": "9efefe55-f12a-42d0-8411-77c90cd728e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd examples/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/msaic/pytorch-pretrained-BERT/examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nPW5l6syk2vW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from run_classifier import InputExample, convert_examples_to_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wupb-GJAskA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nRoRV-VLk0CS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ques_training_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(train_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[0]\n",
        "  label = 0\n",
        "  ques_training_list.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "\n",
        "pos_training_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(train_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[1]\n",
        "  label = 0\n",
        "  pos_training_list.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "  \n",
        "neg_training_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(train_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[2]\n",
        "  label = 0\n",
        "  neg_training_list.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "\n",
        "pos_pair_training_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(train_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[0]\n",
        "  text_b = row[1]\n",
        "  label = 0\n",
        "  pos_pair_training_list.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "\n",
        "neg_pair_training_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(train_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[0]\n",
        "  text_b = row[2]\n",
        "  label = 0\n",
        "  neg_pair_training_list.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7s3cer3Jkz9v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ques_dev_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(dev_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[0]\n",
        "  label = 0\n",
        "  ques_dev_list.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "\n",
        "\n",
        "pos_dev_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(dev_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[1]\n",
        "  label = 0\n",
        "  pos_dev_list.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "  \n",
        "neg_dev_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(dev_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[2]\n",
        "  label = 0\n",
        "  neg_dev_list.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "\n",
        "pos_pair_dev_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(dev_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[0]\n",
        "  text_b = row[1]\n",
        "  label = 0\n",
        "  pos_pair_dev_list.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "\n",
        "neg_pair_dev_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(dev_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[0]\n",
        "  text_b = row[2]\n",
        "  label = 0\n",
        "  neg_pair_dev_list.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3XPZpLHA5qYV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JCxJZ5hmlqtV",
        "colab_type": "code",
        "outputId": "997708ed-7af3-4423-f3c2-a79ceb302f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "cell_type": "code",
      "source": [
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12/2018 06:41:27 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpo4jo63z5\n",
            "100%|██████████| 231508/231508 [00:00<00:00, 2534466.47B/s]\n",
            "12/12/2018 06:41:27 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpo4jo63z5 to cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/12/2018 06:41:27 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/12/2018 06:41:27 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpo4jo63z5\n",
            "12/12/2018 06:41:27 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8CB0C8R2l5Tm",
        "colab_type": "code",
        "outputId": "a7806270-bb9c-4cb9-ce18-9688f1ec82f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6465
        }
      },
      "cell_type": "code",
      "source": [
        "ques_training_features = convert_examples_to_features(ques_training_list, [0], 30, tokenizer)\n",
        "pos_training_features = convert_examples_to_features(pos_training_list, [0], 60, tokenizer)\n",
        "neg_training_features = convert_examples_to_features(neg_training_list, [0], 60, tokenizer)\n",
        "pos_pair_training_features = convert_examples_to_features(pos_pair_training_list, [0], 100, tokenizer)\n",
        "neg_pair_training_features = convert_examples_to_features(neg_pair_training_list, [0], 100, tokenizer)\n",
        "ques_dev_features = convert_examples_to_features(ques_dev_list, [0], 30, tokenizer)\n",
        "pos_dev_features = convert_examples_to_features(pos_dev_list, [0], 60, tokenizer)\n",
        "neg_dev_features = convert_examples_to_features(neg_dev_list, [0], 60, tokenizer)\n",
        "pos_pair_dev_features = convert_examples_to_features(pos_pair_dev_list, [0], 100, tokenizer)\n",
        "neg_pair_dev_features = convert_examples_to_features(neg_pair_dev_list, [0], 100, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12/2018 06:41:27 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   guid: train-0-0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   tokens: [CLS] you best way to clean paint brushes [SEP]\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   input_ids: 101 2017 2190 2126 2000 4550 6773 22569 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   guid: train-1-1\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   tokens: [CLS] what team did earl campbell play for [SEP]\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   input_ids: 101 2054 2136 2106 4656 6063 2377 2005 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   guid: train-2-2\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   tokens: [CLS] what is the original nu ##ma nu ##ma [SEP]\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   input_ids: 101 2054 2003 1996 2434 16371 2863 16371 2863 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   guid: train-3-3\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   tokens: [CLS] types of he ##pa ##to ##cellular car ##cino ##ma [SEP]\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   input_ids: 101 4127 1997 2002 4502 3406 16882 2482 21081 2863 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   guid: train-4-4\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   tokens: [CLS] what does do mean martial arts [SEP]\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   input_ids: 101 2054 2515 2079 2812 7761 2840 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:27 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   guid: train-0-0\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   tokens: [CLS] the best way to determine if there is any residual paint in the brush is to suspend it in a clear container after you think it is clean . use a string or thin wire through the hole at the end of the brush handle to suspend just the br ##istles in clean water . let it sit [SEP]\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   input_ids: 101 1996 2190 2126 2000 5646 2065 2045 2003 2151 21961 6773 1999 1996 8248 2003 2000 28324 2009 1999 1037 3154 11661 2044 2017 2228 2009 2003 4550 1012 2224 1037 5164 2030 4857 7318 2083 1996 4920 2012 1996 2203 1997 1996 8248 5047 2000 28324 2074 1996 7987 28738 1999 4550 2300 1012 2292 2009 4133 102\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   guid: train-1-1\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   tokens: [CLS] running back earl campbell of the new orleans saints retired monday after nine seasons in pro football . he ended his career with 9 , 407 yards rushing . i ' m a man ; i ' m not a little boy , campbell said during a news conference at the saints ' training camp in hammond , [SEP]\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   input_ids: 101 2770 2067 4656 6063 1997 1996 2047 5979 6586 3394 6928 2044 3157 3692 1999 4013 2374 1012 2002 3092 2010 2476 2007 1023 1010 28941 4210 8375 1012 1045 1005 1049 1037 2158 1025 1045 1005 1049 2025 1037 2210 2879 1010 6063 2056 2076 1037 2739 3034 2012 1996 6586 1005 2731 3409 1999 11309 1010 102\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   guid: train-2-2\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   tokens: [CLS] americas . 1 a popular video named nu ##ma nu ##ma originally posted on new ##grounds features a man named gary bro ##ls ##ma performing a lip - sync to the song while dancing . 2 in brazil , singer latino replaced all the lyrics to create his reviewed version of drag ##ost ##ea din te ##i ( [SEP]\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   input_ids: 101 10925 1012 1015 1037 2759 2678 2315 16371 2863 16371 2863 2761 6866 2006 2047 28951 2838 1037 2158 2315 5639 22953 4877 2863 4488 1037 5423 1011 26351 2000 1996 2299 2096 5613 1012 1016 1999 4380 1010 3220 7402 2999 2035 1996 4581 2000 3443 2010 8182 2544 1997 8011 14122 5243 11586 8915 2072 1006 102\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   guid: train-3-3\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   tokens: [CLS] his ##to ##logic classification is as follows : 1 he ##pa ##to ##cellular car ##cino ##ma ( hc ##c ; liver cell car ##cino ##ma ) . 2 fi ##bro ##lam ##ella ##r variant of hc ##c . 3 cho ##lang ##io ##car ##cino ##ma ( intra ##he ##pati ##c bile duct car ##cino ##ma ) . 4 [SEP]\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   input_ids: 101 2010 3406 27179 5579 2003 2004 4076 1024 1015 2002 4502 3406 16882 2482 21081 2863 1006 16731 2278 1025 11290 3526 2482 21081 2863 1007 1012 1016 10882 12618 10278 8411 2099 8349 1997 16731 2278 1012 1017 16480 25023 3695 10010 21081 2863 1006 26721 5369 24952 2278 23974 23245 2482 21081 2863 1007 1012 1018 102\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   guid: train-4-4\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   tokens: [CLS] although the term martial art has become associated with the fighting arts of eastern asia , it originally referred to the combat systems of europe as early as the 1550 ##s . the term is derived from latin , and means arts of mars , the roman god of war . [SEP]\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   input_ids: 101 2348 1996 2744 7761 2396 2038 2468 3378 2007 1996 3554 2840 1997 2789 4021 1010 2009 2761 3615 2000 1996 4337 3001 1997 2885 2004 2220 2004 1996 26245 2015 1012 1996 2744 2003 5173 2013 3763 1010 1998 2965 2840 1997 7733 1010 1996 3142 2643 1997 2162 1012 102 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:31 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   guid: train-0-0\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   tokens: [CLS] don ' t clean the brush with dish soap ; it will gum up the fe ##rr ##ule and br ##istles . and there ' s no need to ri ##nse the tool in fresh water . the more often you clean it with the soft ##ener solution , the better it gets . fabric soft ##ener coats [SEP]\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   input_ids: 101 2123 1005 1056 4550 1996 8248 2007 9841 7815 1025 2009 2097 16031 2039 1996 10768 12171 9307 1998 7987 28738 1012 1998 2045 1005 1055 2053 2342 2000 15544 12325 1996 6994 1999 4840 2300 1012 1996 2062 2411 2017 4550 2009 2007 1996 3730 24454 5576 1010 1996 2488 2009 4152 1012 8313 3730 24454 15695 102\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   guid: train-1-1\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   tokens: [CLS] in 1981 the legislature en ##sh ##rine ##d earl campbell as an official state hero of texas . only three other favorite sons — davy cr ##ock ##ett , stephen f . austin , and sam houston — had been previous recipients of that honor , so the proclamation was a fair measure of campbell ’ s popularity [SEP]\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   input_ids: 101 1999 3261 1996 6372 4372 4095 11467 2094 4656 6063 2004 2019 2880 2110 5394 1997 3146 1012 2069 2093 2060 5440 4124 1517 23255 13675 7432 6582 1010 4459 1042 1012 5899 1010 1998 3520 5395 1517 2018 2042 3025 15991 1997 2008 3932 1010 2061 1996 16413 2001 1037 4189 5468 1997 6063 1521 1055 6217 102\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   guid: train-2-2\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   tokens: [CLS] nu ##ma nu ##ma is in romanian . it is actually called drag ##ost ##ea din te ##i ( love from the linden trees ) . [SEP]\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   input_ids: 101 16371 2863 16371 2863 2003 1999 7056 1012 2009 2003 2941 2170 8011 14122 5243 11586 8915 2072 1006 2293 2013 1996 22066 3628 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   guid: train-3-3\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   tokens: [CLS] what is he ##pa ##to ##cellular car ##cino ##ma ? he ##pa ##to ##cellular car ##cino ##ma is a type of liver cancer that usually affects people whose liver ##s have been under extra strain for a long time because of infections , metabolic diseases or prolonged use of certain drugs , including : infections with viral hepatitis [SEP]\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   input_ids: 101 2054 2003 2002 4502 3406 16882 2482 21081 2863 1029 2002 4502 3406 16882 2482 21081 2863 2003 1037 2828 1997 11290 4456 2008 2788 13531 2111 3005 11290 2015 2031 2042 2104 4469 10178 2005 1037 2146 2051 2138 1997 15245 1010 21453 7870 2030 15330 2224 1997 3056 5850 1010 2164 1024 15245 2007 13434 28389 102\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   guid: train-4-4\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   tokens: [CLS] sometimes , training with one specific weapon will be considered a style of martial arts in its own right , which is especially the case in japanese martial arts with disciplines such as ken ##ju ##tsu and ken ##do ( sword ) , bo ##ju ##tsu ( staff ) , and ky ##ud ##o ( archery ) . [SEP]\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   input_ids: 101 2823 1010 2731 2007 2028 3563 5195 2097 2022 2641 1037 2806 1997 7761 2840 1999 2049 2219 2157 1010 2029 2003 2926 1996 2553 1999 2887 7761 2840 2007 12736 2107 2004 6358 9103 10422 1998 6358 3527 1006 4690 1007 1010 8945 9103 10422 1006 3095 1007 1010 1998 18712 6784 2080 1006 21383 1007 1012 102\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:41:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   guid: train-0-0\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   tokens: [CLS] you best way to clean paint brushes [SEP] the best way to determine if there is any residual paint in the brush is to suspend it in a clear container after you think it is clean . use a string or thin wire through the hole at the end of the brush handle to suspend just the br ##istles in clean water . let it sit in the water for about four hours . he best way to determine if there is any residual paint in the brush is to suspend it in a clear container after you [SEP]\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   input_ids: 101 2017 2190 2126 2000 4550 6773 22569 102 1996 2190 2126 2000 5646 2065 2045 2003 2151 21961 6773 1999 1996 8248 2003 2000 28324 2009 1999 1037 3154 11661 2044 2017 2228 2009 2003 4550 1012 2224 1037 5164 2030 4857 7318 2083 1996 4920 2012 1996 2203 1997 1996 8248 5047 2000 28324 2074 1996 7987 28738 1999 4550 2300 1012 2292 2009 4133 1999 1996 2300 2005 2055 2176 2847 1012 2002 2190 2126 2000 5646 2065 2045 2003 2151 21961 6773 1999 1996 8248 2003 2000 28324 2009 1999 1037 3154 11661 2044 2017 102\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   guid: train-1-1\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   tokens: [CLS] what team did earl campbell play for [SEP] running back earl campbell of the new orleans saints retired monday after nine seasons in pro football . he ended his career with 9 , 407 yards rushing . i ' m a man ; i ' m not a little boy , campbell said during a news conference at the saints ' training camp in hammond , la . i believe this is the best thing - - not only for myself , but for the saints . . saints ' coach jim mora said : he ' s [SEP]\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   input_ids: 101 2054 2136 2106 4656 6063 2377 2005 102 2770 2067 4656 6063 1997 1996 2047 5979 6586 3394 6928 2044 3157 3692 1999 4013 2374 1012 2002 3092 2010 2476 2007 1023 1010 28941 4210 8375 1012 1045 1005 1049 1037 2158 1025 1045 1005 1049 2025 1037 2210 2879 1010 6063 2056 2076 1037 2739 3034 2012 1996 6586 1005 2731 3409 1999 11309 1010 2474 1012 1045 2903 2023 2003 1996 2190 2518 1011 1011 2025 2069 2005 2870 1010 2021 2005 1996 6586 1012 1012 6586 1005 2873 3958 26821 2056 1024 2002 1005 1055 102\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   guid: train-2-2\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   tokens: [CLS] what is the original nu ##ma nu ##ma [SEP] americas . 1 a popular video named nu ##ma nu ##ma originally posted on new ##grounds features a man named gary bro ##ls ##ma performing a lip - sync to the song while dancing . 2 in brazil , singer latino replaced all the lyrics to create his reviewed version of drag ##ost ##ea din te ##i ( the song still resembles the original one in rhythm and melody ) . [SEP]\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   input_ids: 101 2054 2003 1996 2434 16371 2863 16371 2863 102 10925 1012 1015 1037 2759 2678 2315 16371 2863 16371 2863 2761 6866 2006 2047 28951 2838 1037 2158 2315 5639 22953 4877 2863 4488 1037 5423 1011 26351 2000 1996 2299 2096 5613 1012 1016 1999 4380 1010 3220 7402 2999 2035 1996 4581 2000 3443 2010 8182 2544 1997 8011 14122 5243 11586 8915 2072 1006 1996 2299 2145 12950 1996 2434 2028 1999 6348 1998 8531 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   guid: train-3-3\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   tokens: [CLS] types of he ##pa ##to ##cellular car ##cino ##ma [SEP] his ##to ##logic classification is as follows : 1 he ##pa ##to ##cellular car ##cino ##ma ( hc ##c ; liver cell car ##cino ##ma ) . 2 fi ##bro ##lam ##ella ##r variant of hc ##c . 3 cho ##lang ##io ##car ##cino ##ma ( intra ##he ##pati ##c bile duct car ##cino ##ma ) . 4 mixed he ##pa ##to ##cellular cho ##lang ##io ##car ##cino ##ma . 5 und ##iff ##ere ##nti ##ated . he ##pa ##to ##bla ##sto ##ma . [SEP]\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   input_ids: 101 4127 1997 2002 4502 3406 16882 2482 21081 2863 102 2010 3406 27179 5579 2003 2004 4076 1024 1015 2002 4502 3406 16882 2482 21081 2863 1006 16731 2278 1025 11290 3526 2482 21081 2863 1007 1012 1016 10882 12618 10278 8411 2099 8349 1997 16731 2278 1012 1017 16480 25023 3695 10010 21081 2863 1006 26721 5369 24952 2278 23974 23245 2482 21081 2863 1007 1012 1018 3816 2002 4502 3406 16882 16480 25023 3695 10010 21081 2863 1012 1019 6151 13355 7869 16778 4383 1012 2002 4502 3406 28522 16033 2863 1012 102 0 0 0 0\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   guid: train-4-4\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   tokens: [CLS] what does do mean martial arts [SEP] although the term martial art has become associated with the fighting arts of eastern asia , it originally referred to the combat systems of europe as early as the 1550 ##s . the term is derived from latin , and means arts of mars , the roman god of war . [SEP]\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   input_ids: 101 2054 2515 2079 2812 7761 2840 102 2348 1996 2744 7761 2396 2038 2468 3378 2007 1996 3554 2840 1997 2789 4021 1010 2009 2761 3615 2000 1996 4337 3001 1997 2885 2004 2220 2004 1996 26245 2015 1012 1996 2744 2003 5173 2013 3763 1010 1998 2965 2840 1997 7733 1010 1996 3142 2643 1997 2162 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:24 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   guid: train-0-0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   tokens: [CLS] you best way to clean paint brushes [SEP] don ' t clean the brush with dish soap ; it will gum up the fe ##rr ##ule and br ##istles . and there ' s no need to ri ##nse the tool in fresh water . the more often you clean it with the soft ##ener solution , the better it gets . fabric soft ##ener coats the handle , fe ##rr ##ule , and br ##istles , allowing paint to flow effortlessly off the tool . . to dry your paint ##brush quickly , use a paint ##brush [SEP]\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   input_ids: 101 2017 2190 2126 2000 4550 6773 22569 102 2123 1005 1056 4550 1996 8248 2007 9841 7815 1025 2009 2097 16031 2039 1996 10768 12171 9307 1998 7987 28738 1012 1998 2045 1005 1055 2053 2342 2000 15544 12325 1996 6994 1999 4840 2300 1012 1996 2062 2411 2017 4550 2009 2007 1996 3730 24454 5576 1010 1996 2488 2009 4152 1012 8313 3730 24454 15695 1996 5047 1010 10768 12171 9307 1010 1998 7987 28738 1010 4352 6773 2000 4834 29483 2125 1996 6994 1012 1012 2000 4318 2115 6773 18623 2855 1010 2224 1037 6773 18623 102\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   guid: train-1-1\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   tokens: [CLS] what team did earl campbell play for [SEP] in 1981 the legislature en ##sh ##rine ##d earl campbell as an official state hero of texas . only three other favorite sons — davy cr ##ock ##ett , stephen f . austin , and sam houston — had been previous recipients of that honor , so the proclamation was a fair measure of campbell ’ s popularity and fame at the time . [SEP]\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   input_ids: 101 2054 2136 2106 4656 6063 2377 2005 102 1999 3261 1996 6372 4372 4095 11467 2094 4656 6063 2004 2019 2880 2110 5394 1997 3146 1012 2069 2093 2060 5440 4124 1517 23255 13675 7432 6582 1010 4459 1042 1012 5899 1010 1998 3520 5395 1517 2018 2042 3025 15991 1997 2008 3932 1010 2061 1996 16413 2001 1037 4189 5468 1997 6063 1521 1055 6217 1998 4476 2012 1996 2051 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   guid: train-2-2\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   tokens: [CLS] what is the original nu ##ma nu ##ma [SEP] nu ##ma nu ##ma is in romanian . it is actually called drag ##ost ##ea din te ##i ( love from the linden trees ) . [SEP]\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   input_ids: 101 2054 2003 1996 2434 16371 2863 16371 2863 102 16371 2863 16371 2863 2003 1999 7056 1012 2009 2003 2941 2170 8011 14122 5243 11586 8915 2072 1006 2293 2013 1996 22066 3628 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   guid: train-3-3\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   tokens: [CLS] types of he ##pa ##to ##cellular car ##cino ##ma [SEP] what is he ##pa ##to ##cellular car ##cino ##ma ? he ##pa ##to ##cellular car ##cino ##ma is a type of liver cancer that usually affects people whose liver ##s have been under extra strain for a long time because of infections , metabolic diseases or prolonged use of certain drugs , including : infections with viral hepatitis b or c . [SEP]\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   input_ids: 101 4127 1997 2002 4502 3406 16882 2482 21081 2863 102 2054 2003 2002 4502 3406 16882 2482 21081 2863 1029 2002 4502 3406 16882 2482 21081 2863 2003 1037 2828 1997 11290 4456 2008 2788 13531 2111 3005 11290 2015 2031 2042 2104 4469 10178 2005 1037 2146 2051 2138 1997 15245 1010 21453 7870 2030 15330 2224 1997 3056 5850 1010 2164 1024 15245 2007 13434 28389 1038 2030 1039 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   guid: train-4-4\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   tokens: [CLS] what does do mean martial arts [SEP] sometimes , training with one specific weapon will be considered a style of martial arts in its own right , which is especially the case in japanese martial arts with disciplines such as ken ##ju ##tsu and ken ##do ( sword ) , bo ##ju ##tsu ( staff ) , and ky ##ud ##o ( archery ) . [SEP]\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   input_ids: 101 2054 2515 2079 2812 7761 2840 102 2823 1010 2731 2007 2028 3563 5195 2097 2022 2641 1037 2806 1997 7761 2840 1999 2049 2219 2157 1010 2029 2003 2926 1996 2553 1999 2887 7761 2840 2007 12736 2107 2004 6358 9103 10422 1998 6358 3527 1006 4690 1007 1010 8945 9103 10422 1006 3095 1007 1010 1998 18712 6784 2080 1006 21383 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:42:55 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   guid: train-0-0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   tokens: [CLS] weather in geneva switzerland [SEP]\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_ids: 101 4633 1999 9810 5288 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   guid: train-1-1\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   tokens: [CLS] ve ##riz ##on lay ##off [SEP]\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_ids: 101 2310 21885 2239 3913 7245 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   guid: train-2-2\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   tokens: [CLS] provisional license cost online [SEP]\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_ids: 101 10864 6105 3465 3784 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   guid: train-3-3\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   tokens: [CLS] which type of food is stored in fungi [SEP]\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_ids: 101 2029 2828 1997 2833 2003 8250 1999 15289 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   guid: train-4-4\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   tokens: [CLS] define a heat stroke [SEP]\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_ids: 101 9375 1037 3684 6909 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   guid: train-0-0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   tokens: [CLS] geneva , switzerland yearly monthly weather averages . weekly weather report for geneva , switzerland . looking at the weather in geneva , switzerland over the next 7 days , the maximum temperature will be [UNK] ( or [UNK] ) on friday 14th april at around 12 pm . in the same week the minimum temperature will be [SEP]\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_ids: 101 9810 1010 5288 12142 7058 4633 20185 1012 4882 4633 3189 2005 9810 1010 5288 1012 2559 2012 1996 4633 1999 9810 1010 5288 2058 1996 2279 1021 2420 1010 1996 4555 4860 2097 2022 100 1006 2030 100 1007 2006 5958 6400 2258 2012 2105 2260 7610 1012 1999 1996 2168 2733 1996 6263 4860 2097 2022 102\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   guid: train-1-1\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   tokens: [CLS] ve ##riz ##on confirmed the lay ##offs in its it workforce , including in ve ##riz ##on data services india , but the local arm did not disclose the number of people asked to leave their jobs . the firm has a unit in bengal ##uru also . “ as ve ##riz ##on consolidate ##s its strategy , [SEP]\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_ids: 101 2310 21885 2239 4484 1996 3913 27475 1999 2049 2009 14877 1010 2164 1999 2310 21885 2239 2951 2578 2634 1010 2021 1996 2334 2849 2106 2025 26056 1996 2193 1997 2111 2356 2000 2681 2037 5841 1012 1996 3813 2038 1037 3131 1999 8191 14129 2036 1012 1523 2004 2310 21885 2239 24939 2015 2049 5656 1010 102\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   guid: train-2-2\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   tokens: [CLS] the fee for drivers applying for a provisional driving licence online will fall from £5 ##0 to £3 ##4 and online renewal ##s after 10 years will fall from £2 ##0 to £1 ##4 . the new fees , representing price cuts of up to 32 % , begin on 31 october . he fee for drivers applying [SEP]\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_ids: 101 1996 7408 2005 6853 11243 2005 1037 10864 4439 11172 3784 2097 2991 2013 27813 2692 2000 28182 2549 1998 3784 14524 2015 2044 2184 2086 2097 2991 2013 21853 2692 2000 14534 2549 1012 1996 2047 9883 1010 5052 3976 7659 1997 2039 2000 3590 1003 1010 4088 2006 2861 2255 1012 2002 7408 2005 6853 11243 102\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   guid: train-3-3\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   tokens: [CLS] the organisms in kingdom fungi include mushrooms , yeast ##s , mold ##s , rust ##s , sm ##uts , puff ##balls , tr ##uf ##fles , more ##ls , and mold ##s . more than 70 , 000 species of fungi have been identified . t he fungi constitute and independent group to that of plants and [SEP]\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_ids: 101 1996 11767 1999 2983 15289 2421 23827 1010 21957 2015 1010 18282 2015 1010 18399 2015 1010 15488 16446 1010 23893 18510 1010 19817 16093 28331 1010 2062 4877 1010 1998 18282 2015 1012 2062 2084 3963 1010 2199 2427 1997 15289 2031 2042 4453 1012 1056 2002 15289 12346 1998 2981 2177 2000 2008 1997 4264 1998 102\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   guid: train-4-4\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   tokens: [CLS] heat stroke , also known as sun stroke , is a severe heat illness , defined as hyper ##ther ##mia with a body temperature greater than 40 . 6 °c ( 105 . 1 °f ) because of environmental heat exposure with lack of the ##rm ##ore ##gul ##ation . this is distinct from a fever , where [SEP]\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_ids: 101 3684 6909 1010 2036 2124 2004 3103 6909 1010 2003 1037 5729 3684 7355 1010 4225 2004 23760 12399 10092 2007 1037 2303 4860 3618 2084 2871 1012 1020 6362 1006 8746 1012 1015 8157 1007 2138 1997 4483 3684 7524 2007 3768 1997 1996 10867 5686 24848 3370 1012 2023 2003 5664 2013 1037 9016 1010 2073 102\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:25 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   guid: train-0-0\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   tokens: [CLS] this page is best viewed in an up - to - date web browser with style sheets ( cs ##s ) enabled . while you will be able to view the content of this page in your current browser , you will not be able to get the full visual experience . please consider upgrading your browser software [SEP]\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   input_ids: 101 2023 3931 2003 2190 7021 1999 2019 2039 1011 2000 1011 3058 4773 16602 2007 2806 8697 1006 20116 2015 1007 9124 1012 2096 2017 2097 2022 2583 2000 3193 1996 4180 1997 2023 3931 1999 2115 2783 16602 1010 2017 2097 2025 2022 2583 2000 2131 1996 2440 5107 3325 1012 3531 5136 25925 2115 16602 4007 102\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   guid: train-1-1\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   tokens: [CLS] it ' s that exact attitude which is causing ve ##riz ##on to lose customers / money and resulting in these lay ##offs . their whole brand is around have better coverage than other carriers , hence why they charge more . [SEP]\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   input_ids: 101 2009 1005 1055 2008 6635 7729 2029 2003 4786 2310 21885 2239 2000 4558 6304 1013 2769 1998 4525 1999 2122 3913 27475 1012 2037 2878 4435 2003 2105 2031 2488 6325 2084 2060 11363 1010 6516 2339 2027 3715 2062 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   guid: train-2-2\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   tokens: [CLS] the costs of your provisional licence will depend on how you apply . 1 apply online and your provisional licence will cost £3 ##4 . 2 a postal application for the driving licence will be £ ##43 . om ##ple ##te a d ##1 application for a provisional driving licence available from the post office . alternately go [SEP]\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   input_ids: 101 1996 5366 1997 2115 10864 11172 2097 12530 2006 2129 2017 6611 1012 1015 6611 3784 1998 2115 10864 11172 2097 3465 28182 2549 1012 1016 1037 10690 4646 2005 1996 4439 11172 2097 2022 1069 23777 1012 18168 10814 2618 1037 1040 2487 4646 2005 1037 10864 4439 11172 2800 2013 1996 2695 2436 1012 23554 2175 102\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   guid: train-3-3\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   tokens: [CLS] it occurs in sap ##rot ##rop ##hs or het ##ero ##tro ##phs , and is most often associated with fungi ( for example mu ##cor ) and soil bacteria . sap ##rot ##rop ##hic microscopic fungi are sometimes called sap ##ro ##bes ; sap ##rot ##rop ##hic plants or bacterial flora are called sap ##rop ##hy ##tes ( [SEP]\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   input_ids: 101 2009 5158 1999 20066 21709 18981 7898 2030 21770 10624 13181 18757 1010 1998 2003 2087 2411 3378 2007 15289 1006 2005 2742 14163 27108 1007 1998 5800 10327 1012 20066 21709 18981 16066 26396 15289 2024 2823 2170 20066 3217 12681 1025 20066 21709 18981 16066 4264 2030 17341 10088 2024 2170 20066 18981 10536 4570 1006 102\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   guid: train-4-4\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   tokens: [CLS] definition of heats ##tro ##ke . : a life - threatening condition marked especially by ce ##ssa ##tion of sweating , extremely high body temperature , and collapse that results from prolonged exposure to high temperature — compare heat exhaustion , suns ##tro ##ke . [SEP]\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   input_ids: 101 6210 1997 18559 13181 3489 1012 1024 1037 2166 1011 8701 4650 4417 2926 2011 8292 11488 3508 1997 18972 1010 5186 2152 2303 4860 1010 1998 7859 2008 3463 2013 15330 7524 2000 2152 4860 1517 12826 3684 15575 1010 19352 13181 3489 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:31 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   guid: train-0-0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   tokens: [CLS] weather in geneva switzerland [SEP] geneva , switzerland yearly monthly weather averages . weekly weather report for geneva , switzerland . looking at the weather in geneva , switzerland over the next 7 days , the maximum temperature will be [UNK] ( or [UNK] ) on friday 14th april at around 12 pm . in the same week the minimum temperature will be - [UNK] ( or [UNK] ) on thursday 20th april at around 3 am . [SEP]\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   input_ids: 101 4633 1999 9810 5288 102 9810 1010 5288 12142 7058 4633 20185 1012 4882 4633 3189 2005 9810 1010 5288 1012 2559 2012 1996 4633 1999 9810 1010 5288 2058 1996 2279 1021 2420 1010 1996 4555 4860 2097 2022 100 1006 2030 100 1007 2006 5958 6400 2258 2012 2105 2260 7610 1012 1999 1996 2168 2733 1996 6263 4860 2097 2022 1011 100 1006 2030 100 1007 2006 9432 3983 2258 2012 2105 1017 2572 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   guid: train-1-1\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   tokens: [CLS] ve ##riz ##on lay ##off [SEP] ve ##riz ##on confirmed the lay ##offs in its it workforce , including in ve ##riz ##on data services india , but the local arm did not disclose the number of people asked to leave their jobs . the firm has a unit in bengal ##uru also . “ as ve ##riz ##on consolidate ##s its strategy , we can scale [SEP]\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   input_ids: 101 2310 21885 2239 3913 7245 102 2310 21885 2239 4484 1996 3913 27475 1999 2049 2009 14877 1010 2164 1999 2310 21885 2239 2951 2578 2634 1010 2021 1996 2334 2849 2106 2025 26056 1996 2193 1997 2111 2356 2000 2681 2037 5841 1012 1996 3813 2038 1037 3131 1999 8191 14129 2036 1012 1523 2004 2310 21885 2239 24939 2015 2049 5656 1010 2057 2064 4094 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   guid: train-2-2\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   tokens: [CLS] provisional license cost online [SEP] the fee for drivers applying for a provisional driving licence online will fall from £5 ##0 to £3 ##4 and online renewal ##s after 10 years will fall from £2 ##0 to £1 ##4 . the new fees , representing price cuts of up to 32 % , begin on 31 october . he fee for drivers applying for a provisional driving licence online will fall from £5 ##0 to £3 ##4 and online renewal ##s after 10 years will fall from £2 ##0 to £1 ##4 . [SEP]\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   input_ids: 101 10864 6105 3465 3784 102 1996 7408 2005 6853 11243 2005 1037 10864 4439 11172 3784 2097 2991 2013 27813 2692 2000 28182 2549 1998 3784 14524 2015 2044 2184 2086 2097 2991 2013 21853 2692 2000 14534 2549 1012 1996 2047 9883 1010 5052 3976 7659 1997 2039 2000 3590 1003 1010 4088 2006 2861 2255 1012 2002 7408 2005 6853 11243 2005 1037 10864 4439 11172 3784 2097 2991 2013 27813 2692 2000 28182 2549 1998 3784 14524 2015 2044 2184 2086 2097 2991 2013 21853 2692 2000 14534 2549 1012 102 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   guid: train-3-3\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   tokens: [CLS] which type of food is stored in fungi [SEP] the organisms in kingdom fungi include mushrooms , yeast ##s , mold ##s , rust ##s , sm ##uts , puff ##balls , tr ##uf ##fles , more ##ls , and mold ##s . more than 70 , 000 species of fungi have been identified . t he fungi constitute and independent group to that of plants and animals . the structure of cell wall is similar to plants but chemical ##ly the fungi cell wall are composed of chi ##tin . 2 fungi are het ##ero ##tro ##phic [SEP]\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   input_ids: 101 2029 2828 1997 2833 2003 8250 1999 15289 102 1996 11767 1999 2983 15289 2421 23827 1010 21957 2015 1010 18282 2015 1010 18399 2015 1010 15488 16446 1010 23893 18510 1010 19817 16093 28331 1010 2062 4877 1010 1998 18282 2015 1012 2062 2084 3963 1010 2199 2427 1997 15289 2031 2042 4453 1012 1056 2002 15289 12346 1998 2981 2177 2000 2008 1997 4264 1998 4176 1012 1996 3252 1997 3526 2813 2003 2714 2000 4264 2021 5072 2135 1996 15289 3526 2813 2024 3605 1997 9610 7629 1012 1016 15289 2024 21770 10624 13181 17926 102\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   guid: train-4-4\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   tokens: [CLS] define a heat stroke [SEP] heat stroke , also known as sun stroke , is a severe heat illness , defined as hyper ##ther ##mia with a body temperature greater than 40 . 6 °c ( 105 . 1 °f ) because of environmental heat exposure with lack of the ##rm ##ore ##gul ##ation . this is distinct from a fever , where there is a physiological increase in the temperature set point of the body . [SEP]\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   input_ids: 101 9375 1037 3684 6909 102 3684 6909 1010 2036 2124 2004 3103 6909 1010 2003 1037 5729 3684 7355 1010 4225 2004 23760 12399 10092 2007 1037 2303 4860 3618 2084 2871 1012 1020 6362 1006 8746 1012 1015 8157 1007 2138 1997 4483 3684 7524 2007 3768 1997 1996 10867 5686 24848 3370 1012 2023 2003 5664 2013 1037 9016 1010 2073 2045 2003 1037 19389 3623 1999 1996 4860 2275 2391 1997 1996 2303 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:36 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   guid: train-0-0\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   tokens: [CLS] weather in geneva switzerland [SEP] this page is best viewed in an up - to - date web browser with style sheets ( cs ##s ) enabled . while you will be able to view the content of this page in your current browser , you will not be able to get the full visual experience . please consider upgrading your browser software or enabling style sheets ( cs ##s ) if you are able to do so . [SEP]\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   input_ids: 101 4633 1999 9810 5288 102 2023 3931 2003 2190 7021 1999 2019 2039 1011 2000 1011 3058 4773 16602 2007 2806 8697 1006 20116 2015 1007 9124 1012 2096 2017 2097 2022 2583 2000 3193 1996 4180 1997 2023 3931 1999 2115 2783 16602 1010 2017 2097 2025 2022 2583 2000 2131 1996 2440 5107 3325 1012 3531 5136 25925 2115 16602 4007 2030 12067 2806 8697 1006 20116 2015 1007 2065 2017 2024 2583 2000 2079 2061 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   guid: train-1-1\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   tokens: [CLS] ve ##riz ##on lay ##off [SEP] it ' s that exact attitude which is causing ve ##riz ##on to lose customers / money and resulting in these lay ##offs . their whole brand is around have better coverage than other carriers , hence why they charge more . [SEP]\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   input_ids: 101 2310 21885 2239 3913 7245 102 2009 1005 1055 2008 6635 7729 2029 2003 4786 2310 21885 2239 2000 4558 6304 1013 2769 1998 4525 1999 2122 3913 27475 1012 2037 2878 4435 2003 2105 2031 2488 6325 2084 2060 11363 1010 6516 2339 2027 3715 2062 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   guid: train-2-2\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   tokens: [CLS] provisional license cost online [SEP] the costs of your provisional licence will depend on how you apply . 1 apply online and your provisional licence will cost £3 ##4 . 2 a postal application for the driving licence will be £ ##43 . om ##ple ##te a d ##1 application for a provisional driving licence available from the post office . alternately go online to d ##v ##la order forms and have the d ##1 form sent in the post . complete and return your application to d ##v ##la , you will need to include a photo [SEP]\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   input_ids: 101 10864 6105 3465 3784 102 1996 5366 1997 2115 10864 11172 2097 12530 2006 2129 2017 6611 1012 1015 6611 3784 1998 2115 10864 11172 2097 3465 28182 2549 1012 1016 1037 10690 4646 2005 1996 4439 11172 2097 2022 1069 23777 1012 18168 10814 2618 1037 1040 2487 4646 2005 1037 10864 4439 11172 2800 2013 1996 2695 2436 1012 23554 2175 3784 2000 1040 2615 2721 2344 3596 1998 2031 1996 1040 2487 2433 2741 1999 1996 2695 1012 3143 1998 2709 2115 4646 2000 1040 2615 2721 1010 2017 2097 2342 2000 2421 1037 6302 102\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   guid: train-3-3\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   tokens: [CLS] which type of food is stored in fungi [SEP] it occurs in sap ##rot ##rop ##hs or het ##ero ##tro ##phs , and is most often associated with fungi ( for example mu ##cor ) and soil bacteria . sap ##rot ##rop ##hic microscopic fungi are sometimes called sap ##ro ##bes ; sap ##rot ##rop ##hic plants or bacterial flora are called sap ##rop ##hy ##tes ( sap ##ro - + - ph ##yte , rotten material + plant ) . apr ##ot ##rop ##hic nutrition / [UNK] / [UNK] is a process of its che ##mo ##het [SEP]\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   input_ids: 101 2029 2828 1997 2833 2003 8250 1999 15289 102 2009 5158 1999 20066 21709 18981 7898 2030 21770 10624 13181 18757 1010 1998 2003 2087 2411 3378 2007 15289 1006 2005 2742 14163 27108 1007 1998 5800 10327 1012 20066 21709 18981 16066 26396 15289 2024 2823 2170 20066 3217 12681 1025 20066 21709 18981 16066 4264 2030 17341 10088 2024 2170 20066 18981 10536 4570 1006 20066 3217 1011 1009 1011 6887 17250 1010 11083 3430 1009 3269 1007 1012 19804 4140 18981 16066 14266 1013 100 1013 100 2003 1037 2832 1997 2049 18178 5302 27065 102\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   *** Example ***\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   guid: train-4-4\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   tokens: [CLS] define a heat stroke [SEP] definition of heats ##tro ##ke . : a life - threatening condition marked especially by ce ##ssa ##tion of sweating , extremely high body temperature , and collapse that results from prolonged exposure to high temperature — compare heat exhaustion , suns ##tro ##ke . [SEP]\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   input_ids: 101 9375 1037 3684 6909 102 6210 1997 18559 13181 3489 1012 1024 1037 2166 1011 8701 4650 4417 2926 2011 8292 11488 3508 1997 18972 1010 5186 2152 2303 4860 1010 1998 7859 2008 3463 2013 15330 7524 2000 2152 4860 1517 12826 3684 15575 1010 19352 13181 3489 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2018 06:43:42 - INFO - run_classifier -   label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QClNY2g-nki-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qav4k5BHl5fb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "qid1 = torch.tensor([f.input_ids for f in ques_training_features], dtype=torch.long)\n",
        "qtid1 = torch.tensor([f.input_mask for f in ques_training_features], dtype=torch.long)\n",
        "qmk1 = torch.tensor([f.segment_ids for f in ques_training_features], dtype=torch.long)\n",
        "\n",
        "pid1 = torch.tensor([f.input_ids for f in pos_training_features], dtype=torch.long)\n",
        "ptid1 = torch.tensor([f.input_mask for f in pos_training_features], dtype=torch.long)\n",
        "pmk1 = torch.tensor([f.segment_ids for f in pos_training_features], dtype=torch.long)\n",
        "\n",
        "nid1 = torch.tensor([f.input_ids for f in neg_training_features], dtype=torch.long)\n",
        "ntid1 = torch.tensor([f.input_mask for f in neg_training_features], dtype=torch.long)\n",
        "nmk1 = torch.tensor([f.segment_ids for f in neg_training_features], dtype=torch.long)\n",
        "\n",
        "ppid1 = torch.tensor([f.input_ids for f in pos_pair_training_features], dtype=torch.long)\n",
        "pptid1 = torch.tensor([f.input_mask for f in pos_pair_training_features], dtype=torch.long)\n",
        "ppmk1 = torch.tensor([f.segment_ids for f in pos_pair_training_features], dtype=torch.long)\n",
        "\n",
        "npid1 = torch.tensor([f.input_ids for f in neg_pair_training_features], dtype=torch.long)\n",
        "nptid1 = torch.tensor([f.input_mask for f in neg_pair_training_features], dtype=torch.long)\n",
        "npmk1 = torch.tensor([f.segment_ids for f in neg_pair_training_features], dtype=torch.long)\n",
        "\n",
        "train_data = TensorDataset(qid1,qtid1, qmk1, pid1, ptid1, pmk1, nid1, ntid1, nmk1, ppid1, pptid1, ppmk1, npid1, nptid1, npmk1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MumtzaMAl5x0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "qid2 = torch.tensor([f.input_ids for f in ques_dev_features], dtype=torch.long)\n",
        "qtid2 = torch.tensor([f.input_mask for f in ques_dev_features], dtype=torch.long)\n",
        "qmk2 = torch.tensor([f.segment_ids for f in ques_dev_features], dtype=torch.long)\n",
        "\n",
        "pid2 = torch.tensor([f.input_ids for f in pos_dev_features], dtype=torch.long)\n",
        "ptid2 = torch.tensor([f.input_mask for f in pos_dev_features], dtype=torch.long)\n",
        "pmk2 = torch.tensor([f.segment_ids for f in pos_dev_features], dtype=torch.long)\n",
        "\n",
        "nid2 = torch.tensor([f.input_ids for f in neg_dev_features], dtype=torch.long)\n",
        "ntid2 = torch.tensor([f.input_mask for f in neg_dev_features], dtype=torch.long)\n",
        "nmk2 = torch.tensor([f.segment_ids for f in neg_dev_features], dtype=torch.long)\n",
        "\n",
        "ppid2 = torch.tensor([f.input_ids for f in pos_pair_dev_features], dtype=torch.long)\n",
        "pptid2 = torch.tensor([f.input_mask for f in pos_pair_dev_features], dtype=torch.long)\n",
        "ppmk2 = torch.tensor([f.segment_ids for f in pos_pair_dev_features], dtype=torch.long)\n",
        "\n",
        "npid2 = torch.tensor([f.input_ids for f in neg_pair_dev_features], dtype=torch.long)\n",
        "nptid2 = torch.tensor([f.input_mask for f in neg_pair_dev_features], dtype=torch.long)\n",
        "npmk2 = torch.tensor([f.segment_ids for f in neg_pair_dev_features], dtype=torch.long)\n",
        "\n",
        "\n",
        "eval_data = TensorDataset(qid2, qtid2, qmk2, pid2, ptid2, pmk2, nid2, ntid2, nmk2, ppid2, pptid2, ppmk2, npid2, nptid2, npmk2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cou5NZrqtPkd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import logging\n",
        "import argparse\n",
        "import random\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "from pytorch_pretrained_bert.tokenization import printable_text, BertTokenizer\n",
        "from pytorch_pretrained_bert.modeling import PreTrainedBertModel, BertModel\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "\n",
        "import os\n",
        "import copy\n",
        "import json\n",
        "import math\n",
        "import logging\n",
        "import tarfile\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "from torch import optim\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, L1Loss\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "loss_fct = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ndZCfDvjw0DZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3EpHRMYftLly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BertForAnswerSelection(PreTrainedBertModel):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "\n",
        "    Params:\n",
        "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
        "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
        "\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
        "            with indices selected in [0, ..., num_labels].\n",
        "\n",
        "    Outputs:\n",
        "        if `labels` is not `None`:\n",
        "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
        "        if `labels` is `None`:\n",
        "            Outputs the classification logits.\n",
        "\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 2, 0]])\n",
        "    # Logits 1 is positive and 2 is negative\n",
        "    config = BertConfig(vocab_size=32000, hidden_size=512,\n",
        "        num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)\n",
        "\n",
        "    num_labels = 2\n",
        "\n",
        "    model = BertForAnswerSelection(config, num_labels)\n",
        "    logits = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels=2):\n",
        "        super(BertForAnswerSelection, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.fc1 = nn.Linear(2*config.hidden_size, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 1)\n",
        "        self.dist = F.pairwise_distance\n",
        "        self.apply(self.init_bert_weights)\n",
        "        self.margin = 2\n",
        "\n",
        "    def forward(self, qid, qtid, qmk, pid, ptid, pmk, nid, ntid, nmk):\n",
        "        _, ques_pooled_output = self.bert(qid, qtid, qmk, output_all_encoded_layers=False)\n",
        "        _, pos_pooled_output = self.bert(pid, ptid, pmk, output_all_encoded_layers=False)\n",
        "        _, neg_pooled_output = self.bert(nid, ntid, nmk, output_all_encoded_layers=False)\n",
        "        pos_dist = self.dist(ques_pooled_output, pos_pooled_output)\n",
        "        neg_dist = self.dist(ques_pooled_output, neg_pooled_output)\n",
        "        criterion1 = torch.log(Variable(torch.ones(pos_dist.size(0)).cuda()) + torch.exp(pos_dist - neg_dist))\n",
        "        err1 = torch.mean(criterion1)\n",
        "        #criterion = torch.max(Variable(torch.zeros(logits1.size(0)).cuda()), Variable(self.margin*torch.ones(logits1.size(0)).cuda()) + logits2 - logits1)\n",
        "        ques_pooled_output = self.dropout(ques_pooled_output)\n",
        "        pos_pooled_output = self.dropout(pos_pooled_output)\n",
        "        neg_pooled_output = self.dropout(neg_pooled_output)\n",
        "        pos_features = torch.cat((ques_pooled_output,pos_pooled_output),1)\n",
        "        neg_features = torch.cat((ques_pooled_output,neg_pooled_output),1)\n",
        "        lay11 = self.dropout(F.relu(self.fc1(pos_features)))\n",
        "        lay21 = self.dropout(F.relu(self.fc2(lay11)))\n",
        "        lay31 = self.fc3(lay21)\n",
        "\n",
        "        lay12 = self.dropout(F.relu(self.fc1(neg_features)))\n",
        "        lay22 = self.dropout(F.relu(self.fc2(lay12)))\n",
        "        lay32 = self.fc3(lay22)\n",
        "#        criterion2 = torch.log(Variable(torch.ones(lay32.size(0)).cuda()) + torch.exp(lay32 - lay31))        \n",
        "        err2 = torch.mean(loss_fct(torch.stack((lay31,lay32),1), Variable(torch.zeros(lay31.size(0),1).cuda().long())))\n",
        "        err = err2 + 0.1*err1# + torch.mean(criterion2) #+ 0.005*err2\n",
        "        return err, lay31, lay32\n",
        "\n",
        "    def pos_forward(self, qid, qtid, qmk, pid, ptid, pmt):\n",
        "        _, ques_pooled_output = self.bert(qid, qtid, qmk, output_all_encoded_layers=False)\n",
        "        _, pos_pooled_output = self.bert(pid, ptid, pmk, output_all_encoded_layers=False)\n",
        "        ques_pooled_output = self.dropout(ques_pooled_output)\n",
        "        pos_pooled_output = self.dropout(pos_pooled_output)\n",
        "        pos_features = torch.cat((ques_pooled_output,pos_pooled_output),1)\n",
        "        lay11 = self.dropout(F.relu(self.fc1(pos_features)))\n",
        "        lay21 = self.dropout(F.relu(self.fc2(lay11)))\n",
        "        lay31 = self.fc3(lay21)\n",
        "        return lay31\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eHP7DJMQsB7w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.random import choice, randint\n",
        "import torch as th\n",
        "from torch import nn\n",
        "from torch.autograd import Function, Variable\n",
        "from torch.utils.data import Dataset\n",
        "from collections import defaultdict as ddict\n",
        "\n",
        "eps = 1e-5\n",
        "\n",
        "\n",
        "class PoincareDistance1(Function):\n",
        "    boundary = 1 - eps\n",
        "\n",
        "    def grad(self, x, v, sqnormx, sqnormv, sqdist):\n",
        "        alpha = (1 - sqnormx)\n",
        "        beta = (1 - sqnormv)\n",
        "        z = 1 + 2 * sqdist / (alpha * beta)\n",
        "        a = ((sqnormv - 2 * th.sum(x * v, dim=-1) + 1) / th.pow(alpha, 2)).unsqueeze(-1).expand_as(x)\n",
        "        a = a * x - v / alpha.unsqueeze(-1).expand_as(v)\n",
        "        z = th.sqrt(th.pow(z, 2) - 1)\n",
        "        z = th.clamp(z * beta, min=eps).unsqueeze(-1)\n",
        "        return 4 * a / z.expand_as(x)\n",
        "\n",
        "    def forward(self, u, v):\n",
        "        self.save_for_backward(u, v)\n",
        "        self.squnorm = th.clamp(th.sum(u * u, dim=-1), 0, self.boundary)\n",
        "        self.sqvnorm = th.clamp(th.sum(v * v, dim=-1), 0, self.boundary)\n",
        "        self.sqdist = th.sum(th.pow(u - v, 2), dim=-1)\n",
        "        x = self.sqdist / ((1 - self.squnorm) * (1 - self.sqvnorm)) * 2 + 1\n",
        "        # arcosh\n",
        "        z = th.sqrt(th.pow(x, 2) - 1)\n",
        "        return th.log(x + z)\n",
        "\n",
        "    def backward(self, g):\n",
        "        u, v = self.saved_tensors\n",
        "        g = g.unsqueeze(-1)\n",
        "        gu = self.grad(u, v, self.squnorm, self.sqvnorm, self.sqdist)\n",
        "        gv = self.grad(v, u, self.sqvnorm, self.squnorm, self.sqdist)\n",
        "        return g.expand_as(gu) * gu, g.expand_as(gv) * gv\n",
        "\n",
        "class PoincareDistance2(Function):\n",
        "    boundary = 1 - eps\n",
        "\n",
        "    def grad(self, x, v, sqnormx, sqnormv, sqdist):\n",
        "        alpha = (1 - sqnormx)\n",
        "        beta = (1 - sqnormv)\n",
        "        z = 1 + 2 * sqdist / (alpha * beta)\n",
        "        a = ((sqnormv - 2 * th.sum(x * v, dim=-1) + 1) / th.pow(alpha, 2)).unsqueeze(-1).expand_as(x)\n",
        "        a = a * x - v / alpha.unsqueeze(-1).expand_as(v)\n",
        "        z = th.sqrt(th.pow(z, 2) - 1)\n",
        "        z = th.clamp(z * beta, min=eps).unsqueeze(-1)\n",
        "        return 4 * a / z.expand_as(x)\n",
        "\n",
        "    def forward(self, u, v):\n",
        "        self.save_for_backward(u, v)\n",
        "        self.squnorm = th.clamp(th.sum(u * u, dim=-1), 0, self.boundary)\n",
        "        self.sqvnorm = th.clamp(th.sum(v * v, dim=-1), 0, self.boundary)\n",
        "        self.sqdist = th.sum(th.pow(u - v, 2), dim=-1)\n",
        "        x = self.sqdist / ((1 - self.squnorm) * (1 - self.sqvnorm)) * 2 + 1\n",
        "        # arcosh\n",
        "        z = th.sqrt(th.pow(x, 2) - 1)\n",
        "        return th.log(x + z)\n",
        "\n",
        "    def backward(self, g):\n",
        "        u, v = self.saved_tensors\n",
        "        g = g.unsqueeze(-1)\n",
        "        gu = self.grad(u, v, self.squnorm, self.sqvnorm, self.sqdist)\n",
        "        gv = self.grad(v, u, self.sqvnorm, self.squnorm, self.sqdist)\n",
        "        return g.expand_as(gu) * gu, g.expand_as(gv) * gv\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mI-E7FrA25FI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BertForAnswerSelection2(PreTrainedBertModel):\n",
        "    def __init__(self, config, num_labels=2):\n",
        "        super(BertForAnswerSelection2, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.fc1 = nn.Linear(3*config.hidden_size, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 1)\n",
        "        self.dist = F.pairwise_distance\n",
        "        self.apply(self.init_bert_weights)\n",
        "        self.margin = 2\n",
        "#        for child in self.bert.children():\n",
        "#          for item in child.parameters():\n",
        "#              item.requires_grad = False\n",
        "              \n",
        "    def forward(self, qid, qtid, qmk, pid, ptid, pmk, nid, ntid, nmk, ppid, pptid, ppmk, npid, nptid, npmk):\n",
        "        _, ques_pooled_output = self.bert(qid, qtid, qmk, output_all_encoded_layers=False)\n",
        "        _, pos_pooled_output = self.bert(pid, ptid, pmk, output_all_encoded_layers=False)\n",
        "        _, neg_pooled_output = self.bert(nid, ntid, nmk, output_all_encoded_layers=False)\n",
        "        _, pair_pos_pooled_output = self.bert(ppid, pptid, ppmk, output_all_encoded_layers=False)\n",
        "        _, pair_neg_pooled_output = self.bert(npid, nptid, npmk, output_all_encoded_layers=False)\n",
        "        \n",
        " #       pos_dist = self.dist(ques_pooled_output, pos_pooled_output)\n",
        " #       neg_dist = self.dist(ques_pooled_output, neg_pooled_output)\n",
        " #       criterion1 = torch.log(Variable(torch.ones(pos_dist.size(0)).cuda()) + torch.exp(pos_dist - neg_dist))\n",
        "#        err1 = torch.mean(criterion1)\n",
        "        #criterion = torch.max(Variable(torch.zeros(logits1.size(0)).cuda()), Variable(self.margin*torch.ones(logits1.size(0)).cuda()) + logits2 - logits1)\n",
        "        pos_features = self.dropout(torch.cat((ques_pooled_output,pos_pooled_output, pair_pos_pooled_output),1))\n",
        "        neg_features = self.dropout(torch.cat((ques_pooled_output,neg_pooled_output, pair_neg_pooled_output),1))\n",
        "\n",
        "        lay11 = self.dropout(F.relu(self.fc1(pos_features)))\n",
        "        lay21 = self.dropout(F.relu(self.fc2(lay11)))\n",
        "        lay31 = self.fc3(lay21)\n",
        "\n",
        "        lay12 = self.dropout(F.relu(self.fc1(neg_features)))\n",
        "        lay22 = self.dropout(F.relu(self.fc2(lay12)))\n",
        "        lay32 = self.fc3(lay22)\n",
        "        criterion2 = torch.log(Variable(torch.ones(lay32.size(0)).cuda()) + torch.exp(lay32 - lay31))        \n",
        "        err2 = torch.mean(loss_fct(torch.stack((lay31,lay32),1), Variable(torch.zeros(lay31.size(0),1).cuda().long())))\n",
        "        err = torch.mean(criterion2) + err2#+ 0.1*err1# +  #\n",
        "        return err, lay31, lay32\n",
        "\n",
        "    def pos_forward(self, qid, qtid, qmk, pid, ptid, pmt):\n",
        "        _, ques_pooled_output = self.bert(qid, qtid, qmk, output_all_encoded_layers=False)\n",
        "        _, pos_pooled_output = self.bert(pid, ptid, pmk, output_all_encoded_layers=False)\n",
        "        ques_pooled_output = self.dropout(ques_pooled_output)\n",
        "        pos_pooled_output = self.dropout(pos_pooled_output)\n",
        "        pos_features = torch.cat((ques_pooled_output,pos_pooled_output),1)\n",
        "        lay11 = self.dropout(F.relu(self.fc1(pos_features)))\n",
        "        lay21 = self.dropout(F.relu(self.fc2(lay11)))\n",
        "        lay31 = self.fc3(lay21)\n",
        "        return lay31\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ydTqv3AtOZfP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SmblJaYrhbPW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPuBMtqUh0Ls",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#list(model.children())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_w4i4cN41Nx2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bert_model = 'bert-base-uncased'\n",
        "train_batch_size = 16\n",
        "learning_rate = 2e-5\n",
        "warmup_proportion = 0.1\n",
        "eval_batch_size = 4\n",
        "num_train_epochs = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KgjCNy2F3QJp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(logits1, logits2):\n",
        "    return np.sum(logits1 > logits2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j4eGHmk24Hrc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
        "eval_sampler = SequentialSampler(eval_data)\n",
        "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hKxOefFD_4RS",
        "colab_type": "code",
        "outputId": "33236132-cff6-4f49-e704-a087d3702172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = 1\n",
        "\n",
        "\n",
        "random.seed(200)\n",
        "np.random.seed(200)\n",
        "torch.manual_seed(200)\n",
        "torch.cuda.manual_seed_all(200)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "\n",
        "# Prepare model\n",
        "model = BertForAnswerSelection2.from_pretrained(bert_model)\n",
        "model.to(device)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "total_steps = int(len(train_dataloader)/train_batch_size/num_train_epochs)\n",
        "#optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "#optimizer = optim.Adagrad(model.parameters(), lr = learning_rate,weight_decay = 1e-2)\n",
        "optimizer = BertAdam(optimizer_grouped_parameters, lr=learning_rate, warmup=warmup_proportion)#, t_total=total_steps)\n",
        "#optimizer  = AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.99), weight_decay = 1e-6)\n",
        "global_step = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12/2018 06:43:50 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/12/2018 06:43:50 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpvtdgfz7f\n",
            "100%|██████████| 407873900/407873900 [00:09<00:00, 43535865.09B/s]\n",
            "12/12/2018 06:44:00 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpvtdgfz7f to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "12/12/2018 06:44:02 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "12/12/2018 06:44:02 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpvtdgfz7f\n",
            "12/12/2018 06:44:02 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "12/12/2018 06:44:02 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpt5yj25d9\n",
            "12/12/2018 06:44:07 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/12/2018 06:44:10 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForAnswerSelection2 not initialized from pretrained model: ['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']\n",
            "12/12/2018 06:44:10 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForAnswerSelection2: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OtBXzecIAdii",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Freeze bert first and train only the last layers\n",
        "\n",
        "bert = model.bert\n",
        "core_bert = list(bert.children())[1] # Everything except the embedding layer\n",
        "for item in core_bert.parameters():\n",
        "    item.requires_grad = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wUyWLr7KAFhK",
        "colab_type": "code",
        "outputId": "23b6764a-8b74-475c-c441-02f8bfe9879d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "# Training model\n",
        "model.train()\n",
        "tr_loss = 0\n",
        "nb_tr_examples, nb_tr_steps = 0, 0\n",
        "for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\", position = 0)):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    #input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2 = batch\n",
        "    loss, _, _ = model(*batch)#input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2)\n",
        "    loss.backward()\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += batch[0].size(0)\n",
        "    nb_tr_steps += 1\n",
        "    optimizer.step()\n",
        "    model.zero_grad()\n",
        "    global_step += 1\n",
        "\n",
        "# evaluating on validation set\n",
        "model.eval()\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "for batch in eval_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    with torch.no_grad():\n",
        "        tmp_eval_loss, logits1, logits2 = model(*batch)\n",
        "\n",
        "    logits1 = logits1.detach().cpu().numpy()\n",
        "    logits2 = logits2.detach().cpu().numpy()\n",
        "    tmp_eval_accuracy = accuracy(logits1, logits2)\n",
        "\n",
        "    eval_loss += tmp_eval_loss.item()\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    nb_eval_examples += batch[0].size(0)\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "eval_loss = eval_loss / nb_eval_steps\n",
        "eval_accuracy = eval_accuracy / nb_eval_examples\n",
        "\n",
        "result = {'eval_loss': eval_loss,\n",
        "          'eval_accuracy': eval_accuracy,\n",
        "          'global_step': global_step,\n",
        "          'loss': tr_loss/nb_tr_steps}\n",
        "\n",
        "output_eval_file = \"eval_results.txt\"\n",
        "print(result)\n",
        "torch.save(model, 'checkpoint' + str(eval_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1250/1250 [37:27<00:00,  1.80s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.2208125996291637, 'eval_accuracy': 0.6565, 'global_step': 1250, 'loss': 1.2562981333732606}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BertForAnswerSelection2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vp5pLJy1BpP4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bert = model.bert\n",
        "core_bert = list(bert.children())[1]\n",
        "for item in core_bert.parameters():\n",
        "    item.requires_grad = True\n",
        "\n",
        "\n",
        "core_bert = list(bert.children())[1] \n",
        "ct = 0\n",
        "for item in core_bert.parameters():\n",
        "  ct +=1\n",
        "  if ct < 130:\n",
        "    item.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bChrsQnA_4g-",
        "colab_type": "code",
        "outputId": "ca8848c0-a0f6-4d2f-a2a3-902adc1712fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "cell_type": "code",
      "source": [
        "for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
        "    # Training model\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\", position = 0)):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        #input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2 = batch\n",
        "        loss, _, _ = model(*batch)#input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2)\n",
        "        loss.backward()\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += batch[0].size(0)\n",
        "        nb_tr_steps += 1\n",
        "        optimizer.step()\n",
        "        model.zero_grad()\n",
        "        global_step += 1\n",
        "\n",
        "    # evaluating on validation set\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    for batch in eval_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss, logits1, logits2 = model(*batch)\n",
        "\n",
        "        logits1 = logits1.detach().cpu().numpy()\n",
        "        logits2 = logits2.detach().cpu().numpy()\n",
        "        tmp_eval_accuracy = accuracy(logits1, logits2)\n",
        "\n",
        "        eval_loss += tmp_eval_loss.item()\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        nb_eval_examples += batch[0].size(0)\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
        "\n",
        "    result = {'eval_loss': eval_loss,\n",
        "              'eval_accuracy': eval_accuracy,\n",
        "              'global_step': global_step,\n",
        "              'loss': tr_loss/nb_tr_steps}\n",
        "\n",
        "    output_eval_file = \"eval_results.txt\"\n",
        "    print(result)\n",
        "    torch.save(model, 'checkpoint' + str(eval_accuracy))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1250/1250 [41:54<00:00,  2.01s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.1192889479324222, 'eval_accuracy': 0.697, 'global_step': 2500, 'loss': 1.114076044178009}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BertForAnswerSelection2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "Iteration: 100%|██████████| 1250/1250 [41:57<00:00,  2.02s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.2335068007260561, 'eval_accuracy': 0.68525, 'global_step': 3750, 'loss': 0.9114067981004715}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:   5%|▌         | 66/1250 [02:13<39:44,  2.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-03eaa80cfa63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2 = batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-f9fa99dfa403>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, qid, qtid, qmk, pid, ptid, pmk, nid, ntid, nmk, ppid, pptid, ppmk, npid, nptid, npmk)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlay22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mlay32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mcriterion2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay32\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay32\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlay31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0merr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay31\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlay32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay31\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0merr2\u001b[0m\u001b[0;31m#+ 0.1*err1# +  #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6rt60I4x_4mH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xzD_OpFJl5u_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main(train_data = train_data, eval_data = eval_data):\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n_gpu = 1\n",
        "    \n",
        "\n",
        "    random.seed(200)\n",
        "    np.random.seed(200)\n",
        "    torch.manual_seed(200)\n",
        "    torch.cuda.manual_seed_all(200)\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "\n",
        "    # Prepare model\n",
        "    model = BertForAnswerSelection.from_pretrained(bert_model)\n",
        "    model.to(device)\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
        "        ]\n",
        "    total_steps = int(len(train_dataloader)/train_batch_size/num_train_epochs)\n",
        "    #optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "    #optimizer = optim.Adagrad(model.parameters(), lr = learning_rate,weight_decay = 1e-2)\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters, lr=learning_rate, warmup=warmup_proportion)#, t_total=total_steps)\n",
        "    #optimizer  = AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.99), weight_decay = 1e-6)\n",
        "    global_step = 0\n",
        "    if True:\n",
        "        for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
        "            # Training model\n",
        "            model.train()\n",
        "            tr_loss = 0\n",
        "            nb_tr_examples, nb_tr_steps = 0, 0\n",
        "            for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\", position = 0)):\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "                #input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2 = batch\n",
        "                loss, _, _ = model(*batch)#input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2)\n",
        "                loss.backward()\n",
        "                tr_loss += loss.item()\n",
        "                nb_tr_examples += batch[0].size(0)\n",
        "                nb_tr_steps += 1\n",
        "                optimizer.step()\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "            # evaluating on validation set\n",
        "            model.eval()\n",
        "            eval_loss, eval_accuracy = 0, 0\n",
        "            nb_eval_steps, nb_eval_examples = 0, 0\n",
        "            for batch in eval_dataloader:\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "                with torch.no_grad():\n",
        "                    tmp_eval_loss, logits1, logits2 = model(*batch)\n",
        "\n",
        "                logits1 = logits1.detach().cpu().numpy()\n",
        "                logits2 = logits2.detach().cpu().numpy()\n",
        "                tmp_eval_accuracy = accuracy(logits1, logits2)\n",
        "\n",
        "                eval_loss += tmp_eval_loss.item()\n",
        "                eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "                nb_eval_examples += batch[0].size(0)\n",
        "                nb_eval_steps += 1\n",
        "\n",
        "            eval_loss = eval_loss / nb_eval_steps\n",
        "            eval_accuracy = eval_accuracy / nb_eval_examples\n",
        "\n",
        "            result = {'eval_loss': eval_loss,\n",
        "                      'eval_accuracy': eval_accuracy,\n",
        "                      'global_step': global_step,\n",
        "                      'loss': tr_loss/nb_tr_steps}\n",
        "\n",
        "            output_eval_file = \"eval_results.txt\"\n",
        "            print(result)\n",
        "            torch.save(model, 'checkpoint' + str(eval_accuracy))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z1V-VrSKl5sA",
        "colab_type": "code",
        "outputId": "914b64eb-e6b8-4e9e-c2d0-e0e2f045dc51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/11/2018 05:06:49 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/11/2018 05:06:49 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "12/11/2018 05:06:49 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpj7x6nj4u\n",
            "12/11/2018 05:06:54 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/11/2018 05:06:58 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForAnswerSelection not initialized from pretrained model: ['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']\n",
            "12/11/2018 05:06:58 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForAnswerSelection: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "Iteration: 100%|██████████| 1000/1000 [20:13<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6216511135101318, 'eval_accuracy': 0.693, 'global_step': 1000, 'loss': 0.6452162100672721}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BertForAnswerSelection. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "Iteration: 100%|██████████| 1000/1000 [20:16<00:00,  1.22s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6326753741800785, 'eval_accuracy': 0.68925, 'global_step': 2000, 'loss': 0.5221087872236967}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1000/1000 [20:18<00:00,  1.22s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8135936195701361, 'eval_accuracy': 0.686, 'global_step': 3000, 'loss': 0.3571634153947234}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1000/1000 [20:18<00:00,  1.22s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.1974220558553934, 'eval_accuracy': 0.67775, 'global_step': 4000, 'loss': 0.18523352541588248}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch: 100%|██████████| 4/4 [1:29:30<00:00, 1342.40s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "v1K32Fdpe-Es",
        "colab_type": "code",
        "outputId": "6bc8dbdc-6081-4a53-d5d7-5a54dd6dfafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5509
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForAnswerSelection(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1)\n",
              "  (fc1): Linear(in_features=1536, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (fc3): Linear(in_features=100, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "metadata": {
        "id": "tBxVOk62IOYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = ''\n",
        "for item in eval_dataloader:\n",
        "  a = item\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YYVYIz6nIOTw",
        "colab_type": "code",
        "outputId": "49eb2759-c8a2-4df9-d7b6-9469035e955c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5472
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torch.load(\"checkpoint0.65\")\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForAnswerSelection(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "5vjn7iKvDnF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch = tuple(t.to(device) for t in a)\n",
        "input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2 = batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wg9BeZPMl5o_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "err, l1, l2 = model(input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HvTKTW8El5cb",
        "colab_type": "code",
        "outputId": "3698fbbe-df3a-4f6a-8ece-c4695c3a6639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "model.pos_forward(input_ids2, input_mask2, segment_ids2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.3791],\n",
              "        [ 0.7406],\n",
              "        [ 1.4084],\n",
              "        [ 3.8159],\n",
              "        [ 0.5862],\n",
              "        [-0.9376],\n",
              "        [ 2.7582],\n",
              "        [ 2.3178]], device='cuda:0', grad_fn=<ThAddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "fYBWO0UaJaWG",
        "colab_type": "code",
        "outputId": "521cd97b-b4bb-4fad-cfc7-d1684164990a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "l2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.3791],\n",
              "        [ 0.7406],\n",
              "        [ 1.4084],\n",
              "        [ 3.8159],\n",
              "        [ 0.5862],\n",
              "        [-0.9376],\n",
              "        [ 2.7582],\n",
              "        [ 2.3178]], device='cuda:0', grad_fn=<ThAddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "MB8Tna3DJaRu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lJQcnX2VXlEk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = torch.log(Variable(torch.ones(logits1.size(0)).cuda()) + torch.exp(logits2 - logits1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QSZwKvizJZ0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugEruqvQexsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JNLto9X-ZjdE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "l1 = torch.Tensor([1, 3])\n",
        "l2 = torch.Tensor([100, 100])\n",
        "out = torch.stack((l1,l2),1)\n",
        "labels = torch.zeros(out.size(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5kDb6-RMb6S1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bui1YfFLb6YW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UcHc7gsOb6Nc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "class AdamW(Optimizer):\n",
        "    \"\"\"Implements Adam algorithm.\n",
        "    It has been proposed in `Adam: A Method for Stochastic Optimization`_.\n",
        "    Arguments:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float, optional): learning rate (default: 1e-3)\n",
        "        betas (Tuple[float, float], optional): coefficients used for computing\n",
        "            running averages of gradient and its square (default: (0.9, 0.999))\n",
        "        eps (float, optional): term added to the denominator to improve\n",
        "            numerical stability (default: 1e-8)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n",
        "            algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
        "    .. _Adam\\: A Method for Stochastic Optimization:\n",
        "        https://arxiv.org/abs/1412.6980\n",
        "    .. _On the Convergence of Adam and Beyond:\n",
        "        https://openreview.net/forum?id=ryQu7f-RZ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
        "                 weight_decay=0, amsgrad=False):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay, amsgrad=amsgrad)\n",
        "        super(AdamW, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(AdamW, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('amsgrad', False)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
        "                amsgrad = group['amsgrad']\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "                    if amsgrad:\n",
        "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
        "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                if amsgrad:\n",
        "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                # if group['weight_decay'] != 0:\n",
        "                #     grad = grad.add(group['weight_decay'], p.data)\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                if amsgrad:\n",
        "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
        "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
        "                    # Use the max. for normalizing running avg. of gradient\n",
        "                    denom = max_exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                else:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "\n",
        "                bias_correction1 = 1 - beta1 ** state['step']\n",
        "                bias_correction2 = 1 - beta2 ** state['step']\n",
        "                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n",
        "\n",
        "                # p.data.addcdiv_(-step_size, exp_avg, denom)\n",
        "                p.data.add_(-step_size,  torch.mul(p.data, group['weight_decay']).addcdiv_(1, exp_avg, denom) )\n",
        "\n",
        "        return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}