{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S0VWM2ElZqkU"
   },
   "source": [
    "# **Load and read data, split into train and val**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "id": "3p1FNVTHZz73",
    "outputId": "88cb3f2e-898f-4ee7-8973-57e106c99af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-12-18 19:30:25--  https://competitions.codalab.org/my/datasets/download/2c6a99a5-b071-4f1d-a3b1-d49a923e0c68\n",
      "Resolving competitions.codalab.org (competitions.codalab.org)... 134.158.75.178\n",
      "Connecting to competitions.codalab.org (competitions.codalab.org)|134.158.75.178|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/ba53c/data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2cbe0d18c7a6e5fd795ba469f0bf8629a55a90c96ba4d38bd386cdd48cd6c2a7&X-Amz-Date=20181218T193017Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20181218%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
      "--2018-12-18 19:30:26--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/ba53c/data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2cbe0d18c7a6e5fd795ba469f0bf8629a55a90c96ba4d38bd386cdd48cd6c2a7&X-Amz-Date=20181218T193017Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20181218%2Fnewcodalab%2Fs3%2Faws4_request\n",
      "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
      "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 608893981 (581M) [application/zip]\n",
      "Saving to: ‘2c6a99a5-b071-4f1d-a3b1-d49a923e0c68’\n",
      "\n",
      "2c6a99a5-b071-4f1d- 100%[===================>] 580.69M  26.4MB/s    in 23s     \n",
      "\n",
      "2018-12-18 19:30:49 (25.6 MB/s) - ‘2c6a99a5-b071-4f1d-a3b1-d49a923e0c68’ saved [608893981/608893981]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://competitions.codalab.org/my/datasets/download/2c6a99a5-b071-4f1d-a3b1-d49a923e0c68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q2hy8fbnYnf4"
   },
   "outputs": [],
   "source": [
    "!mv 2c6a99a5-b071-4f1d-a3b1-d49a923e0c68 data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "f8WaXmx2ZHrn",
    "outputId": "005a1f91-4cbd-49c1-b493-40b07dba31c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zipfile36\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/8a/3b7da0b0bd87d1ef05b74207827c72d348b56a0d6d83242582be18a81e02/zipfile36-0.1.3-py3-none-any.whl\n",
      "Installing collected packages: zipfile36\n",
      "Successfully installed zipfile36-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install zipfile36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTHBSkoEZNp1"
   },
   "outputs": [],
   "source": [
    "!mkdir msaic\n",
    "!mv data.zip msaic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5SqdckPxZU-5",
    "outputId": "f4cb386d-51cc-4e54-d959-c2e77abf04ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/msaic\n"
     ]
    }
   ],
   "source": [
    "%cd msaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nqm6AQyiZblX"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zipref = zipfile.ZipFile('data.zip', 'r')\n",
    "zipref.extractall()\n",
    "zipref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwFwx83NZfbk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8lcP4afaPCx"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.tsv\", sep= '\\t',header=None)\n",
    "df.columns = ['index','question', 'passage', 'label','seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "tLM59QsYaXsC",
    "outputId": "1bb7abc8-db1a-40ca-e871-056fead1e9cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>. what is a corporation?</td>\n",
       "      <td>A company is incorporated in a specific nation...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "      <td>. what is a corporation?</td>\n",
       "      <td>Today, there is a growing community of more th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>. what is a corporation?</td>\n",
       "      <td>Corporation definition, an association of indi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131</td>\n",
       "      <td>. what is a corporation?</td>\n",
       "      <td>Examples of corporation in a Sentence. 1  He w...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131</td>\n",
       "      <td>. what is a corporation?</td>\n",
       "      <td>1: a government-owned corporation (as a utilit...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                  question  \\\n",
       "0    131  . what is a corporation?   \n",
       "1    131  . what is a corporation?   \n",
       "2    131  . what is a corporation?   \n",
       "3    131  . what is a corporation?   \n",
       "4    131  . what is a corporation?   \n",
       "\n",
       "                                             passage  label  seq  \n",
       "0  A company is incorporated in a specific nation...      0    0  \n",
       "1  Today, there is a growing community of more th...      0    1  \n",
       "2  Corporation definition, an association of indi...      0    2  \n",
       "3  Examples of corporation in a Sentence. 1  He w...      0    3  \n",
       "4  1: a government-owned corporation (as a utilit...      0    4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UOELzvKea5JH",
    "outputId": "d95025c1-ecf8-4808-937d-e46575a3de36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5241880"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uJjt-xySbe4h",
    "outputId": "3f9730b4-1393-440d-b05e-e6d23c616e6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1397"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0jSbap-DcqZB",
    "outputId": "afbb0b4a-76af-4ac8-88d2-faf1ba7daeab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2].str.len().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFmLbiVoI4DQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(200)\n",
    "np.random.seed(200)\n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VlDvuHWRJop7"
   },
   "outputs": [],
   "source": [
    "# get first n_samp positive cased and n_samp negative samples\n",
    "ratio = 8\n",
    "pos_samp = 30000\n",
    "neg_samp = pos_samp*ratio\n",
    "pos_df = df[df.label==1][:pos_samp]\n",
    "neg_df = df[df.label==0][:neg_samp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyEG0uSGKBjw"
   },
   "outputs": [],
   "source": [
    "tot_df = pos_df.append(neg_df)\n",
    "tot_df = shuffle(tot_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48364</td>\n",
       "      <td>cost of new hvac unit</td>\n",
       "      <td>Ductwork in your house is one of the main sour...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29436</td>\n",
       "      <td>can a check be postdated legally</td>\n",
       "      <td>Such evidence infers the checks were postdated...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110160</td>\n",
       "      <td>how long can you work before a break</td>\n",
       "      <td>The rest period time shall be based on the tot...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>384512</td>\n",
       "      <td>what is the biggest dinosaur ever called</td>\n",
       "      <td>These dinosaurs lived during the late Jurassic...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>336610</td>\n",
       "      <td>what is an stp</td>\n",
       "      <td>Catia Document. STP file is a Catia Document. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                  question  \\\n",
       "0   48364                     cost of new hvac unit   \n",
       "1   29436          can a check be postdated legally   \n",
       "2  110160      how long can you work before a break   \n",
       "3  384512  what is the biggest dinosaur ever called   \n",
       "4  336610                            what is an stp   \n",
       "\n",
       "                                             passage  label  seq  \n",
       "0  Ductwork in your house is one of the main sour...      0    7  \n",
       "1  Such evidence infers the checks were postdated...      0    0  \n",
       "2  The rest period time shall be based on the tot...      0    5  \n",
       "3  These dinosaurs lived during the late Jurassic...      0    8  \n",
       "4  Catia Document. STP file is a Catia Document. ...      0    9  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "EQ9Jqf42Kl9g",
    "outputId": "c670b058-c4e4-4431-c04d-1b1388a1479e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465664</td>\n",
       "      <td>where can the liver cause pain</td>\n",
       "      <td>Liver pain may be confused with a more general...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>456839</td>\n",
       "      <td>when is kirby star allies release date</td>\n",
       "      <td>The coop focused Kirby game for the Nintendo S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90780</td>\n",
       "      <td>government per diem 2015</td>\n",
       "      <td>federal per diem rates are set by the general ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102483</td>\n",
       "      <td>how does molasses affect blood sugar</td>\n",
       "      <td>One tablespoon of unsulphured blackstrap molas...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>451486</td>\n",
       "      <td>when did mt rainier erupt last</td>\n",
       "      <td>Mount Rainier is one of the 16 Decade Volcanoe...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97426</td>\n",
       "      <td>how calcium depletion cause tetany</td>\n",
       "      <td>this primefact is one of three primefacts on g...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>193526</td>\n",
       "      <td>legal definition of lump.sum payment</td>\n",
       "      <td>The main characteristic of a lump sum contract...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>245647</td>\n",
       "      <td>website that shows email settings</td>\n",
       "      <td>From here, you can select the option in the le...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>348288</td>\n",
       "      <td>what is difference between planned amounts and...</td>\n",
       "      <td>The flexible budget variance is the difference...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>138899</td>\n",
       "      <td>how many week is first trimester</td>\n",
       "      <td>At the end of the third month, your baby is ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                           question  \\\n",
       "0  465664                     where can the liver cause pain   \n",
       "1  456839             when is kirby star allies release date   \n",
       "2   90780                           government per diem 2015   \n",
       "3  102483               how does molasses affect blood sugar   \n",
       "4  451486                     when did mt rainier erupt last   \n",
       "5   97426                 how calcium depletion cause tetany   \n",
       "6  193526               legal definition of lump.sum payment   \n",
       "7  245647                  website that shows email settings   \n",
       "8  348288  what is difference between planned amounts and...   \n",
       "9  138899                   how many week is first trimester   \n",
       "\n",
       "                                             passage  label  seq  \n",
       "0  Liver pain may be confused with a more general...      1    4  \n",
       "1  The coop focused Kirby game for the Nintendo S...      0    0  \n",
       "2  federal per diem rates are set by the general ...      0    7  \n",
       "3  One tablespoon of unsulphured blackstrap molas...      0    3  \n",
       "4  Mount Rainier is one of the 16 Decade Volcanoe...      1    2  \n",
       "5  this primefact is one of three primefacts on g...      0    2  \n",
       "6  The main characteristic of a lump sum contract...      0    0  \n",
       "7  From here, you can select the option in the le...      0    1  \n",
       "8  The flexible budget variance is the difference...      0    8  \n",
       "9  At the end of the third month, your baby is ab...      0    9  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aac7JeDXK5Ye",
    "outputId": "57bf8668-d736-41cf-9cee-e7e66f1cbae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'question', 'passage', 'label', 'seq'], dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = tot_df.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChlQxnN7K5Ta"
   },
   "outputs": [],
   "source": [
    "tot_df = tot_df[['label','index' ,'seq' ,'question', 'passage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "9q5OmJlRLxoh",
    "outputId": "32102b71-3926-4808-c8a6-63d5c46c0bf2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>seq</th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>465664</td>\n",
       "      <td>4</td>\n",
       "      <td>where can the liver cause pain</td>\n",
       "      <td>Liver pain may be confused with a more general...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>456839</td>\n",
       "      <td>0</td>\n",
       "      <td>when is kirby star allies release date</td>\n",
       "      <td>The coop focused Kirby game for the Nintendo S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>90780</td>\n",
       "      <td>7</td>\n",
       "      <td>government per diem 2015</td>\n",
       "      <td>federal per diem rates are set by the general ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>102483</td>\n",
       "      <td>3</td>\n",
       "      <td>how does molasses affect blood sugar</td>\n",
       "      <td>One tablespoon of unsulphured blackstrap molas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>451486</td>\n",
       "      <td>2</td>\n",
       "      <td>when did mt rainier erupt last</td>\n",
       "      <td>Mount Rainier is one of the 16 Decade Volcanoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>97426</td>\n",
       "      <td>2</td>\n",
       "      <td>how calcium depletion cause tetany</td>\n",
       "      <td>this primefact is one of three primefacts on g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>193526</td>\n",
       "      <td>0</td>\n",
       "      <td>legal definition of lump.sum payment</td>\n",
       "      <td>The main characteristic of a lump sum contract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>245647</td>\n",
       "      <td>1</td>\n",
       "      <td>website that shows email settings</td>\n",
       "      <td>From here, you can select the option in the le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>348288</td>\n",
       "      <td>8</td>\n",
       "      <td>what is difference between planned amounts and...</td>\n",
       "      <td>The flexible budget variance is the difference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>138899</td>\n",
       "      <td>9</td>\n",
       "      <td>how many week is first trimester</td>\n",
       "      <td>At the end of the third month, your baby is ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   index  seq                                           question  \\\n",
       "0      1  465664    4                     where can the liver cause pain   \n",
       "1      0  456839    0             when is kirby star allies release date   \n",
       "2      0   90780    7                           government per diem 2015   \n",
       "3      0  102483    3               how does molasses affect blood sugar   \n",
       "4      1  451486    2                     when did mt rainier erupt last   \n",
       "5      0   97426    2                 how calcium depletion cause tetany   \n",
       "6      0  193526    0               legal definition of lump.sum payment   \n",
       "7      0  245647    1                  website that shows email settings   \n",
       "8      0  348288    8  what is difference between planned amounts and...   \n",
       "9      0  138899    9                   how many week is first trimester   \n",
       "\n",
       "                                             passage  \n",
       "0  Liver pain may be confused with a more general...  \n",
       "1  The coop focused Kirby game for the Nintendo S...  \n",
       "2  federal per diem rates are set by the general ...  \n",
       "3  One tablespoon of unsulphured blackstrap molas...  \n",
       "4  Mount Rainier is one of the 16 Decade Volcanoe...  \n",
       "5  this primefact is one of three primefacts on g...  \n",
       "6  The main characteristic of a lump sum contract...  \n",
       "7  From here, you can select the option in the le...  \n",
       "8  The flexible budget variance is the difference...  \n",
       "9  At the end of the third month, your baby is ab...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGu9Ahk0NmGk"
   },
   "outputs": [],
   "source": [
    "val_split = 0.3\n",
    "ind = int(len(tot_df)*val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGyzHX9JLSH4"
   },
   "outputs": [],
   "source": [
    "train_df, val_df = tot_df[ind:], tot_df[:ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "-BUVI8DnOVJr",
    "outputId": "867c3b64-b052-4d7a-87d9-14632ae9925f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>seq</th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81000</th>\n",
       "      <td>1</td>\n",
       "      <td>451860</td>\n",
       "      <td>3</td>\n",
       "      <td>when did san pellegrino start</td>\n",
       "      <td>With a tradition of excellence and fine taste ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81001</th>\n",
       "      <td>0</td>\n",
       "      <td>456099</td>\n",
       "      <td>2</td>\n",
       "      <td>when is aledo rhubarb fest over</td>\n",
       "      <td>Desserts, Pies, Bar cookies, Recipes, Spring, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81002</th>\n",
       "      <td>0</td>\n",
       "      <td>272541</td>\n",
       "      <td>0</td>\n",
       "      <td>what conveys sperm and urine</td>\n",
       "      <td>At puberty, reproductive organs (sexual body p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81003</th>\n",
       "      <td>0</td>\n",
       "      <td>247882</td>\n",
       "      <td>9</td>\n",
       "      <td>what age does tj maxx hire</td>\n",
       "      <td>Referred by: Please print clearly in ink. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81004</th>\n",
       "      <td>1</td>\n",
       "      <td>132258</td>\n",
       "      <td>3</td>\n",
       "      <td>how many human authors wrote the books of the ...</td>\n",
       "      <td>1 There are more authors of the Bible than the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label   index  seq                                           question  \\\n",
       "81000      1  451860    3                      when did san pellegrino start   \n",
       "81001      0  456099    2                    when is aledo rhubarb fest over   \n",
       "81002      0  272541    0                       what conveys sperm and urine   \n",
       "81003      0  247882    9                         what age does tj maxx hire   \n",
       "81004      1  132258    3  how many human authors wrote the books of the ...   \n",
       "\n",
       "                                                 passage  \n",
       "81000  With a tradition of excellence and fine taste ...  \n",
       "81001  Desserts, Pies, Bar cookies, Recipes, Spring, ...  \n",
       "81002  At puberty, reproductive organs (sexual body p...  \n",
       "81003  Referred by: Please print clearly in ink. The ...  \n",
       "81004  1 There are more authors of the Bible than the...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjDikKIwc5WS"
   },
   "source": [
    "# **Install Pytorch and clone BERT Repo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "LrG4G59lejc-",
    "outputId": "55992ed7-0fe8-46ec-fc91-d663849de86d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 109, done.\u001b[K\n",
      "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
      "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
      "remote: Total 2316 (delta 54), reused 77 (delta 34), pack-reused 2207\u001b[K\n",
      "Receiving objects: 100% (2316/2316), 7.87 MiB | 22.07 MiB/s, done.\n",
      "Resolving deltas: 100% (1411/1411), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/apex.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "colab_type": "code",
    "id": "YVNpuhqKeln_",
    "outputId": "00f56bc4-a78a-43cd-d98e-3f66494d8ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/msaic/apex\n",
      "torch.__version__  =  1.0.0\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing apex.egg-info/PKG-INFO\n",
      "writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "writing top-level names to apex.egg-info/top_level.txt\n",
      "reading manifest file 'apex.egg-info/SOURCES.txt'\n",
      "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "running build_ext\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.7/syncbn.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.7/apex_C.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/apex\n",
      "creating build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "copying build/lib.linux-x86_64-3.7/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "copying build/lib.linux-x86_64-3.7/apex/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "copying build/lib.linux-x86_64-3.7/apex/__init__.py -> build/bdist.linux-x86_64/egg/apex\n",
      "creating build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "copying build/lib.linux-x86_64-3.7/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "copying build/lib.linux-x86_64-3.7/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "copying build/lib.linux-x86_64-3.7/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "creating build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.7/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.7/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.7/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.7/apex/fp16_utils/fused_weight_norm.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.7/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "creating build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.7/apex/RNN/models.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.7/apex/RNN/__init__.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.7/apex/RNN/cells.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.7/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "creating build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/handle.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "creating build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/__version__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/scaler.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/opt.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/utils.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/wrap.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/amp.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.7/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "creating build/bdist.linux-x86_64/egg/apex/normalization\n",
      "copying build/lib.linux-x86_64-3.7/apex/normalization/__init__.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
      "copying build/lib.linux-x86_64-3.7/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
      "creating build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.7/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.7/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.7/apex/parallel/distributed.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.7/apex/parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.7/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.7/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.7/apex/parallel/LARC.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.7/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.7/fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.7/fused_adam_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/reparameterization.py to reparameterization.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/weight_norm.py to weight_norm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16util.py to fp16util.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fused_weight_norm.py to fused_weight_norm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/models.py to models.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/cells.py to cells.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/RNNBackend.py to RNNBackend.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/handle.py to handle.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__version__.py to __version__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/scaler.py to scaler.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/opt.py to opt.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/utils.py to utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/wrap.py to wrap.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/amp.py to amp.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/compat.py to compat.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/rnn_compat.py to rnn_compat.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/multiproc.py to multiproc.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/distributed.py to distributed.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/LARC.py to LARC.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-37.pyc\n",
      "creating stub loader for apex_C.cpython-37m-x86_64-linux-gnu.so\n",
      "creating stub loader for fused_adam_cuda.cpython-37m-x86_64-linux-gnu.so\n",
      "creating stub loader for syncbn.cpython-37m-x86_64-linux-gnu.so\n",
      "creating stub loader for fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex_C.py to apex_C.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fused_adam_cuda.py to fused_adam_cuda.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/syncbn.py to syncbn.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fused_layer_norm_cuda.py to fused_layer_norm_cuda.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.apex_C.cpython-37: module references __file__\n",
      "__pycache__.fused_adam_cuda.cpython-37: module references __file__\n",
      "__pycache__.fused_layer_norm_cuda.cpython-37: module references __file__\n",
      "__pycache__.syncbn.cpython-37: module references __file__\n",
      "creating 'dist/apex-0.1-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing apex-0.1-py3.7-linux-x86_64.egg\n",
      "removing '/opt/anaconda3/lib/python3.7/site-packages/apex-0.1-py3.7-linux-x86_64.egg' (and everything under it)\n",
      "creating /opt/anaconda3/lib/python3.7/site-packages/apex-0.1-py3.7-linux-x86_64.egg\n",
      "Extracting apex-0.1-py3.7-linux-x86_64.egg to /opt/anaconda3/lib/python3.7/site-packages\n",
      "apex 0.1 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /opt/anaconda3/lib/python3.7/site-packages/apex-0.1-py3.7-linux-x86_64.egg\n",
      "Processing dependencies for apex==0.1\n",
      "Finished processing dependencies for apex==0.1\n",
      "/home/jupyter/msaic\n"
     ]
    }
   ],
   "source": [
    "%cd apex/\n",
    "!python setup.py install --cuda_ext --cpp_ext\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "xXKvYv_Gd8gD",
    "outputId": "6cb380a7-4bc7-4105-938d-9edc56556b0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-pretrained-bert==0.4.0 in /opt/anaconda3/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.4.0) (4.26.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.4.0) (2.19.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.4.0) (1.0.0)\n",
      "Requirement already satisfied: boto3 in /opt/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.4.0) (1.9.67)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.4.0) (1.15.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert==0.4.0) (2.7)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert==0.4.0) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert==0.4.0) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /opt/anaconda3/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert==0.4.0) (0.1.13)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/anaconda3/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert==0.4.0) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.67 in /opt/anaconda3/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert==0.4.0) (1.12.67)\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.67->boto3->pytorch-pretrained-bert==0.4.0) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/anaconda3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.67->boto3->pytorch-pretrained-bert==0.4.0) (2.7.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.67->boto3->pytorch-pretrained-bert==0.4.0) (1.11.0)\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[31mspacy 2.0.16 has requirement regex==2018.01.10, but you'll have regex 2018.8.29 which is incompatible.\u001b[0m\n",
      "\u001b[31mjupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.7 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Wt5Zp9-5Z05p",
    "outputId": "c7dd9da1-4b4f-4ac0-a520-bfb4cc7ec178"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6qwwooDyOd5"
   },
   "outputs": [],
   "source": [
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()\n",
    "\n",
    "def accuracy(out, labels):\n",
    "    outputs = np.argmax(out, axis=1)\n",
    "    return np.sum(outputs == labels)\n",
    "\n",
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y892bGY5xeCQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def convert_examples_to_features(df,tokenizer, max_seq_length):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "#    label_map = {label : i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for ex_index, example in df.iterrows():\n",
    "        tokens_a = tokenizer.tokenize(example[3])\n",
    "\n",
    "        tokens_b = tokenizer.tokenize(example[4])\n",
    "        # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "        # length is less than the specified length.\n",
    "        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids: 0   0   0   0  0     0 0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        if tokens_b:\n",
    "            tokens += tokens_b + [\"[SEP]\"]\n",
    "            segment_ids += [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=example[0]))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdfIM5yczWvD"
   },
   "outputs": [],
   "source": [
    "fp16 = True\n",
    "local_rank = -1 \n",
    "gradient_accumulation_steps = 1\n",
    "train_batch_size = 32\n",
    "seed = 111\n",
    "bert_model = 'bert-large-uncased'\n",
    "do_lower_case = True\n",
    "warmup_proportion = 0.1\n",
    "#num_choices = num_choices\n",
    "learning_rate = 2e-5\n",
    "loss_scale = 128\n",
    "num_train_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "LAHAShl-xeN7",
    "outputId": "17f79d8b-1687-4f36-ab9e-a081e0930bff"
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case = do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Vgydtk5lxeLr",
    "outputId": "7e7f97f4-7100-4c62-a393-98c02f92eccd"
   },
   "outputs": [],
   "source": [
    "train_features = convert_examples_to_features(train_df, tokenizer,80)\n",
    "eval_features = convert_examples_to_features(val_df, tokenizer,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DYVRJXSxeJI"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForMultipleChoice, BertModel\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import logging\n",
    "import tarfile\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss, L1Loss\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "loss_fct = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EERzNusGxeGj"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4MuBWnvxd-W"
   },
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "toXxnnmC01-r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYWctJMH0E9u"
   },
   "outputs": [],
   "source": [
    "all_eval_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "all_eval_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "all_eval_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "all_eval_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "eval_data = TensorDataset(all_eval_input_ids, all_eval_input_mask, all_eval_segment_ids, all_eval_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12HiUqWw0H4g"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 5907/5907 [13:28<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28326426863105375, 'eval_accuracy': 0.8904074074074074, 'global_step': 5907, 'loss': 0.30487656742662306}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 5907/5907 [13:24<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2906447737514502, 'eval_accuracy': 0.8820246913580246, 'global_step': 11814, 'loss': 0.24686774025718955}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 5907/5907 [13:25<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3848509585122927, 'eval_accuracy': 0.8683950617283951, 'global_step': 17721, 'loss': 0.15939744361992392}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [50:38<00:00, 1013.46s/it]\n"
     ]
    }
   ],
   "source": [
    "if local_rank == -1:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    device = torch.device(\"cuda\", local_rank)\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "\n",
    "if gradient_accumulation_steps < 1:\n",
    "    raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(\n",
    "                        gradient_accumulation_steps))\n",
    "\n",
    "train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "num_labels = 2\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=do_lower_case)\n",
    "\n",
    "num_train_steps = int(\n",
    "    len(train_data) / train_batch_size / gradient_accumulation_steps * num_train_epochs)\n",
    "\n",
    "# Prepare model\n",
    "model = BertForSequenceClassification.from_pretrained(bert_model, num_labels = num_labels)\n",
    "if fp16:\n",
    "    model.half()\n",
    "model.to(device)\n",
    "if local_rank != -1:\n",
    "    try:\n",
    "        from apex.parallel import DistributedDataParallel as DDP\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    model = DDP(model)\n",
    "elif n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "# Prepare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "t_total = num_train_steps\n",
    "if local_rank != -1:\n",
    "    t_total = t_total // torch.distributed.get_world_size()\n",
    "if fp16:\n",
    "    try:\n",
    "        from apex.optimizers import FP16_Optimizer\n",
    "        from apex.optimizers import FusedAdam\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    optimizer = FusedAdam(optimizer_grouped_parameters,\n",
    "                          lr=learning_rate,\n",
    "                          bias_correction=False,\n",
    "                          max_grad_norm=1.0)\n",
    "    if loss_scale == 0:\n",
    "        optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
    "    else:\n",
    "        optimizer = FP16_Optimizer(optimizer, static_loss_scale=loss_scale)\n",
    "\n",
    "else:\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=learning_rate,\n",
    "                         warmup=warmup_proportion,\n",
    "                         t_total=t_total)\n",
    "\n",
    "global_step = 0\n",
    "if local_rank == -1:\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "else:\n",
    "    train_sampler = DistributedSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "for _ in trange(int(num_train_epochs), desc=\"Epoch\", position=0):\n",
    "    tr_loss = 0\n",
    "    model.train()\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\", position = 0)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "        loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "\n",
    "        if fp16:\n",
    "            optimizer.backward(loss)\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            # modify learning rate with special warm up BERT uses\n",
    "            lr_this_step = learning_rate * warmup_linear(global_step/t_total, warmup_proportion)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=train_batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            logits = model(input_ids, segment_ids, input_mask)\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        tmp_eval_accuracy = accuracy(logits, label_ids)\n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        nb_eval_examples += input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
    "\n",
    "    result = {'eval_loss': eval_loss,\n",
    "              'eval_accuracy': eval_accuracy,\n",
    "              'global_step': global_step,\n",
    "              'loss': tr_loss/nb_tr_steps}\n",
    "    print(result)\n",
    "    torch.save(model, 'checkpoint' + str(eval_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQqZqniR0H_i"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie Canal Distance Tables The Erie Canal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>What is the distance between Erie AND Buffalo?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>The distance between Erie and Buffalo in a str...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie Canal Distances. Erie Canal Distance Tabl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie's Metropolitan Area consists of approxima...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                   question  \\\n",
       "0  1135787  distance between erie in buffalo new york   \n",
       "1  1135787  distance between erie in buffalo new york   \n",
       "2  1135787  distance between erie in buffalo new york   \n",
       "3  1135787  distance between erie in buffalo new york   \n",
       "4  1135787  distance between erie in buffalo new york   \n",
       "\n",
       "                                             passage  seq  \n",
       "0  Erie Canal Distance Tables The Erie Canal is t...    0  \n",
       "1  What is the distance between Erie AND Buffalo?...    1  \n",
       "2  The distance between Erie and Buffalo in a str...    2  \n",
       "3  Erie Canal Distances. Erie Canal Distance Tabl...    3  \n",
       "4  Erie's Metropolitan Area consists of approxima...    4  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"eval1_unlabelled.tsv\", sep= '\\t',header=None)\n",
    "df3 = df2.copy()\n",
    "df3.columns = ['index', ' question', 'passage', 'seq']\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qp5DRYze0H8t"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_test_features(df,tokenizer, max_seq_length):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "#    label_map = {label : i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for ex_index, example in df.iterrows():\n",
    "        tokens_a = tokenizer.tokenize(example[1])\n",
    "\n",
    "        tokens_b = tokenizer.tokenize(example[2])\n",
    "        # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "        # length is less than the specified length.\n",
    "        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids: 0   0   0   0  0     0 0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        if tokens_b:\n",
    "            tokens += tokens_b + [\"[SEP]\"]\n",
    "            segment_ids += [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=None))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = convert_examples_to_test_features(df3,tokenizer, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_t_AHC60H1o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.load(\"bert_large_1to8_270k_88_val_acc\")\n",
    "model.half()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
    "#all_label_ids = torch.tensor([f.label_id for f in test_features], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3256/3256 [02:14<00:00, 24.25it/s]\n"
     ]
    }
   ],
   "source": [
    "output_list = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "with torch.no_grad():\n",
    "  from tqdm import tqdm\n",
    "  for input_ids, input_mask, segment_ids in tqdm(eval_dataloader, total = len(eval_dataloader), position = 0):\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    logits = model(input_ids, segment_ids, input_mask)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    output_list.append(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4941 , -0.7017 ],\n",
       "       [ 0.3274 , -0.05408],\n",
       "       [ 0.4497 , -0.2593 ],\n",
       "       [ 0.4888 , -0.681  ],\n",
       "       [ 1.629  , -2.318  ],\n",
       "       [ 2.82   , -3.775  ],\n",
       "       [ 1.426  , -2.102  ],\n",
       "       [ 1.365  , -2.033  ],\n",
       "       [ 2.11   , -2.74   ],\n",
       "       [ 0.3347 , -0.0585 ],\n",
       "       [ 0.8735 , -1.459  ],\n",
       "       [ 2.78   , -3.758  ],\n",
       "       [ 0.4102 , -0.6562 ],\n",
       "       [ 2.61   , -3.428  ],\n",
       "       [ 2.475  , -3.242  ],\n",
       "       [ 0.3413 , -0.4277 ],\n",
       "       [ 2.455  , -3.244  ],\n",
       "       [ 2.672  , -3.535  ],\n",
       "       [ 1.568  , -2.25   ],\n",
       "       [ 1.828  , -2.465  ],\n",
       "       [ 0.9185 , -1.594  ],\n",
       "       [ 1.488  , -2.182  ],\n",
       "       [ 2.275  , -2.9    ],\n",
       "       [ 0.828  , -1.423  ],\n",
       "       [ 0.7456 , -1.317  ],\n",
       "       [ 0.2507 , -0.366  ],\n",
       "       [ 2.514  , -3.303  ],\n",
       "       [ 0.5493 , -0.9326 ],\n",
       "       [ 1.033  , -1.739  ],\n",
       "       [ 2.34   , -3.041  ],\n",
       "       [ 2.79   , -3.69   ],\n",
       "       [ 0.873  , -1.502  ]], dtype=float16)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs =[]\n",
    "for item in output_list:\n",
    "  for i in item:\n",
    "    outputs.append(math.exp(i[1])/(math.exp(i[1]) + math.exp(i[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104170"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['pred'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>seq</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie Canal Distance Tables The Erie Canal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>What is the distance between Erie AND Buffalo?...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.405772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>The distance between Erie and Buffalo in a str...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.329823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie Canal Distances. Erie Canal Distance Tabl...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.236869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie's Metropolitan Area consists of approxima...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.018942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>This will help you estimate how much time you ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>As a general guide, Albany to Oswego, NY will ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.028544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>Erie, PA. {{::location.tagLine.value.text}}. C...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.032344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>You start your flight Distance from Buffalo, N...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.007771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1135787</td>\n",
       "      <td>distance between erie in buffalo new york</td>\n",
       "      <td>What is the distance between Erie AND Buffalo?...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.402943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                   question  \\\n",
       "0  1135787  distance between erie in buffalo new york   \n",
       "1  1135787  distance between erie in buffalo new york   \n",
       "2  1135787  distance between erie in buffalo new york   \n",
       "3  1135787  distance between erie in buffalo new york   \n",
       "4  1135787  distance between erie in buffalo new york   \n",
       "5  1135787  distance between erie in buffalo new york   \n",
       "6  1135787  distance between erie in buffalo new york   \n",
       "7  1135787  distance between erie in buffalo new york   \n",
       "8  1135787  distance between erie in buffalo new york   \n",
       "9  1135787  distance between erie in buffalo new york   \n",
       "\n",
       "                                             passage  seq      pred  \n",
       "0  Erie Canal Distance Tables The Erie Canal is t...    0  0.232223  \n",
       "1  What is the distance between Erie AND Buffalo?...    1  0.405772  \n",
       "2  The distance between Erie and Buffalo in a str...    2  0.329823  \n",
       "3  Erie Canal Distances. Erie Canal Distance Tabl...    3  0.236869  \n",
       "4  Erie's Metropolitan Area consists of approxima...    4  0.018942  \n",
       "5  This will help you estimate how much time you ...    5  0.001364  \n",
       "6  As a general guide, Albany to Oswego, NY will ...    6  0.028544  \n",
       "7  Erie, PA. {{::location.tagLine.value.text}}. C...    7  0.032344  \n",
       "8  You start your flight Distance from Buffalo, N...    8  0.007771  \n",
       "9  What is the distance between Erie AND Buffalo?...    9  0.402943  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the distance between Erie AND Buffalo? The distance between Erie and Buffalo in a straight line is 87 miles or 139.98 Kilometers . Driving Directions & Drive Times from Erie to Buffalo can be found further down the page. Driving distances, maps and journey times are currently provided by Google mapping systems.'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['passage'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "outfilename = 'answer.tsv'\n",
    "with open(outfilename,\"w\",encoding=\"utf-8\") as fw:\n",
    "  import math\n",
    "  linelist = []\n",
    "  tempscores = []\n",
    "  for idx, row in df3.iterrows():\n",
    "      tempscores.append(row['pred'])\n",
    "      if((idx +1)%10==0):\n",
    "          expsum = sum(tempscores)\n",
    "          tempscores = [str(s) for s in tempscores]\n",
    "          scoreString = \"\\t\".join(tempscores)\n",
    "          qid = str(row[0])\n",
    "          fw.write(qid+\"\\t\"+scoreString+\"\\n\")\n",
    "          tempscores=[]\n",
    "      if(idx%5000==0):\n",
    "          print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1135787</th>\n",
       "      <th>0.8430570601328118</th>\n",
       "      <th>0.9195703334850451</th>\n",
       "      <th>0.923177795547052</th>\n",
       "      <th>0.8244619263765706</th>\n",
       "      <th>0.4577123465541187</th>\n",
       "      <th>0.01363683528142988</th>\n",
       "      <th>0.10270900077722551</th>\n",
       "      <th>0.7689067580749572</th>\n",
       "      <th>0.11085559492526088</th>\n",
       "      <th>0.916708077443256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>281922</td>\n",
       "      <td>0.064477</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.203945</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.777511</td>\n",
       "      <td>0.009727</td>\n",
       "      <td>0.014602</td>\n",
       "      <td>0.020567</td>\n",
       "      <td>0.018476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120233</td>\n",
       "      <td>0.763528</td>\n",
       "      <td>0.111193</td>\n",
       "      <td>0.010611</td>\n",
       "      <td>0.704135</td>\n",
       "      <td>0.156298</td>\n",
       "      <td>0.897740</td>\n",
       "      <td>0.012564</td>\n",
       "      <td>0.762336</td>\n",
       "      <td>0.574171</td>\n",
       "      <td>0.117927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>319757</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.699152</td>\n",
       "      <td>0.010348</td>\n",
       "      <td>0.467909</td>\n",
       "      <td>0.552419</td>\n",
       "      <td>0.131731</td>\n",
       "      <td>0.017426</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.645385</td>\n",
       "      <td>0.629839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193633</td>\n",
       "      <td>0.024423</td>\n",
       "      <td>0.261095</td>\n",
       "      <td>0.023644</td>\n",
       "      <td>0.006811</td>\n",
       "      <td>0.007892</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.313210</td>\n",
       "      <td>0.160398</td>\n",
       "      <td>0.003318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50229</td>\n",
       "      <td>0.817210</td>\n",
       "      <td>0.018107</td>\n",
       "      <td>0.631076</td>\n",
       "      <td>0.871584</td>\n",
       "      <td>0.466435</td>\n",
       "      <td>0.564984</td>\n",
       "      <td>0.599430</td>\n",
       "      <td>0.497925</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.584916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1135787  0.8430570601328118  0.9195703334850451  0.923177795547052  \\\n",
       "0   281922            0.064477            0.007108           0.203945   \n",
       "1   120233            0.763528            0.111193           0.010611   \n",
       "2   319757            0.006098            0.699152           0.010348   \n",
       "3   193633            0.024423            0.261095           0.023644   \n",
       "4    50229            0.817210            0.018107           0.631076   \n",
       "\n",
       "   0.8244619263765706  0.4577123465541187  0.01363683528142988  \\\n",
       "0            0.014159            0.013274             0.777511   \n",
       "1            0.704135            0.156298             0.897740   \n",
       "2            0.467909            0.552419             0.131731   \n",
       "3            0.006811            0.007892             0.004399   \n",
       "4            0.871584            0.466435             0.564984   \n",
       "\n",
       "   0.10270900077722551  0.7689067580749572  0.11085559492526088  \\\n",
       "0             0.009727            0.014602             0.020567   \n",
       "1             0.012564            0.762336             0.574171   \n",
       "2             0.017426            0.005664             0.645385   \n",
       "3             0.006615            0.313210             0.160398   \n",
       "4             0.599430            0.497925             0.186984   \n",
       "\n",
       "   0.916708077443256  \n",
       "0           0.018476  \n",
       "1           0.117927  \n",
       "2           0.629839  \n",
       "3           0.003318  \n",
       "4           0.584916  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.read_csv('answer.tsv', sep = '\\t')\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1135787</th>\n",
       "      <th>0.23222307635523556</th>\n",
       "      <th>0.40577246585394805</th>\n",
       "      <th>0.329823295015375</th>\n",
       "      <th>0.23686910602444727</th>\n",
       "      <th>0.01894170782518539</th>\n",
       "      <th>0.0013643619186429429</th>\n",
       "      <th>0.028544151696160362</th>\n",
       "      <th>0.032344332381157095</th>\n",
       "      <th>0.007770581295614233</th>\n",
       "      <th>0.40294263416072096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>281922</td>\n",
       "      <td>0.088465</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.256087</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.316686</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.021492</td>\n",
       "      <td>0.013480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120233</td>\n",
       "      <td>0.075007</td>\n",
       "      <td>0.024845</td>\n",
       "      <td>0.005620</td>\n",
       "      <td>0.095265</td>\n",
       "      <td>0.112747</td>\n",
       "      <td>0.350533</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.185136</td>\n",
       "      <td>0.058831</td>\n",
       "      <td>0.004583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>319757</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.085099</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.100702</td>\n",
       "      <td>0.112016</td>\n",
       "      <td>0.058777</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.120594</td>\n",
       "      <td>0.319811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193633</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.041114</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50229</td>\n",
       "      <td>0.382545</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>0.066751</td>\n",
       "      <td>0.513958</td>\n",
       "      <td>0.058185</td>\n",
       "      <td>0.055669</td>\n",
       "      <td>0.192995</td>\n",
       "      <td>0.120232</td>\n",
       "      <td>0.020864</td>\n",
       "      <td>0.034391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1135787  0.23222307635523556  0.40577246585394805  0.329823295015375  \\\n",
       "0   281922             0.088465             0.001447           0.256087   \n",
       "1   120233             0.075007             0.024845           0.005620   \n",
       "2   319757             0.001534             0.085099           0.007374   \n",
       "3   193633             0.001938             0.014842           0.001585   \n",
       "4    50229             0.382545             0.005797           0.066751   \n",
       "\n",
       "   0.23686910602444727  0.01894170782518539  0.0013643619186429429  \\\n",
       "0             0.002383             0.003279               0.316686   \n",
       "1             0.095265             0.112747               0.350533   \n",
       "2             0.100702             0.112016               0.058777   \n",
       "3             0.001004             0.001211               0.001055   \n",
       "4             0.513958             0.058185               0.055669   \n",
       "\n",
       "   0.028544151696160362  0.032344332381157095  0.007770581295614233  \\\n",
       "0              0.003337              0.002011              0.021492   \n",
       "1              0.002969              0.185136              0.058831   \n",
       "2              0.005240              0.001172              0.120594   \n",
       "3              0.001042              0.041114              0.004023   \n",
       "4              0.192995              0.120232              0.020864   \n",
       "\n",
       "   0.40294263416072096  \n",
       "0             0.013480  \n",
       "1             0.004583  \n",
       "2             0.319811  \n",
       "3             0.000987  \n",
       "4             0.034391  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.read_csv('answer.tsv', sep = '\\t')\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv('answer.tsv', sep = '\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lUp4Z9ule1sN",
    "outputId": "232b510a-9de1-4812-88cd-1a76fabbc1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/msaic/mrc/pytorch-pretrained-BERT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.manual_seed_all(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 27624
    },
    "colab_type": "code",
    "id": "U5j-XuGRusV2",
    "outputId": "32910e15-acae-4ebf-f95b-0697facc0728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "12/18/2018 03:24:14 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "12/18/2018 03:24:14 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpr4ehsmtn\n",
      "100% 231508/231508 [00:00<00:00, 2121644.00B/s]\n",
      "12/18/2018 03:24:14 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpr4ehsmtn to cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "12/18/2018 03:24:14 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "12/18/2018 03:24:14 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpr4ehsmtn\n",
      "12/18/2018 03:24:14 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "12/18/2018 03:24:14 - INFO - __main__ -   LOOKING AT /content/msaic/mrc/train.tsv\n",
      "12/18/2018 03:24:15 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpnxndsk_h\n",
      "100% 407873900/407873900 [00:09<00:00, 44890485.41B/s]\n",
      "12/18/2018 03:24:25 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpnxndsk_h to cache at /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "12/18/2018 03:24:27 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "12/18/2018 03:24:27 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpnxndsk_h\n",
      "12/18/2018 03:24:27 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "12/18/2018 03:24:27 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp2xjyhh4d\n",
      "12/18/2018 03:24:32 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "12/18/2018 03:24:36 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "12/18/2018 03:24:36 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   *** Example ***\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   guid: train-1\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   tokens: [CLS] levels ke ##tones urine causes [SEP] [UNK] of [UNK] in the urine . [UNK] section discusses 17 medical conditions causing [UNK] in the urine . [UNK] simple discussion of these causes with additional information is below . [UNK] of [UNK] in the urine : [UNK] following medical conditions are some of the possible causes of [UNK] in the urine . [UNK] are likely to be other possible causes , so ask your doctor about your symptoms . [UNK] diabetes . [UNK] storage disease . [SEP]\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   input_ids: 101 3798 17710 11115 17996 5320 102 100 1997 100 1999 1996 17996 1012 100 2930 15841 2459 2966 3785 4786 100 1999 1996 17996 1012 100 3722 6594 1997 2122 5320 2007 3176 2592 2003 2917 1012 100 1997 100 1999 1996 17996 1024 100 2206 2966 3785 2024 2070 1997 1996 2825 5320 1997 100 1999 1996 17996 1012 100 2024 3497 2000 2022 2060 2825 5320 1010 2061 3198 2115 3460 2055 2115 8030 1012 100 14671 1012 100 5527 4295 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   label: 1 (id = 1)\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   *** Example ***\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   guid: train-2\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   tokens: [CLS] where does sea ##weed grow [SEP] [UNK] is the common name for countless species of marine plants and algae that grow in the ocean as well as in rivers , lakes , and other water bodies . [SEP]\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   input_ids: 101 2073 2515 2712 18041 4982 102 100 2003 1996 2691 2171 2005 14518 2427 1997 3884 4264 1998 18670 2008 4982 1999 1996 4153 2004 2092 2004 1999 5485 1010 6597 1010 1998 2060 2300 4230 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   label: 1 (id = 1)\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   *** Example ***\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   guid: train-3\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   tokens: [CLS] what is the climate of latvia like [SEP] [UNK] . 1 [UNK] climate of the [UNK] can be described as typical [UNK] continental influenced climate with warm , dry summers and fairly severe winters . [UNK] is the cold ##est month with daytime temperatures usually around - [UNK] , but in some cases winter months can be quite colder with temperatures far below zero , about - [UNK] or lower and strong , cold northeast ##erly winds . [SEP]\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   input_ids: 101 2054 2003 1996 4785 1997 12429 2066 102 100 1012 1015 100 4785 1997 1996 100 2064 2022 2649 2004 5171 100 6803 5105 4785 2007 4010 1010 4318 10945 1998 7199 5729 12214 1012 100 2003 1996 3147 4355 3204 2007 12217 7715 2788 2105 1011 100 1010 2021 1999 2070 3572 3467 2706 2064 2022 3243 21399 2007 7715 2521 2917 5717 1010 2055 1011 100 2030 2896 1998 2844 1010 3147 4794 12561 7266 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   label: 1 (id = 1)\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   *** Example ***\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   guid: train-4\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   tokens: [CLS] what was lucy ' s condition in 50 first dates [SEP] [UNK] film stars [UNK] [UNK] as a lot ##hari ##o vet ##erina ##rian and [UNK] [UNK] as an amnesia ##c , along with [UNK] [UNK] , [UNK] [UNK] , [UNK] [UNK] , [UNK] [UNK] , and [UNK] [UNK] . os ##t of the film was shot on location in [UNK] , [UNK] on the [UNK] side and the [UNK] [UNK] . [UNK] and [UNK] won an [UNK] award . [UNK] fictitious memory impairment suffered by [UNK] ' s character , [UNK] ' s [UNK] , is similar to short term memory loss and ant ##ero ##grade amnesia . [SEP]\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   input_ids: 101 2054 2001 7004 1005 1055 4650 1999 2753 2034 5246 102 100 2143 3340 100 100 2004 1037 2843 18428 2080 29525 26052 6862 1998 100 100 2004 2019 29222 2278 1010 2247 2007 100 100 1010 100 100 1010 100 100 1010 100 100 1010 1998 100 100 1012 9808 2102 1997 1996 2143 2001 2915 2006 3295 1999 100 1010 100 2006 1996 100 2217 1998 1996 100 100 1012 100 1998 100 2180 2019 100 2400 1012 100 23577 3638 25172 4265 2011 100 1005 1055 2839 1010 100 1005 1055 100 1010 2003 2714 2000 2460 2744 3638 3279 1998 14405 10624 24170 29222 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   label: 0 (id = 0)\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   *** Example ***\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   guid: train-5\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   tokens: [CLS] how many cal ##ories for an active woman [SEP] [UNK] [UNK] [UNK] . [UNK] average , a moderately active woman - - one who walks 1 . 5 to 3 miles per day or who gets the equivalent amount of exercise - - burns 2 , 200 cal ##ories per day from age 19 to 25 . [UNK] age 26 and 50 , she burns about 2 , 000 cal ##ories per day . [UNK] 50 , cal ##ori ##e burning slow ##s to about 1 , 800 daily cal ##ories . [UNK] a se ##dent ##ary lifestyle , she ex ##pen ##ds about 200 fewer cal ##ories each day ; with a more active lifestyle , she may burn 200 to 400 more cal ##ories [SEP]\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   input_ids: 101 2129 2116 10250 18909 2005 2019 3161 2450 102 100 100 100 1012 100 2779 1010 1037 17844 3161 2450 1011 1011 2028 2040 7365 1015 1012 1019 2000 1017 2661 2566 2154 2030 2040 4152 1996 5662 3815 1997 6912 1011 1011 7641 1016 1010 3263 10250 18909 2566 2154 2013 2287 2539 2000 2423 1012 100 2287 2656 1998 2753 1010 2016 7641 2055 1016 1010 2199 10250 18909 2566 2154 1012 100 2753 1010 10250 10050 2063 5255 4030 2015 2000 2055 1015 1010 5385 3679 10250 18909 1012 100 1037 7367 16454 5649 9580 1010 2016 4654 11837 5104 2055 3263 8491 10250 18909 2169 2154 1025 2007 1037 2062 3161 9580 1010 2016 2089 6402 3263 2000 4278 2062 10250 18909 102\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/18/2018 03:24:39 - INFO - __main__ -   label: 1 (id = 1)\n",
      "12/18/2018 03:26:03 - INFO - __main__ -   ***** Running training *****\n",
      "12/18/2018 03:26:03 - INFO - __main__ -     Num examples = 62999\n",
      "12/18/2018 03:26:03 - INFO - __main__ -     Batch size = 32\n",
      "12/18/2018 03:26:03 - INFO - __main__ -     Num steps = 5906\n",
      "Epoch:   0% 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/1969 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0% 1/1969 [00:01<56:20,  1.72s/it]\u001b[A\n",
      "Iteration:   0% 2/1969 [00:03<54:40,  1.67s/it]\u001b[A\n",
      "Iteration:   0% 3/1969 [00:04<53:27,  1.63s/it]\u001b[A\n",
      "Iteration:   0% 4/1969 [00:06<52:37,  1.61s/it]\u001b[A\n",
      "Iteration:   0% 5/1969 [00:07<52:03,  1.59s/it]\u001b[A\n",
      "Iteration:   0% 6/1969 [00:09<51:37,  1.58s/it]\u001b[A\n",
      "Iteration:   0% 7/1969 [00:11<51:21,  1.57s/it]\u001b[A\n",
      "Iteration:   0% 8/1969 [00:12<51:09,  1.57s/it]\u001b[A\n",
      "Iteration:   0% 9/1969 [00:14<50:58,  1.56s/it]\u001b[A\n",
      "Iteration:   1% 10/1969 [00:15<50:51,  1.56s/it]\u001b[A\n",
      "Iteration:   1% 11/1969 [00:17<50:44,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 12/1969 [00:18<50:40,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 13/1969 [00:20<50:38,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 14/1969 [00:21<50:33,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 15/1969 [00:23<50:34,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 16/1969 [00:24<50:31,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 17/1969 [00:26<50:33,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 18/1969 [00:28<50:30,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 19/1969 [00:29<50:25,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 20/1969 [00:31<50:26,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 21/1969 [00:32<50:23,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 22/1969 [00:34<50:24,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 23/1969 [00:35<50:20,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 24/1969 [00:37<50:22,  1.55s/it]\u001b[A\n",
      "Iteration:   1% 25/1969 [00:38<50:24,  1.56s/it]\u001b[A\n",
      "Iteration:   1% 26/1969 [00:40<50:33,  1.56s/it]\u001b[A\n",
      "Iteration:   1% 27/1969 [00:42<50:37,  1.56s/it]\u001b[A\n",
      "Iteration:   1% 28/1969 [00:43<50:35,  1.56s/it]\u001b[A\n",
      "Iteration:   1% 29/1969 [00:45<50:24,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 30/1969 [00:46<50:28,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 31/1969 [00:48<50:24,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 32/1969 [00:49<50:24,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 33/1969 [00:51<50:21,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 34/1969 [00:53<50:24,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 35/1969 [00:54<50:22,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 36/1969 [00:56<50:18,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 37/1969 [00:57<50:14,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 38/1969 [00:59<50:12,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 39/1969 [01:00<50:10,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 40/1969 [01:02<50:09,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 41/1969 [01:03<50:06,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 42/1969 [01:05<50:03,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 43/1969 [01:07<50:05,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 44/1969 [01:08<50:04,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 45/1969 [01:10<50:04,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 46/1969 [01:11<50:01,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 47/1969 [01:13<49:57,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 48/1969 [01:14<49:51,  1.56s/it]\u001b[A\n",
      "Iteration:   2% 49/1969 [01:16<49:49,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 50/1969 [01:17<49:49,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 51/1969 [01:19<49:48,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 52/1969 [01:21<49:48,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 53/1969 [01:22<49:55,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 54/1969 [01:24<49:50,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 55/1969 [01:25<49:51,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 56/1969 [01:27<49:49,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 57/1969 [01:28<49:48,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 58/1969 [01:30<49:41,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 59/1969 [01:32<49:41,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 60/1969 [01:33<49:44,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 61/1969 [01:35<49:42,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 62/1969 [01:36<49:40,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 63/1969 [01:38<49:37,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 64/1969 [01:39<49:33,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 65/1969 [01:41<49:34,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 66/1969 [01:42<49:37,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 67/1969 [01:44<49:30,  1.56s/it]\u001b[A\n",
      "Iteration:   3% 68/1969 [01:46<49:28,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 69/1969 [01:47<49:30,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 70/1969 [01:49<49:24,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 71/1969 [01:50<49:21,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 72/1969 [01:52<49:27,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 73/1969 [01:53<49:23,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 74/1969 [01:55<49:21,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 75/1969 [01:57<49:18,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 76/1969 [01:58<49:17,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 77/1969 [02:00<49:15,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 78/1969 [02:01<49:17,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 79/1969 [02:03<49:14,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 80/1969 [02:04<49:11,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 81/1969 [02:06<49:09,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 82/1969 [02:07<49:09,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 83/1969 [02:09<49:04,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 84/1969 [02:11<49:01,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 85/1969 [02:12<49:02,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 86/1969 [02:14<48:56,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 87/1969 [02:15<48:54,  1.56s/it]\u001b[A\n",
      "Iteration:   4% 88/1969 [02:17<48:53,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 89/1969 [02:18<48:53,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 90/1969 [02:20<48:51,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 91/1969 [02:22<48:51,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 92/1969 [02:23<48:49,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 93/1969 [02:25<48:50,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 94/1969 [02:26<48:53,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 95/1969 [02:28<48:48,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 96/1969 [02:29<48:44,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 97/1969 [02:31<48:45,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 98/1969 [02:32<48:50,  1.57s/it]\u001b[A\n",
      "Iteration:   5% 99/1969 [02:34<48:48,  1.57s/it]\u001b[A\n",
      "Iteration:   5% 100/1969 [02:36<48:42,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 101/1969 [02:37<48:43,  1.57s/it]\u001b[A\n",
      "Iteration:   5% 102/1969 [02:39<48:41,  1.57s/it]\u001b[A\n",
      "Iteration:   5% 103/1969 [02:40<48:40,  1.57s/it]\u001b[A\n",
      "Iteration:   5% 104/1969 [02:42<48:37,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 105/1969 [02:43<48:36,  1.56s/it]\u001b[A\n",
      "Iteration:   5% 106/1969 [02:45<48:39,  1.57s/it]\u001b[A\n",
      "Iteration:   5% 107/1969 [02:47<48:37,  1.57s/it]\u001b[A\n",
      "Iteration:   5% 108/1969 [02:48<48:32,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 109/1969 [02:50<48:29,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 110/1969 [02:51<48:28,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 111/1969 [02:53<48:26,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 112/1969 [02:54<48:23,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 113/1969 [02:56<48:25,  1.57s/it]\u001b[A\n",
      "Iteration:   6% 114/1969 [02:58<48:22,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 115/1969 [02:59<48:20,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 116/1969 [03:01<48:25,  1.57s/it]\u001b[A\n",
      "Iteration:   6% 117/1969 [03:02<48:15,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 118/1969 [03:04<48:17,  1.57s/it]\u001b[A\n",
      "Iteration:   6% 119/1969 [03:05<48:16,  1.57s/it]\u001b[A\n",
      "Iteration:   6% 120/1969 [03:07<48:13,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 121/1969 [03:08<48:09,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 122/1969 [03:10<48:08,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 123/1969 [03:12<48:03,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 124/1969 [03:13<47:56,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 125/1969 [03:15<48:01,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 126/1969 [03:16<47:53,  1.56s/it]\u001b[A\n",
      "Iteration:   6% 127/1969 [03:18<47:51,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 128/1969 [03:19<47:49,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 129/1969 [03:21<47:48,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 130/1969 [03:22<47:43,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 131/1969 [03:24<47:44,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 132/1969 [03:26<47:45,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 133/1969 [03:27<47:41,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 134/1969 [03:29<47:41,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 135/1969 [03:30<47:45,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 136/1969 [03:32<47:43,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 137/1969 [03:33<47:40,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 138/1969 [03:35<47:41,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 139/1969 [03:37<47:41,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 140/1969 [03:38<47:42,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 141/1969 [03:40<47:44,  1.57s/it]\u001b[A\n",
      "Iteration:   7% 142/1969 [03:41<47:38,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 143/1969 [03:43<47:38,  1.57s/it]\u001b[A\n",
      "Iteration:   7% 144/1969 [03:44<47:32,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 145/1969 [03:46<47:30,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 146/1969 [03:48<47:24,  1.56s/it]\u001b[A\n",
      "Iteration:   7% 147/1969 [03:49<47:25,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 148/1969 [03:51<47:20,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 149/1969 [03:52<47:14,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 150/1969 [03:54<47:11,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 151/1969 [03:55<47:10,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 152/1969 [03:57<47:06,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 153/1969 [03:58<47:07,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 154/1969 [04:00<47:05,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 155/1969 [04:02<47:07,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 156/1969 [04:03<47:05,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 157/1969 [04:05<47:04,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 158/1969 [04:06<47:05,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 159/1969 [04:08<47:08,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 160/1969 [04:09<47:08,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 161/1969 [04:11<47:07,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 162/1969 [04:12<47:02,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 163/1969 [04:14<46:58,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 164/1969 [04:16<46:57,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 165/1969 [04:17<46:57,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 166/1969 [04:19<46:57,  1.56s/it]\u001b[A\n",
      "Iteration:   8% 167/1969 [04:20<46:57,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 168/1969 [04:22<46:58,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 169/1969 [04:23<46:54,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 170/1969 [04:25<46:54,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 171/1969 [04:27<46:46,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 172/1969 [04:28<46:46,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 173/1969 [04:30<46:44,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 174/1969 [04:31<46:37,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 175/1969 [04:33<46:35,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 176/1969 [04:34<46:37,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 177/1969 [04:36<46:36,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 178/1969 [04:37<46:29,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 179/1969 [04:39<46:29,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 180/1969 [04:41<46:29,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 181/1969 [04:42<46:28,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 182/1969 [04:44<46:25,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 183/1969 [04:45<46:28,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 184/1969 [04:47<46:24,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 185/1969 [04:48<46:23,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 186/1969 [04:50<46:28,  1.56s/it]\u001b[A\n",
      "Iteration:   9% 187/1969 [04:51<46:27,  1.56s/it]\u001b[A\n",
      "Iteration:  10% 188/1969 [04:53<46:26,  1.56s/it]\u001b[A\n",
      "Iteration:  10% 189/1969 [04:55<46:33,  1.57s/it]\u001b[A\n",
      "Iteration:  10% 190/1969 [04:56<46:31,  1.57s/it]\u001b[A\n",
      "Iteration:  10% 191/1969 [04:58<46:32,  1.57s/it]\u001b[A\n",
      "Iteration:  10% 192/1969 [04:59<46:32,  1.57s/it]\u001b[A\n",
      "Iteration:  10% 193/1969 [05:01<46:26,  1.57s/it]\u001b[A\n",
      "Iteration:  10% 194/1969 [05:02<46:20,  1.57s/it]\u001b[A\n",
      "Iteration:  10% 195/1969 [05:04<46:15,  1.56s/it]\u001b[A\n",
      "Iteration:  10% 196/1969 [05:06<46:13,  1.56s/it]\u001b[A\n",
      "Iteration:  10% 197/1969 [05:07<46:13,  1.57s/it]\u001b[A\n",
      "Iteration:  10% 198/1969 [05:09<46:13,  1.57s/it]\u001b[A\n",
      "Iteration:  10% 199/1969 [05:10<46:04,  1.56s/it]\u001b[A\n",
      "Iteration:  10% 200/1969 [05:12<46:02,  1.56s/it]\u001b[A\n",
      "Iteration:  10% 201/1969 [05:13<46:02,  1.56s/it]\u001b[A\n",
      "Iteration:  10% 202/1969 [05:15<45:59,  1.56s/it]\u001b[A\n",
      "Iteration:  10% 203/1969 [05:17<45:53,  1.56s/it]\u001b[A\n",
      "Iteration:  10% 204/1969 [05:18<45:51,  1.56s/it]\u001b[A\n",
      "Iteration:  10% 205/1969 [05:20<45:54,  1.56s/it]\u001b[A\n",
      "Iteration:  10% 206/1969 [05:21<45:50,  1.56s/it]\u001b[A\n",
      "Iteration:  11% 207/1969 [05:23<45:48,  1.56s/it]\u001b[A\n",
      "Iteration:  11% 208/1969 [05:24<45:49,  1.56s/it]\u001b[A\n",
      "Iteration:  11% 209/1969 [05:26<45:52,  1.56s/it]\u001b[A\n",
      "Iteration:  11% 210/1969 [05:27<45:58,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 211/1969 [05:29<45:55,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 212/1969 [05:31<45:55,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 213/1969 [05:32<45:54,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 214/1969 [05:34<45:49,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 215/1969 [05:35<45:44,  1.56s/it]\u001b[A\n",
      "Iteration:  11% 216/1969 [05:37<45:40,  1.56s/it]\u001b[A\n",
      "Iteration:  11% 217/1969 [05:38<45:42,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 218/1969 [05:40<45:36,  1.56s/it]\u001b[A\n",
      "Iteration:  11% 219/1969 [05:42<45:33,  1.56s/it]\u001b[A\n",
      "Iteration:  11% 220/1969 [05:43<45:38,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 221/1969 [05:45<45:36,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 222/1969 [05:46<45:38,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 223/1969 [05:48<45:39,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 224/1969 [05:49<45:32,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 225/1969 [05:51<45:33,  1.57s/it]\u001b[A\n",
      "Iteration:  11% 226/1969 [05:53<45:29,  1.57s/it]\u001b[A\n",
      "Iteration:  12% 227/1969 [05:54<45:25,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 228/1969 [05:56<45:21,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 229/1969 [05:57<45:19,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 230/1969 [05:59<45:14,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 231/1969 [06:00<45:15,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 232/1969 [06:02<45:13,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 233/1969 [06:03<45:10,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 234/1969 [06:05<45:10,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 235/1969 [06:07<45:07,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 236/1969 [06:08<45:04,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 237/1969 [06:10<45:03,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 238/1969 [06:11<45:04,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 239/1969 [06:13<44:56,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 240/1969 [06:14<44:54,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 241/1969 [06:16<44:51,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 242/1969 [06:17<44:54,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 243/1969 [06:19<44:51,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 244/1969 [06:21<44:49,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 245/1969 [06:22<44:50,  1.56s/it]\u001b[A\n",
      "Iteration:  12% 246/1969 [06:24<44:47,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 247/1969 [06:25<44:42,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 248/1969 [06:27<44:39,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 249/1969 [06:28<44:39,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 250/1969 [06:30<44:39,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 251/1969 [06:32<44:39,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 252/1969 [06:33<44:37,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 253/1969 [06:35<44:31,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 254/1969 [06:36<44:29,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 255/1969 [06:38<44:29,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 256/1969 [06:39<44:31,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 257/1969 [06:41<44:30,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 258/1969 [06:42<44:29,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 259/1969 [06:44<44:33,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 260/1969 [06:46<44:32,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 261/1969 [06:47<44:28,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 262/1969 [06:49<44:26,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 263/1969 [06:50<44:24,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 264/1969 [06:52<44:26,  1.56s/it]\u001b[A\n",
      "Iteration:  13% 265/1969 [06:53<44:26,  1.57s/it]\u001b[A\n",
      "Iteration:  14% 266/1969 [06:55<44:21,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 267/1969 [06:57<44:20,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 268/1969 [06:58<44:19,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 269/1969 [07:00<44:15,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 270/1969 [07:01<44:09,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 271/1969 [07:03<44:07,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 272/1969 [07:04<44:06,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 273/1969 [07:06<44:02,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 274/1969 [07:07<44:00,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 275/1969 [07:09<44:00,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 276/1969 [07:11<43:58,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 277/1969 [07:12<43:58,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 278/1969 [07:14<44:00,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 279/1969 [07:15<43:56,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 280/1969 [07:17<43:54,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 281/1969 [07:18<43:59,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 282/1969 [07:20<43:52,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 283/1969 [07:21<43:50,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 284/1969 [07:23<43:48,  1.56s/it]\u001b[A\n",
      "Iteration:  14% 285/1969 [07:25<43:47,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 286/1969 [07:26<43:42,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 287/1969 [07:28<43:43,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 288/1969 [07:29<43:44,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 289/1969 [07:31<43:42,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 290/1969 [07:32<43:40,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 291/1969 [07:34<43:37,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 292/1969 [07:36<43:34,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 293/1969 [07:37<43:33,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 294/1969 [07:39<43:35,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 295/1969 [07:40<43:28,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 296/1969 [07:42<43:26,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 297/1969 [07:43<43:23,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 298/1969 [07:45<43:30,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 299/1969 [07:46<43:26,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 300/1969 [07:48<43:21,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 301/1969 [07:50<43:20,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 302/1969 [07:51<43:20,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 303/1969 [07:53<43:22,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 304/1969 [07:54<43:24,  1.56s/it]\u001b[A\n",
      "Iteration:  15% 305/1969 [07:56<43:19,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 306/1969 [07:57<43:17,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 307/1969 [07:59<43:16,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 308/1969 [08:00<43:15,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 309/1969 [08:02<43:11,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 310/1969 [08:04<43:16,  1.57s/it]\u001b[A\n",
      "Iteration:  16% 311/1969 [08:05<43:12,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 312/1969 [08:07<43:06,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 313/1969 [08:08<43:03,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 314/1969 [08:10<43:00,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 315/1969 [08:11<42:57,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 316/1969 [08:13<42:53,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 317/1969 [08:15<42:53,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 318/1969 [08:16<42:50,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 319/1969 [08:18<42:49,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 320/1969 [08:19<42:54,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 321/1969 [08:21<42:50,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 322/1969 [08:22<42:47,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 323/1969 [08:24<42:47,  1.56s/it]\u001b[A\n",
      "Iteration:  16% 324/1969 [08:25<42:49,  1.56s/it]\u001b[A\n",
      "Iteration:  17% 325/1969 [08:27<42:49,  1.56s/it]\u001b[A\n",
      "Iteration:  17% 326/1969 [08:29<42:43,  1.56s/it]\u001b[A\n",
      "Iteration:  17% 327/1969 [08:30<42:44,  1.56s/it]\u001b[A\n",
      "Iteration:  17% 328/1969 [08:32<42:41,  1.56s/it]\u001b[A\n",
      "Iteration:  17% 329/1969 [08:33<42:42,  1.56s/it]\u001b[A\n",
      "Iteration:  17% 330/1969 [08:35<42:37,  1.56s/it]\u001b[A\n",
      "Iteration:  17% 331/1969 [08:36<42:39,  1.56s/it]\u001b[A\n",
      "Iteration:  17% 332/1969 [08:38<42:37,  1.56s/it]\u001b[A\n",
      "Iteration:  17% 333/1969 [08:40<42:42,  1.57s/it]\u001b[A\n",
      "Iteration:  17% 334/1969 [08:41<42:41,  1.57s/it]\u001b[A\n",
      "Iteration:  17% 335/1969 [08:43<42:41,  1.57s/it]\u001b[A\n",
      "Iteration:  17% 336/1969 [08:44<42:40,  1.57s/it]\u001b[A\n",
      "Iteration:  17% 337/1969 [08:46<42:34,  1.57s/it]\u001b[A\n",
      "Iteration:  17% 338/1969 [08:47<42:33,  1.57s/it]\u001b[A\n",
      "Iteration:  17% 339/1969 [08:49<42:34,  1.57s/it]\u001b[A\n",
      "Iteration:  17% 340/1969 [08:50<42:29,  1.57s/it]\u001b[A\n",
      "Iteration:  17% 341/1969 [08:52<42:30,  1.57s/it]\u001b[A\n",
      "Iteration:  17% 342/1969 [08:54<42:29,  1.57s/it]\u001b[A\n",
      "Iteration:  17% 343/1969 [08:55<42:23,  1.56s/it]\u001b[A\n",
      "Iteration:  17% 344/1969 [08:57<42:21,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 345/1969 [08:58<42:17,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 346/1969 [09:00<42:12,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 347/1969 [09:01<42:09,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 348/1969 [09:03<42:11,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 349/1969 [09:05<42:08,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 350/1969 [09:06<42:04,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 351/1969 [09:08<42:09,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 352/1969 [09:09<42:07,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 353/1969 [09:11<42:05,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 354/1969 [09:12<42:04,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 355/1969 [09:14<42:00,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 356/1969 [09:15<42:01,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 357/1969 [09:17<41:57,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 358/1969 [09:19<41:57,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 359/1969 [09:20<41:54,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 360/1969 [09:22<41:54,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 361/1969 [09:23<41:53,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 362/1969 [09:25<41:46,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 363/1969 [09:26<41:43,  1.56s/it]\u001b[A\n",
      "Iteration:  18% 364/1969 [09:28<41:44,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 365/1969 [09:30<41:42,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 366/1969 [09:31<41:40,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 367/1969 [09:33<41:39,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 368/1969 [09:34<41:39,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 369/1969 [09:36<41:36,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 370/1969 [09:37<41:34,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 371/1969 [09:39<41:33,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 372/1969 [09:40<41:29,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 373/1969 [09:42<41:27,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 374/1969 [09:44<41:29,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 375/1969 [09:45<41:28,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 376/1969 [09:47<41:27,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 377/1969 [09:48<41:29,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 378/1969 [09:50<41:27,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 379/1969 [09:51<41:26,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 380/1969 [09:53<41:25,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 381/1969 [09:55<41:24,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 382/1969 [09:56<41:21,  1.56s/it]\u001b[A\n",
      "Iteration:  19% 383/1969 [09:58<41:18,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 384/1969 [09:59<41:15,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 385/1969 [10:01<41:16,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 386/1969 [10:02<41:15,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 387/1969 [10:04<41:14,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 388/1969 [10:05<41:14,  1.57s/it]\u001b[A\n",
      "Iteration:  20% 389/1969 [10:07<41:14,  1.57s/it]\u001b[A\n",
      "Iteration:  20% 390/1969 [10:09<41:11,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 391/1969 [10:10<41:06,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 392/1969 [10:12<41:02,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 393/1969 [10:13<41:03,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 394/1969 [10:15<40:59,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 395/1969 [10:16<40:55,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 396/1969 [10:18<41:00,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 397/1969 [10:20<40:56,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 398/1969 [10:21<40:58,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 399/1969 [10:23<40:56,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 400/1969 [10:24<40:53,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 401/1969 [10:26<40:53,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 402/1969 [10:27<40:52,  1.56s/it]\u001b[A\n",
      "Iteration:  20% 403/1969 [10:29<40:48,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 404/1969 [10:30<40:43,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 405/1969 [10:32<40:42,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 406/1969 [10:34<40:39,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 407/1969 [10:35<40:36,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 408/1969 [10:37<40:39,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 409/1969 [10:38<40:31,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 410/1969 [10:40<40:29,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 411/1969 [10:41<40:32,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 412/1969 [10:43<40:28,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 413/1969 [10:44<40:23,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 414/1969 [10:46<40:22,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 415/1969 [10:48<40:23,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 416/1969 [10:49<40:23,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 417/1969 [10:51<40:22,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 418/1969 [10:52<40:27,  1.57s/it]\u001b[A\n",
      "Iteration:  21% 419/1969 [10:54<40:27,  1.57s/it]\u001b[A\n",
      "Iteration:  21% 420/1969 [10:55<40:26,  1.57s/it]\u001b[A\n",
      "Iteration:  21% 421/1969 [10:57<40:27,  1.57s/it]\u001b[A\n",
      "Iteration:  21% 422/1969 [10:59<40:20,  1.56s/it]\u001b[A\n",
      "Iteration:  21% 423/1969 [11:00<40:18,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 424/1969 [11:02<40:13,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 425/1969 [11:03<40:10,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 426/1969 [11:05<40:10,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 427/1969 [11:06<40:10,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 428/1969 [11:08<40:10,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 429/1969 [11:10<40:04,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 430/1969 [11:11<40:04,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 431/1969 [11:13<40:00,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 432/1969 [11:14<39:59,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 433/1969 [11:16<39:55,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 434/1969 [11:17<39:54,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 435/1969 [11:19<39:51,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 436/1969 [11:20<39:49,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 437/1969 [11:22<39:47,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 438/1969 [11:24<39:43,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 439/1969 [11:25<39:43,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 440/1969 [11:27<39:45,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 441/1969 [11:28<39:40,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 442/1969 [11:30<39:40,  1.56s/it]\u001b[A\n",
      "Iteration:  22% 443/1969 [11:31<39:39,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 444/1969 [11:33<39:37,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 445/1969 [11:34<39:32,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 446/1969 [11:36<39:33,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 447/1969 [11:38<39:32,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 448/1969 [11:39<39:36,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 449/1969 [11:41<39:31,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 450/1969 [11:42<39:33,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 451/1969 [11:44<39:27,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 452/1969 [11:45<39:26,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 453/1969 [11:47<39:26,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 454/1969 [11:48<39:25,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 455/1969 [11:50<39:23,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 456/1969 [11:52<39:22,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 457/1969 [11:53<39:23,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 458/1969 [11:55<39:20,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 459/1969 [11:56<39:18,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 460/1969 [11:58<39:17,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 461/1969 [11:59<39:16,  1.56s/it]\u001b[A\n",
      "Iteration:  23% 462/1969 [12:01<39:15,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 463/1969 [12:03<39:10,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 464/1969 [12:04<39:06,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 465/1969 [12:06<39:04,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 466/1969 [12:07<39:04,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 467/1969 [12:09<39:01,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 468/1969 [12:10<38:58,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 469/1969 [12:12<38:56,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 470/1969 [12:13<38:59,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 471/1969 [12:15<38:57,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 472/1969 [12:17<38:53,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 473/1969 [12:18<38:59,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 474/1969 [12:20<38:53,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 475/1969 [12:21<38:52,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 476/1969 [12:23<38:49,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 477/1969 [12:24<38:45,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 478/1969 [12:26<38:43,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 479/1969 [12:28<38:42,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 480/1969 [12:29<38:43,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 481/1969 [12:31<38:38,  1.56s/it]\u001b[A\n",
      "Iteration:  24% 482/1969 [12:32<38:42,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 483/1969 [12:34<38:42,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 484/1969 [12:35<38:39,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 485/1969 [12:37<38:37,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 486/1969 [12:38<38:38,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 487/1969 [12:40<38:37,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 488/1969 [12:42<38:35,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 489/1969 [12:43<38:34,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 490/1969 [12:45<38:29,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 491/1969 [12:46<38:30,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 492/1969 [12:48<38:29,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 493/1969 [12:49<38:25,  1.56s/it]\u001b[A\n",
      "Iteration:  25% 494/1969 [12:51<38:30,  1.57s/it]\u001b[A\n",
      "Iteration:  25% 495/1969 [12:53<38:31,  1.57s/it]\u001b[A\n",
      "Iteration:  25% 496/1969 [12:54<38:29,  1.57s/it]\u001b[A\n",
      "Iteration:  25% 497/1969 [12:56<38:27,  1.57s/it]\u001b[A\n",
      "Iteration:  25% 498/1969 [12:57<38:29,  1.57s/it]\u001b[A\n",
      "Iteration:  25% 499/1969 [12:59<38:24,  1.57s/it]\u001b[A\n",
      "Iteration:  25% 500/1969 [13:00<38:19,  1.57s/it]\u001b[A\n",
      "Iteration:  25% 501/1969 [13:02<38:18,  1.57s/it]\u001b[A\n",
      "Iteration:  25% 502/1969 [13:03<38:16,  1.57s/it]\u001b[A\n",
      "Iteration:  26% 503/1969 [13:05<38:13,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 504/1969 [13:07<38:11,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 505/1969 [13:08<38:10,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 506/1969 [13:10<38:08,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 507/1969 [13:11<38:08,  1.57s/it]\u001b[A\n",
      "Iteration:  26% 508/1969 [13:13<38:03,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 509/1969 [13:14<38:00,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 510/1969 [13:16<38:00,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 511/1969 [13:18<37:59,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 512/1969 [13:19<37:55,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 513/1969 [13:21<37:53,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 514/1969 [13:22<37:54,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 515/1969 [13:24<37:56,  1.57s/it]\u001b[A\n",
      "Iteration:  26% 516/1969 [13:25<37:53,  1.56s/it]\u001b[A\n",
      "Iteration:  26% 517/1969 [13:27<37:53,  1.57s/it]\u001b[A\n",
      "Iteration:  26% 518/1969 [13:29<37:51,  1.57s/it]\u001b[A\n",
      "Iteration:  26% 519/1969 [13:30<37:53,  1.57s/it]\u001b[A\n",
      "Iteration:  26% 520/1969 [13:32<37:49,  1.57s/it]\u001b[A\n",
      "Iteration:  26% 521/1969 [13:33<37:46,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 522/1969 [13:35<37:45,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 523/1969 [13:36<37:44,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 524/1969 [13:38<37:40,  1.56s/it]\u001b[A\n",
      "Iteration:  27% 525/1969 [13:39<37:38,  1.56s/it]\u001b[A\n",
      "Iteration:  27% 526/1969 [13:41<37:37,  1.56s/it]\u001b[A\n",
      "Iteration:  27% 527/1969 [13:43<37:35,  1.56s/it]\u001b[A\n",
      "Iteration:  27% 528/1969 [13:44<37:34,  1.56s/it]\u001b[A\n",
      "Iteration:  27% 529/1969 [13:46<37:33,  1.56s/it]\u001b[A\n",
      "Iteration:  27% 530/1969 [13:47<37:32,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 531/1969 [13:49<37:34,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 532/1969 [13:50<37:32,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 533/1969 [13:52<37:30,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 534/1969 [13:54<37:34,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 535/1969 [13:55<37:30,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 536/1969 [13:57<37:28,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 537/1969 [13:58<37:26,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 538/1969 [14:00<37:25,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 539/1969 [14:01<37:23,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 540/1969 [14:03<37:19,  1.57s/it]\u001b[A\n",
      "Iteration:  27% 541/1969 [14:05<37:17,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 542/1969 [14:06<37:16,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 543/1969 [14:08<37:12,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 544/1969 [14:09<37:09,  1.56s/it]\u001b[A\n",
      "Iteration:  28% 545/1969 [14:11<37:10,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 546/1969 [14:12<37:06,  1.56s/it]\u001b[A\n",
      "Iteration:  28% 547/1969 [14:14<37:03,  1.56s/it]\u001b[A\n",
      "Iteration:  28% 548/1969 [14:15<36:59,  1.56s/it]\u001b[A\n",
      "Iteration:  28% 549/1969 [14:17<37:00,  1.56s/it]\u001b[A\n",
      "Iteration:  28% 550/1969 [14:19<36:59,  1.56s/it]\u001b[A\n",
      "Iteration:  28% 551/1969 [14:20<37:00,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 552/1969 [14:22<37:00,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 553/1969 [14:23<36:57,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 554/1969 [14:25<36:59,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 555/1969 [14:26<36:56,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 556/1969 [14:28<36:53,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 557/1969 [14:30<36:58,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 558/1969 [14:31<36:55,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 559/1969 [14:33<36:52,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 560/1969 [14:34<36:50,  1.57s/it]\u001b[A\n",
      "Iteration:  28% 561/1969 [14:36<36:47,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 562/1969 [14:37<36:44,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 563/1969 [14:39<36:41,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 564/1969 [14:41<36:37,  1.56s/it]\u001b[A\n",
      "Iteration:  29% 565/1969 [14:42<36:38,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 566/1969 [14:44<36:39,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 567/1969 [14:45<36:36,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 568/1969 [14:47<36:34,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 569/1969 [14:48<36:32,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 570/1969 [14:50<36:27,  1.56s/it]\u001b[A\n",
      "Iteration:  29% 571/1969 [14:52<36:24,  1.56s/it]\u001b[A\n",
      "Iteration:  29% 572/1969 [14:53<36:25,  1.56s/it]\u001b[A\n",
      "Iteration:  29% 573/1969 [14:55<36:24,  1.56s/it]\u001b[A\n",
      "Iteration:  29% 574/1969 [14:56<36:24,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 575/1969 [14:58<36:22,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 576/1969 [14:59<36:24,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 577/1969 [15:01<36:22,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 578/1969 [15:02<36:18,  1.57s/it]\u001b[A\n",
      "Iteration:  29% 579/1969 [15:04<36:13,  1.56s/it]\u001b[A\n",
      "Iteration:  29% 580/1969 [15:06<36:13,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 581/1969 [15:07<36:11,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 582/1969 [15:09<36:07,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 583/1969 [15:10<36:03,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 584/1969 [15:12<36:05,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 585/1969 [15:13<36:01,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 586/1969 [15:15<35:59,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 587/1969 [15:17<35:57,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 588/1969 [15:18<35:54,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 589/1969 [15:20<35:53,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 590/1969 [15:21<35:54,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 591/1969 [15:23<35:52,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 592/1969 [15:24<35:49,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 593/1969 [15:26<35:51,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 594/1969 [15:27<35:50,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 595/1969 [15:29<35:43,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 596/1969 [15:31<35:41,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 597/1969 [15:32<35:41,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 598/1969 [15:34<35:39,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 599/1969 [15:35<35:42,  1.56s/it]\u001b[A\n",
      "Iteration:  30% 600/1969 [15:37<35:40,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 601/1969 [15:38<35:38,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 602/1969 [15:40<35:34,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 603/1969 [15:42<35:33,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 604/1969 [15:43<35:29,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 605/1969 [15:45<35:27,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 606/1969 [15:46<35:28,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 607/1969 [15:48<35:28,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 608/1969 [15:49<35:25,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 609/1969 [15:51<35:24,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 610/1969 [15:52<35:23,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 611/1969 [15:54<35:20,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 612/1969 [15:56<35:19,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 613/1969 [15:57<35:24,  1.57s/it]\u001b[A\n",
      "Iteration:  31% 614/1969 [15:59<35:23,  1.57s/it]\u001b[A\n",
      "Iteration:  31% 615/1969 [16:00<35:19,  1.57s/it]\u001b[A\n",
      "Iteration:  31% 616/1969 [16:02<35:18,  1.57s/it]\u001b[A\n",
      "Iteration:  31% 617/1969 [16:03<35:15,  1.56s/it]\u001b[A\n",
      "Iteration:  31% 618/1969 [16:05<35:14,  1.57s/it]\u001b[A\n",
      "Iteration:  31% 619/1969 [16:07<35:15,  1.57s/it]\u001b[A\n",
      "Iteration:  31% 620/1969 [16:08<35:12,  1.57s/it]\u001b[A\n",
      "Iteration:  32% 621/1969 [16:10<35:12,  1.57s/it]\u001b[A\n",
      "Iteration:  32% 622/1969 [16:11<35:12,  1.57s/it]\u001b[A\n",
      "Iteration:  32% 623/1969 [16:13<35:05,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 624/1969 [16:14<35:04,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 625/1969 [16:16<35:01,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 626/1969 [16:18<34:59,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 627/1969 [16:19<34:54,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 628/1969 [16:21<34:50,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 629/1969 [16:22<34:48,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 630/1969 [16:24<34:48,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 631/1969 [16:25<34:49,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 632/1969 [16:27<34:48,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 633/1969 [16:28<34:46,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 634/1969 [16:30<34:47,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 635/1969 [16:32<34:43,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 636/1969 [16:33<34:40,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 637/1969 [16:35<34:36,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 638/1969 [16:36<34:38,  1.56s/it]\u001b[A\n",
      "Iteration:  32% 639/1969 [16:38<34:36,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 640/1969 [16:39<34:36,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 641/1969 [16:41<34:36,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 642/1969 [16:42<34:30,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 643/1969 [16:44<34:35,  1.57s/it]\u001b[A\n",
      "Iteration:  33% 644/1969 [16:46<34:33,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 645/1969 [16:47<34:32,  1.57s/it]\u001b[A\n",
      "Iteration:  33% 646/1969 [16:49<34:28,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 647/1969 [16:50<34:29,  1.57s/it]\u001b[A\n",
      "Iteration:  33% 648/1969 [16:52<34:27,  1.57s/it]\u001b[A\n",
      "Iteration:  33% 649/1969 [16:53<34:25,  1.57s/it]\u001b[A\n",
      "Iteration:  33% 650/1969 [16:55<34:25,  1.57s/it]\u001b[A\n",
      "Iteration:  33% 651/1969 [16:57<34:20,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 652/1969 [16:58<34:19,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 653/1969 [17:00<34:20,  1.57s/it]\u001b[A\n",
      "Iteration:  33% 654/1969 [17:01<34:15,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 655/1969 [17:03<34:16,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 656/1969 [17:04<34:12,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 657/1969 [17:06<34:09,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 658/1969 [17:08<34:10,  1.56s/it]\u001b[A\n",
      "Iteration:  33% 659/1969 [17:09<34:09,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 660/1969 [17:11<34:04,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 661/1969 [17:12<34:02,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 662/1969 [17:14<34:03,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 663/1969 [17:15<34:00,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 664/1969 [17:17<33:57,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 665/1969 [17:18<33:54,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 666/1969 [17:20<33:55,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 667/1969 [17:22<33:51,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 668/1969 [17:23<33:51,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 669/1969 [17:25<33:49,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 670/1969 [17:26<33:49,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 671/1969 [17:28<33:48,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 672/1969 [17:29<33:46,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 673/1969 [17:31<33:41,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 674/1969 [17:33<33:39,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 675/1969 [17:34<33:37,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 676/1969 [17:36<33:36,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 677/1969 [17:37<33:35,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 678/1969 [17:39<33:31,  1.56s/it]\u001b[A\n",
      "Iteration:  34% 679/1969 [17:40<33:31,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 680/1969 [17:42<33:29,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 681/1969 [17:43<33:27,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 682/1969 [17:45<33:24,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 683/1969 [17:47<33:24,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 684/1969 [17:48<33:20,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 685/1969 [17:50<33:21,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 686/1969 [17:51<33:20,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 687/1969 [17:53<33:19,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 688/1969 [17:54<33:20,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 689/1969 [17:56<33:20,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 690/1969 [17:57<33:15,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 691/1969 [17:59<33:14,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 692/1969 [18:01<33:14,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 693/1969 [18:02<33:13,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 694/1969 [18:04<33:11,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 695/1969 [18:05<33:11,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 696/1969 [18:07<33:06,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 697/1969 [18:08<33:06,  1.56s/it]\u001b[A\n",
      "Iteration:  35% 698/1969 [18:10<33:05,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 699/1969 [18:12<33:01,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 700/1969 [18:13<32:58,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 701/1969 [18:15<32:59,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 702/1969 [18:16<32:55,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 703/1969 [18:18<32:49,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 704/1969 [18:19<32:46,  1.55s/it]\u001b[A\n",
      "Iteration:  36% 705/1969 [18:21<32:48,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 706/1969 [18:22<32:47,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 707/1969 [18:24<32:45,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 708/1969 [18:26<32:48,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 709/1969 [18:27<32:45,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 710/1969 [18:29<32:47,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 711/1969 [18:30<32:48,  1.57s/it]\u001b[A\n",
      "Iteration:  36% 712/1969 [18:32<32:44,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 713/1969 [18:33<32:44,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 714/1969 [18:35<32:42,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 715/1969 [18:36<32:38,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 716/1969 [18:38<32:39,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 717/1969 [18:40<32:35,  1.56s/it]\u001b[A\n",
      "Iteration:  36% 718/1969 [18:41<32:39,  1.57s/it]\u001b[A\n",
      "Iteration:  37% 719/1969 [18:43<32:33,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 720/1969 [18:44<32:32,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 721/1969 [18:46<32:30,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 722/1969 [18:47<32:26,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 723/1969 [18:49<32:21,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 724/1969 [18:51<32:20,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 725/1969 [18:52<32:19,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 726/1969 [18:54<32:21,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 727/1969 [18:55<32:21,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 728/1969 [18:57<32:16,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 729/1969 [18:58<32:15,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 730/1969 [19:00<32:15,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 731/1969 [19:01<32:18,  1.57s/it]\u001b[A\n",
      "Iteration:  37% 732/1969 [19:03<32:16,  1.57s/it]\u001b[A\n",
      "Iteration:  37% 733/1969 [19:05<32:15,  1.57s/it]\u001b[A\n",
      "Iteration:  37% 734/1969 [19:06<32:14,  1.57s/it]\u001b[A\n",
      "Iteration:  37% 735/1969 [19:08<32:16,  1.57s/it]\u001b[A\n",
      "Iteration:  37% 736/1969 [19:09<32:12,  1.57s/it]\u001b[A\n",
      "Iteration:  37% 737/1969 [19:11<32:04,  1.56s/it]\u001b[A\n",
      "Iteration:  37% 738/1969 [19:12<32:01,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 739/1969 [19:14<32:03,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 740/1969 [19:16<32:01,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 741/1969 [19:17<32:01,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 742/1969 [19:19<32:00,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 743/1969 [19:20<31:59,  1.57s/it]\u001b[A\n",
      "Iteration:  38% 744/1969 [19:22<31:54,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 745/1969 [19:23<31:51,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 746/1969 [19:25<31:52,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 747/1969 [19:27<31:48,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 748/1969 [19:28<31:46,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 749/1969 [19:30<31:43,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 750/1969 [19:31<31:40,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 751/1969 [19:33<31:39,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 752/1969 [19:34<31:40,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 753/1969 [19:36<31:36,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 754/1969 [19:37<31:32,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 755/1969 [19:39<31:31,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 756/1969 [19:41<31:31,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 757/1969 [19:42<31:26,  1.56s/it]\u001b[A\n",
      "Iteration:  38% 758/1969 [19:44<31:23,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 759/1969 [19:45<31:24,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 760/1969 [19:47<31:22,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 761/1969 [19:48<31:22,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 762/1969 [19:50<31:20,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 763/1969 [19:51<31:19,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 764/1969 [19:53<31:20,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 765/1969 [19:55<31:22,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 766/1969 [19:56<31:25,  1.57s/it]\u001b[A\n",
      "Iteration:  39% 767/1969 [19:58<31:20,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 768/1969 [19:59<31:21,  1.57s/it]\u001b[A\n",
      "Iteration:  39% 769/1969 [20:01<31:16,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 770/1969 [20:02<31:12,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 771/1969 [20:04<31:08,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 772/1969 [20:06<31:07,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 773/1969 [20:07<31:03,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 774/1969 [20:09<31:01,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 775/1969 [20:10<31:00,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 776/1969 [20:12<30:59,  1.56s/it]\u001b[A\n",
      "Iteration:  39% 777/1969 [20:13<31:00,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 778/1969 [20:15<30:58,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 779/1969 [20:16<30:56,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 780/1969 [20:18<30:53,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 781/1969 [20:20<30:53,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 782/1969 [20:21<30:51,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 783/1969 [20:23<30:49,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 784/1969 [20:24<30:46,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 785/1969 [20:26<30:44,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 786/1969 [20:27<30:42,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 787/1969 [20:29<30:39,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 788/1969 [20:30<30:36,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 789/1969 [20:32<30:38,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 790/1969 [20:34<30:37,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 791/1969 [20:35<30:36,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 792/1969 [20:37<30:35,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 793/1969 [20:38<30:32,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 794/1969 [20:40<30:30,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 795/1969 [20:41<30:34,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 796/1969 [20:43<30:33,  1.56s/it]\u001b[A\n",
      "Iteration:  40% 797/1969 [20:44<30:28,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 798/1969 [20:46<30:26,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 799/1969 [20:48<30:24,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 800/1969 [20:49<30:20,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 801/1969 [20:51<30:17,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 802/1969 [20:52<30:18,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 803/1969 [20:54<30:19,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 804/1969 [20:55<30:17,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 805/1969 [20:57<30:15,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 806/1969 [20:59<30:13,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 807/1969 [21:00<30:14,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 808/1969 [21:02<30:16,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 809/1969 [21:03<30:16,  1.57s/it]\u001b[A\n",
      "Iteration:  41% 810/1969 [21:05<30:10,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 811/1969 [21:06<30:06,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 812/1969 [21:08<30:07,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 813/1969 [21:09<30:05,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 814/1969 [21:11<30:03,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 815/1969 [21:13<30:02,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 816/1969 [21:14<30:04,  1.56s/it]\u001b[A\n",
      "Iteration:  41% 817/1969 [21:16<29:59,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 818/1969 [21:17<29:59,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 819/1969 [21:19<29:54,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 820/1969 [21:20<29:51,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 821/1969 [21:22<29:50,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 822/1969 [21:23<29:48,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 823/1969 [21:25<29:44,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 824/1969 [21:27<29:44,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 825/1969 [21:28<29:44,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 826/1969 [21:30<29:40,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 827/1969 [21:31<29:38,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 828/1969 [21:33<29:39,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 829/1969 [21:34<29:36,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 830/1969 [21:36<29:33,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 831/1969 [21:38<29:31,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 832/1969 [21:39<29:31,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 833/1969 [21:41<29:29,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 834/1969 [21:42<29:27,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 835/1969 [21:44<29:26,  1.56s/it]\u001b[A\n",
      "Iteration:  42% 836/1969 [21:45<29:23,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 837/1969 [21:47<29:23,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 838/1969 [21:48<29:24,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 839/1969 [21:50<29:23,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 840/1969 [21:52<29:19,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 841/1969 [21:53<29:22,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 842/1969 [21:55<29:22,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 843/1969 [21:56<29:22,  1.57s/it]\u001b[A\n",
      "Iteration:  43% 844/1969 [21:58<29:20,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 845/1969 [21:59<29:19,  1.57s/it]\u001b[A\n",
      "Iteration:  43% 846/1969 [22:01<29:14,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 847/1969 [22:03<29:14,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 848/1969 [22:04<29:10,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 849/1969 [22:06<29:11,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 850/1969 [22:07<29:09,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 851/1969 [22:09<29:11,  1.57s/it]\u001b[A\n",
      "Iteration:  43% 852/1969 [22:10<29:06,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 853/1969 [22:12<29:06,  1.57s/it]\u001b[A\n",
      "Iteration:  43% 854/1969 [22:13<29:07,  1.57s/it]\u001b[A\n",
      "Iteration:  43% 855/1969 [22:15<29:03,  1.56s/it]\u001b[A\n",
      "Iteration:  43% 856/1969 [22:17<28:59,  1.56s/it]\u001b[A\n",
      "Iteration:  44% 857/1969 [22:18<29:03,  1.57s/it]\u001b[A\n",
      "Iteration:  44% 858/1969 [22:20<28:59,  1.57s/it]\u001b[A\n",
      "Iteration:  44% 859/1969 [22:21<28:57,  1.57s/it]\u001b[A\n",
      "Iteration:  44% 860/1969 [22:23<28:57,  1.57s/it]\u001b[A\n",
      "Iteration:  44% 861/1969 [22:24<28:55,  1.57s/it]\u001b[A\n",
      "Iteration:  44% 862/1969 [22:26<28:58,  1.57s/it]\u001b[A\n",
      "Iteration:  44% 863/1969 [22:28<28:54,  1.57s/it]\u001b[A\n",
      "Iteration:  44% 864/1969 [22:29<28:51,  1.57s/it]\u001b[A\n",
      "Iteration:  44% 865/1969 [22:31<28:51,  1.57s/it]\u001b[A\n",
      "Iteration:  44% 866/1969 [22:32<28:48,  1.57s/it]\u001b[A\n",
      "Iteration:  44% 867/1969 [22:34<28:44,  1.57s/it]\u001b[A\n",
      "Iteration:  44% 868/1969 [22:35<28:42,  1.56s/it]\u001b[A\n",
      "Iteration:  44% 869/1969 [22:37<28:39,  1.56s/it]\u001b[A\n",
      "Iteration:  44% 870/1969 [22:39<28:36,  1.56s/it]\u001b[A\n",
      "Iteration:  44% 871/1969 [22:40<28:34,  1.56s/it]\u001b[A\n",
      "Iteration:  44% 872/1969 [22:42<28:34,  1.56s/it]\u001b[A\n",
      "Iteration:  44% 873/1969 [22:43<28:30,  1.56s/it]\u001b[A\n",
      "Iteration:  44% 874/1969 [22:45<28:31,  1.56s/it]\u001b[A\n",
      "Iteration:  44% 875/1969 [22:46<28:29,  1.56s/it]\u001b[A\n",
      "Iteration:  44% 876/1969 [22:48<28:25,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 877/1969 [22:49<28:25,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 878/1969 [22:51<28:28,  1.57s/it]\u001b[A\n",
      "Iteration:  45% 879/1969 [22:53<28:26,  1.57s/it]\u001b[A\n",
      "Iteration:  45% 880/1969 [22:54<28:23,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 881/1969 [22:56<28:20,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 882/1969 [22:57<28:19,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 883/1969 [22:59<28:21,  1.57s/it]\u001b[A\n",
      "Iteration:  45% 884/1969 [23:00<28:20,  1.57s/it]\u001b[A\n",
      "Iteration:  45% 885/1969 [23:02<28:19,  1.57s/it]\u001b[A\n",
      "Iteration:  45% 886/1969 [23:04<28:18,  1.57s/it]\u001b[A\n",
      "Iteration:  45% 887/1969 [23:05<28:15,  1.57s/it]\u001b[A\n",
      "Iteration:  45% 888/1969 [23:07<28:10,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 889/1969 [23:08<28:09,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 890/1969 [23:10<28:07,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 891/1969 [23:11<28:03,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 892/1969 [23:13<27:59,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 893/1969 [23:14<27:58,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 894/1969 [23:16<27:56,  1.56s/it]\u001b[A\n",
      "Iteration:  45% 895/1969 [23:18<27:54,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 896/1969 [23:19<27:52,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 897/1969 [23:21<27:51,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 898/1969 [23:22<27:49,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 899/1969 [23:24<27:49,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 900/1969 [23:25<27:49,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 901/1969 [23:27<27:47,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 902/1969 [23:29<27:44,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 903/1969 [23:30<27:43,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 904/1969 [23:32<27:41,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 905/1969 [23:33<27:38,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 906/1969 [23:35<27:35,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 907/1969 [23:36<27:35,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 908/1969 [23:38<27:33,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 909/1969 [23:39<27:32,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 910/1969 [23:41<27:34,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 911/1969 [23:43<27:30,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 912/1969 [23:44<27:30,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 913/1969 [23:46<27:27,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 914/1969 [23:47<27:25,  1.56s/it]\u001b[A\n",
      "Iteration:  46% 915/1969 [23:49<27:23,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 916/1969 [23:50<27:25,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 917/1969 [23:52<27:22,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 918/1969 [23:53<27:21,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 919/1969 [23:55<27:20,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 920/1969 [23:57<27:19,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 921/1969 [23:58<27:18,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 922/1969 [24:00<27:15,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 923/1969 [24:01<27:17,  1.57s/it]\u001b[A\n",
      "Iteration:  47% 924/1969 [24:03<27:13,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 925/1969 [24:04<27:10,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 926/1969 [24:06<27:09,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 927/1969 [24:08<27:07,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 928/1969 [24:09<27:06,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 929/1969 [24:11<27:06,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 930/1969 [24:12<27:04,  1.56s/it]\u001b[A\n",
      "Iteration:  47% 931/1969 [24:14<27:07,  1.57s/it]\u001b[A\n",
      "Iteration:  47% 932/1969 [24:15<27:06,  1.57s/it]\u001b[A\n",
      "Iteration:  47% 933/1969 [24:17<27:10,  1.57s/it]\u001b[A\n",
      "Iteration:  47% 934/1969 [24:19<27:07,  1.57s/it]\u001b[A\n",
      "Iteration:  47% 935/1969 [24:20<27:03,  1.57s/it]\u001b[A\n",
      "Iteration:  48% 936/1969 [24:22<26:59,  1.57s/it]\u001b[A\n",
      "Iteration:  48% 937/1969 [24:23<26:57,  1.57s/it]\u001b[A\n",
      "Iteration:  48% 938/1969 [24:25<26:51,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 939/1969 [24:26<26:49,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 940/1969 [24:28<26:48,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 941/1969 [24:29<26:45,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 942/1969 [24:31<26:41,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 943/1969 [24:33<26:40,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 944/1969 [24:34<26:40,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 945/1969 [24:36<26:37,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 946/1969 [24:37<26:34,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 947/1969 [24:39<26:32,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 948/1969 [24:40<26:31,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 949/1969 [24:42<26:28,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 950/1969 [24:43<26:25,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 951/1969 [24:45<26:24,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 952/1969 [24:47<26:25,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 953/1969 [24:48<26:25,  1.56s/it]\u001b[A\n",
      "Iteration:  48% 954/1969 [24:50<26:24,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 955/1969 [24:51<26:22,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 956/1969 [24:53<26:20,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 957/1969 [24:54<26:21,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 958/1969 [24:56<26:20,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 959/1969 [24:58<26:15,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 960/1969 [24:59<26:17,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 961/1969 [25:01<26:11,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 962/1969 [25:02<26:11,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 963/1969 [25:04<26:08,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 964/1969 [25:05<26:07,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 965/1969 [25:07<26:05,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 966/1969 [25:08<26:04,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 967/1969 [25:10<26:03,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 968/1969 [25:12<25:59,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 969/1969 [25:13<25:57,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 970/1969 [25:15<25:55,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 971/1969 [25:16<25:53,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 972/1969 [25:18<25:49,  1.55s/it]\u001b[A\n",
      "Iteration:  49% 973/1969 [25:19<25:50,  1.56s/it]\u001b[A\n",
      "Iteration:  49% 974/1969 [25:21<25:47,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 975/1969 [25:22<25:45,  1.55s/it]\u001b[A\n",
      "Iteration:  50% 976/1969 [25:24<25:43,  1.55s/it]\u001b[A\n",
      "Iteration:  50% 977/1969 [25:26<25:41,  1.55s/it]\u001b[A\n",
      "Iteration:  50% 978/1969 [25:27<25:41,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 979/1969 [25:29<25:39,  1.55s/it]\u001b[A\n",
      "Iteration:  50% 980/1969 [25:30<25:37,  1.55s/it]\u001b[A\n",
      "Iteration:  50% 981/1969 [25:32<25:36,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 982/1969 [25:33<25:35,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 983/1969 [25:35<25:32,  1.55s/it]\u001b[A\n",
      "Iteration:  50% 984/1969 [25:36<25:34,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 985/1969 [25:38<25:33,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 986/1969 [25:40<25:30,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 987/1969 [25:41<25:28,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 988/1969 [25:43<25:29,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 989/1969 [25:44<25:27,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 990/1969 [25:46<25:23,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 991/1969 [25:47<25:22,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 992/1969 [25:49<25:23,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 993/1969 [25:50<25:22,  1.56s/it]\u001b[A\n",
      "Iteration:  50% 994/1969 [25:52<25:20,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 995/1969 [25:54<25:19,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 996/1969 [25:55<25:16,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 997/1969 [25:57<25:15,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 998/1969 [25:58<25:14,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 999/1969 [26:00<25:11,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1000/1969 [26:01<25:08,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1001/1969 [26:03<25:06,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1002/1969 [26:05<25:05,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1003/1969 [26:06<25:05,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1004/1969 [26:08<25:05,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1005/1969 [26:09<25:05,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1006/1969 [26:11<25:00,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1007/1969 [26:12<24:58,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1008/1969 [26:14<24:54,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1009/1969 [26:15<24:54,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1010/1969 [26:17<24:51,  1.55s/it]\u001b[A\n",
      "Iteration:  51% 1011/1969 [26:19<24:50,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1012/1969 [26:20<24:49,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1013/1969 [26:22<24:47,  1.56s/it]\u001b[A\n",
      "Iteration:  51% 1014/1969 [26:23<24:45,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1015/1969 [26:25<24:44,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1016/1969 [26:26<24:45,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1017/1969 [26:28<24:40,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1018/1969 [26:29<24:37,  1.55s/it]\u001b[A\n",
      "Iteration:  52% 1019/1969 [26:31<24:36,  1.55s/it]\u001b[A\n",
      "Iteration:  52% 1020/1969 [26:33<24:38,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1021/1969 [26:34<24:36,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1022/1969 [26:36<24:36,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1023/1969 [26:37<24:34,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1024/1969 [26:39<24:33,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1025/1969 [26:40<24:30,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1026/1969 [26:42<24:29,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1027/1969 [26:43<24:26,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1028/1969 [26:45<24:24,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1029/1969 [26:47<24:23,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1030/1969 [26:48<24:22,  1.56s/it]\u001b[A\n",
      "Iteration:  52% 1031/1969 [26:50<24:17,  1.55s/it]\u001b[A\n",
      "Iteration:  52% 1032/1969 [26:51<24:14,  1.55s/it]\u001b[A\n",
      "Iteration:  52% 1033/1969 [26:53<24:15,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1034/1969 [26:54<24:15,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1035/1969 [26:56<24:13,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1036/1969 [26:57<24:10,  1.55s/it]\u001b[A\n",
      "Iteration:  53% 1037/1969 [26:59<24:09,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1038/1969 [27:01<24:09,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1039/1969 [27:02<24:06,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1040/1969 [27:04<24:06,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1041/1969 [27:05<24:06,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1042/1969 [27:07<24:02,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1043/1969 [27:08<24:00,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1044/1969 [27:10<23:58,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1045/1969 [27:11<23:56,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1046/1969 [27:13<23:55,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1047/1969 [27:15<23:52,  1.55s/it]\u001b[A\n",
      "Iteration:  53% 1048/1969 [27:16<23:52,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1049/1969 [27:18<23:49,  1.55s/it]\u001b[A\n",
      "Iteration:  53% 1050/1969 [27:19<23:48,  1.55s/it]\u001b[A\n",
      "Iteration:  53% 1051/1969 [27:21<23:46,  1.55s/it]\u001b[A\n",
      "Iteration:  53% 1052/1969 [27:22<23:47,  1.56s/it]\u001b[A\n",
      "Iteration:  53% 1053/1969 [27:24<23:48,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1054/1969 [27:25<23:48,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1055/1969 [27:27<23:48,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1056/1969 [27:29<23:44,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1057/1969 [27:30<23:41,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1058/1969 [27:32<23:38,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1059/1969 [27:33<23:37,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1060/1969 [27:35<23:34,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1061/1969 [27:36<23:34,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1062/1969 [27:38<23:32,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1063/1969 [27:39<23:29,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1064/1969 [27:41<23:26,  1.55s/it]\u001b[A\n",
      "Iteration:  54% 1065/1969 [27:43<23:27,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1066/1969 [27:44<23:24,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1067/1969 [27:46<23:21,  1.55s/it]\u001b[A\n",
      "Iteration:  54% 1068/1969 [27:47<23:20,  1.55s/it]\u001b[A\n",
      "Iteration:  54% 1069/1969 [27:49<23:20,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1070/1969 [27:50<23:17,  1.55s/it]\u001b[A\n",
      "Iteration:  54% 1071/1969 [27:52<23:15,  1.55s/it]\u001b[A\n",
      "Iteration:  54% 1072/1969 [27:53<23:16,  1.56s/it]\u001b[A\n",
      "Iteration:  54% 1073/1969 [27:55<23:14,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1074/1969 [27:57<23:12,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1075/1969 [27:58<23:12,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1076/1969 [28:00<23:12,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1077/1969 [28:01<23:09,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1078/1969 [28:03<23:07,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1079/1969 [28:04<23:06,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1080/1969 [28:06<23:06,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1081/1969 [28:07<23:03,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1082/1969 [28:09<23:00,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1083/1969 [28:11<22:59,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1084/1969 [28:12<22:57,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1085/1969 [28:14<22:55,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1086/1969 [28:15<22:56,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1087/1969 [28:17<22:53,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1088/1969 [28:18<22:51,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1089/1969 [28:20<22:51,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1090/1969 [28:22<22:51,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1091/1969 [28:23<22:47,  1.56s/it]\u001b[A\n",
      "Iteration:  55% 1092/1969 [28:25<22:44,  1.56s/it]\u001b[A\n",
      "Iteration:  56% 1093/1969 [28:26<22:44,  1.56s/it]\u001b[A\n",
      "Iteration:  56% 1094/1969 [28:28<22:42,  1.56s/it]\u001b[A\n",
      "Iteration:  56% 1095/1969 [28:29<22:38,  1.55s/it]\u001b[A\n",
      "Iteration:  56% 1096/1969 [28:31<22:35,  1.55s/it]\u001b[A\n",
      "Iteration:  56% 1097/1969 [28:32<22:35,  1.55s/it]\u001b[A\n",
      "Iteration:  56% 1098/1969 [28:34<22:33,  1.55s/it]\u001b[A\n",
      "Iteration:  56% 1099/1969 [28:35<22:31,  1.55s/it]\u001b[A\n",
      "Iteration:  56% 1100/1969 [28:37<22:32,  1.56s/it]\u001b[A\n",
      "Iteration:  56% 1101/1969 [28:39<22:30,  1.56s/it]\u001b[A\n",
      "Iteration:  56% 1102/1969 [28:40<22:27,  1.55s/it]\u001b[A\n",
      "Iteration:  56% 1103/1969 [28:42<22:26,  1.55s/it]\u001b[A\n",
      "Iteration:  56% 1104/1969 [28:43<22:24,  1.55s/it]\u001b[A\n",
      "Iteration:  56% 1105/1969 [28:45<22:24,  1.56s/it]\u001b[A\n",
      "Iteration:  56% 1106/1969 [28:46<22:21,  1.55s/it]\u001b[A\n",
      "Iteration:  56% 1107/1969 [28:48<22:21,  1.56s/it]\u001b[A\n",
      "Iteration:  56% 1108/1969 [28:50<22:21,  1.56s/it]\u001b[A\n",
      "Iteration:  56% 1109/1969 [28:51<22:18,  1.56s/it]\u001b[A\n",
      "Iteration:  56% 1110/1969 [28:53<22:16,  1.56s/it]\u001b[A\n",
      "Iteration:  56% 1111/1969 [28:54<22:15,  1.56s/it]\u001b[A\n",
      "Iteration:  56% 1112/1969 [28:56<22:15,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1113/1969 [28:57<22:13,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1114/1969 [28:59<22:11,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1115/1969 [29:00<22:12,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1116/1969 [29:02<22:11,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1117/1969 [29:04<22:10,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1118/1969 [29:05<22:07,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1119/1969 [29:07<22:04,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1120/1969 [29:08<22:02,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1121/1969 [29:10<22:03,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1122/1969 [29:11<22:01,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1123/1969 [29:13<21:59,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1124/1969 [29:14<21:57,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1125/1969 [29:16<21:56,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1126/1969 [29:18<21:51,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1127/1969 [29:19<21:49,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1128/1969 [29:21<21:50,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1129/1969 [29:22<21:50,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1130/1969 [29:24<21:49,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1131/1969 [29:25<21:49,  1.56s/it]\u001b[A\n",
      "Iteration:  57% 1132/1969 [29:27<21:49,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1133/1969 [29:29<21:48,  1.57s/it]\u001b[A\n",
      "Iteration:  58% 1134/1969 [29:30<21:49,  1.57s/it]\u001b[A\n",
      "Iteration:  58% 1135/1969 [29:32<21:44,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1136/1969 [29:33<21:40,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1137/1969 [29:35<21:39,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1138/1969 [29:36<21:37,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1139/1969 [29:38<21:33,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1140/1969 [29:39<21:30,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1141/1969 [29:41<21:29,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1142/1969 [29:43<21:28,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1143/1969 [29:44<21:23,  1.55s/it]\u001b[A\n",
      "Iteration:  58% 1144/1969 [29:46<21:25,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1145/1969 [29:47<21:23,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1146/1969 [29:49<21:20,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1147/1969 [29:50<21:18,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1148/1969 [29:52<21:18,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1149/1969 [29:53<21:16,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1150/1969 [29:55<21:16,  1.56s/it]\u001b[A\n",
      "Iteration:  58% 1151/1969 [29:57<21:17,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1152/1969 [29:58<21:13,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1153/1969 [30:00<21:11,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1154/1969 [30:01<21:08,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1155/1969 [30:03<21:10,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1156/1969 [30:04<21:07,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1157/1969 [30:06<21:03,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1158/1969 [30:07<21:03,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1159/1969 [30:09<21:02,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1160/1969 [30:11<20:59,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1161/1969 [30:12<20:58,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1162/1969 [30:14<20:56,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1163/1969 [30:15<20:54,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1164/1969 [30:17<20:51,  1.55s/it]\u001b[A\n",
      "Iteration:  59% 1165/1969 [30:18<20:52,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1166/1969 [30:20<20:49,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1167/1969 [30:21<20:46,  1.55s/it]\u001b[A\n",
      "Iteration:  59% 1168/1969 [30:23<20:45,  1.55s/it]\u001b[A\n",
      "Iteration:  59% 1169/1969 [30:25<20:45,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1170/1969 [30:26<20:42,  1.56s/it]\u001b[A\n",
      "Iteration:  59% 1171/1969 [30:28<20:40,  1.55s/it]\u001b[A\n",
      "Iteration:  60% 1172/1969 [30:29<20:37,  1.55s/it]\u001b[A\n",
      "Iteration:  60% 1173/1969 [30:31<20:39,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1174/1969 [30:32<20:36,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1175/1969 [30:34<20:37,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1176/1969 [30:35<20:35,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1177/1969 [30:37<20:33,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1178/1969 [30:39<20:31,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1179/1969 [30:40<20:32,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1180/1969 [30:42<20:29,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1181/1969 [30:43<20:26,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1182/1969 [30:45<20:23,  1.55s/it]\u001b[A\n",
      "Iteration:  60% 1183/1969 [30:46<20:23,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1184/1969 [30:48<20:22,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1185/1969 [30:49<20:20,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1186/1969 [30:51<20:18,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1187/1969 [30:53<20:18,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1188/1969 [30:54<20:16,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1189/1969 [30:56<20:16,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1190/1969 [30:57<20:15,  1.56s/it]\u001b[A\n",
      "Iteration:  60% 1191/1969 [30:59<20:16,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1192/1969 [31:00<20:13,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1193/1969 [31:02<20:10,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1194/1969 [31:04<20:08,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1195/1969 [31:05<20:04,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1196/1969 [31:07<20:03,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1197/1969 [31:08<20:02,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1198/1969 [31:10<20:01,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1199/1969 [31:11<20:01,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1200/1969 [31:13<20:04,  1.57s/it]\u001b[A\n",
      "Iteration:  61% 1201/1969 [31:14<20:02,  1.57s/it]\u001b[A\n",
      "Iteration:  61% 1202/1969 [31:16<20:00,  1.57s/it]\u001b[A\n",
      "Iteration:  61% 1203/1969 [31:18<19:57,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1204/1969 [31:19<19:54,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1205/1969 [31:21<19:51,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1206/1969 [31:22<19:48,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1207/1969 [31:24<19:46,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1208/1969 [31:25<19:45,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1209/1969 [31:27<19:44,  1.56s/it]\u001b[A\n",
      "Iteration:  61% 1210/1969 [31:28<19:42,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1211/1969 [31:30<19:39,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1212/1969 [31:32<19:37,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1213/1969 [31:33<19:38,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1214/1969 [31:35<19:36,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1215/1969 [31:36<19:33,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1216/1969 [31:38<19:31,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1217/1969 [31:39<19:31,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1218/1969 [31:41<19:29,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1219/1969 [31:42<19:27,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1220/1969 [31:44<19:25,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1221/1969 [31:46<19:24,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1222/1969 [31:47<19:22,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1223/1969 [31:49<19:21,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1224/1969 [31:50<19:20,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1225/1969 [31:52<19:18,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1226/1969 [31:53<19:17,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1227/1969 [31:55<19:17,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1228/1969 [31:57<19:14,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1229/1969 [31:58<19:14,  1.56s/it]\u001b[A\n",
      "Iteration:  62% 1230/1969 [32:00<19:13,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1231/1969 [32:01<19:12,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1232/1969 [32:03<19:10,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1233/1969 [32:04<19:10,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1234/1969 [32:06<19:08,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1235/1969 [32:07<19:09,  1.57s/it]\u001b[A\n",
      "Iteration:  63% 1236/1969 [32:09<19:08,  1.57s/it]\u001b[A\n",
      "Iteration:  63% 1237/1969 [32:11<19:06,  1.57s/it]\u001b[A\n",
      "Iteration:  63% 1238/1969 [32:12<19:05,  1.57s/it]\u001b[A\n",
      "Iteration:  63% 1239/1969 [32:14<19:02,  1.57s/it]\u001b[A\n",
      "Iteration:  63% 1240/1969 [32:15<19:01,  1.57s/it]\u001b[A\n",
      "Iteration:  63% 1241/1969 [32:17<18:58,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1242/1969 [32:18<18:58,  1.57s/it]\u001b[A\n",
      "Iteration:  63% 1243/1969 [32:20<18:56,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1244/1969 [32:22<18:53,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1245/1969 [32:23<18:52,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1246/1969 [32:25<18:50,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1247/1969 [32:26<18:47,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1248/1969 [32:28<18:46,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1249/1969 [32:29<18:45,  1.56s/it]\u001b[A\n",
      "Iteration:  63% 1250/1969 [32:31<18:45,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1251/1969 [32:33<18:46,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1252/1969 [32:34<18:44,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1253/1969 [32:36<18:42,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1254/1969 [32:37<18:41,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1255/1969 [32:39<18:38,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1256/1969 [32:40<18:38,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1257/1969 [32:42<18:36,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1258/1969 [32:43<18:34,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1259/1969 [32:45<18:33,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1260/1969 [32:47<18:31,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1261/1969 [32:48<18:29,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1262/1969 [32:50<18:29,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1263/1969 [32:51<18:25,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1264/1969 [32:53<18:24,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1265/1969 [32:54<18:21,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1266/1969 [32:56<18:22,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1267/1969 [32:58<18:20,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1268/1969 [32:59<18:17,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1269/1969 [33:01<18:16,  1.57s/it]\u001b[A\n",
      "Iteration:  64% 1270/1969 [33:02<18:15,  1.57s/it]\u001b[A\n",
      "Iteration:  65% 1271/1969 [33:04<18:16,  1.57s/it]\u001b[A\n",
      "Iteration:  65% 1272/1969 [33:05<18:15,  1.57s/it]\u001b[A\n",
      "Iteration:  65% 1273/1969 [33:07<18:13,  1.57s/it]\u001b[A\n",
      "Iteration:  65% 1274/1969 [33:09<18:10,  1.57s/it]\u001b[A\n",
      "Iteration:  65% 1275/1969 [33:10<18:06,  1.57s/it]\u001b[A\n",
      "Iteration:  65% 1276/1969 [33:12<18:03,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1277/1969 [33:13<18:02,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1278/1969 [33:15<18:00,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1279/1969 [33:16<17:57,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1280/1969 [33:18<17:55,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1281/1969 [33:20<17:53,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1282/1969 [33:21<17:51,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1283/1969 [33:23<17:50,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1284/1969 [33:24<17:48,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1285/1969 [33:26<17:46,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1286/1969 [33:27<17:43,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1287/1969 [33:29<17:44,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1288/1969 [33:30<17:41,  1.56s/it]\u001b[A\n",
      "Iteration:  65% 1289/1969 [33:32<17:39,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1290/1969 [33:34<17:38,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1291/1969 [33:35<17:38,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1292/1969 [33:37<17:35,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1293/1969 [33:38<17:32,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1294/1969 [33:40<17:32,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1295/1969 [33:41<17:29,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1296/1969 [33:43<17:27,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1297/1969 [33:44<17:26,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1298/1969 [33:46<17:27,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1299/1969 [33:48<17:24,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1300/1969 [33:49<17:24,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1301/1969 [33:51<17:22,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1302/1969 [33:52<17:21,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1303/1969 [33:54<17:19,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1304/1969 [33:55<17:17,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1305/1969 [33:57<17:15,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1306/1969 [33:58<17:12,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1307/1969 [34:00<17:09,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1308/1969 [34:02<17:10,  1.56s/it]\u001b[A\n",
      "Iteration:  66% 1309/1969 [34:03<17:07,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1310/1969 [34:05<17:05,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1311/1969 [34:06<17:03,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1312/1969 [34:08<17:01,  1.55s/it]\u001b[A\n",
      "Iteration:  67% 1313/1969 [34:09<17:01,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1314/1969 [34:11<16:59,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1315/1969 [34:12<16:58,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1316/1969 [34:14<16:56,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1317/1969 [34:16<16:54,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1318/1969 [34:17<16:54,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1319/1969 [34:19<16:52,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1320/1969 [34:20<16:50,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1321/1969 [34:22<16:47,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1322/1969 [34:23<16:47,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1323/1969 [34:25<16:45,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1324/1969 [34:26<16:43,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1325/1969 [34:28<16:41,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1326/1969 [34:30<16:40,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1327/1969 [34:31<16:42,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1328/1969 [34:33<16:41,  1.56s/it]\u001b[A\n",
      "Iteration:  67% 1329/1969 [34:34<16:42,  1.57s/it]\u001b[A\n",
      "Iteration:  68% 1330/1969 [34:36<16:41,  1.57s/it]\u001b[A\n",
      "Iteration:  68% 1331/1969 [34:37<16:40,  1.57s/it]\u001b[A\n",
      "Iteration:  68% 1332/1969 [34:39<16:38,  1.57s/it]\u001b[A\n",
      "Iteration:  68% 1333/1969 [34:41<16:35,  1.57s/it]\u001b[A\n",
      "Iteration:  68% 1334/1969 [34:42<16:32,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1335/1969 [34:44<16:29,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1336/1969 [34:45<16:27,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1337/1969 [34:47<16:24,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1338/1969 [34:48<16:23,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1339/1969 [34:50<16:21,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1340/1969 [34:51<16:19,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1341/1969 [34:53<16:18,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1342/1969 [34:55<16:15,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1343/1969 [34:56<16:14,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1344/1969 [34:58<16:14,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1345/1969 [34:59<16:14,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1346/1969 [35:01<16:11,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1347/1969 [35:02<16:08,  1.56s/it]\u001b[A\n",
      "Iteration:  68% 1348/1969 [35:04<16:07,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1349/1969 [35:05<16:05,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1350/1969 [35:07<16:02,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1351/1969 [35:09<16:00,  1.55s/it]\u001b[A\n",
      "Iteration:  69% 1352/1969 [35:10<15:59,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1353/1969 [35:12<15:58,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1354/1969 [35:13<15:58,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1355/1969 [35:15<15:56,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1356/1969 [35:16<15:55,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1357/1969 [35:18<15:53,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1358/1969 [35:20<15:53,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1359/1969 [35:21<15:51,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1360/1969 [35:23<15:50,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1361/1969 [35:24<15:48,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1362/1969 [35:26<15:47,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1363/1969 [35:27<15:44,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1364/1969 [35:29<15:42,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1365/1969 [35:30<15:40,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1366/1969 [35:32<15:39,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1367/1969 [35:34<15:36,  1.56s/it]\u001b[A\n",
      "Iteration:  69% 1368/1969 [35:35<15:35,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1369/1969 [35:37<15:34,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1370/1969 [35:38<15:31,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1371/1969 [35:40<15:29,  1.55s/it]\u001b[A\n",
      "Iteration:  70% 1372/1969 [35:41<15:29,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1373/1969 [35:43<15:28,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1374/1969 [35:44<15:26,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1375/1969 [35:46<15:25,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1376/1969 [35:48<15:24,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1377/1969 [35:49<15:20,  1.55s/it]\u001b[A\n",
      "Iteration:  70% 1378/1969 [35:51<15:18,  1.55s/it]\u001b[A\n",
      "Iteration:  70% 1379/1969 [35:52<15:19,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1380/1969 [35:54<15:17,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1381/1969 [35:55<15:14,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1382/1969 [35:57<15:12,  1.55s/it]\u001b[A\n",
      "Iteration:  70% 1383/1969 [35:58<15:11,  1.55s/it]\u001b[A\n",
      "Iteration:  70% 1384/1969 [36:00<15:08,  1.55s/it]\u001b[A\n",
      "Iteration:  70% 1385/1969 [36:02<15:08,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1386/1969 [36:03<15:07,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1387/1969 [36:05<15:07,  1.56s/it]\u001b[A\n",
      "Iteration:  70% 1388/1969 [36:06<15:04,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1389/1969 [36:08<15:05,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1390/1969 [36:09<15:04,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1391/1969 [36:11<15:01,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1392/1969 [36:12<14:58,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1393/1969 [36:14<14:58,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1394/1969 [36:16<14:58,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1395/1969 [36:17<14:59,  1.57s/it]\u001b[A\n",
      "Iteration:  71% 1396/1969 [36:19<15:01,  1.57s/it]\u001b[A\n",
      "Iteration:  71% 1397/1969 [36:20<14:58,  1.57s/it]\u001b[A\n",
      "Iteration:  71% 1398/1969 [36:22<14:54,  1.57s/it]\u001b[A\n",
      "Iteration:  71% 1399/1969 [36:23<14:51,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1400/1969 [36:25<14:47,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1401/1969 [36:27<14:46,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1402/1969 [36:28<14:45,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1403/1969 [36:30<14:42,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1404/1969 [36:31<14:40,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1405/1969 [36:33<14:39,  1.56s/it]\u001b[A\n",
      "Iteration:  71% 1406/1969 [36:34<14:38,  1.56s/it]\u001b[ATraceback (most recent call last):\n",
      "  File \"examples/run_classifier.py\", line 619, in <module>\n",
      "    main()\n",
      "  File \"examples/run_classifier.py\", line 540, in main\n",
      "    loss.backward()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 93, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 90, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "Exception ignored in: <bound method tqdm.__del__ of Iteration:  71% 1406/1969 [36:36<14:38,  1.56s/it]>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 931, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 1133, in close\n",
      "    self._decr_instances(self)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 496, in _decr_instances\n",
      "    cls.monitor.exit()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_monitor.py\", line 52, in exit\n",
      "    self.join()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 1053, in join\n",
      "    raise RuntimeError(\"cannot join current thread\")\n",
      "RuntimeError: cannot join current thread\n"
     ]
    }
   ],
   "source": [
    "!python examples/run_classifier.py \\\n",
    "  --task_name MRPC \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --data_dir /content/msaic/mrc \\\n",
    "  --bert_model bert-base-uncased \\\n",
    "  --max_seq_length 128 \\\n",
    "  --train_batch_size 32 \\\n",
    "  --eval_batch_size 32 \\\n",
    "  --learning_rate 5e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --output_dir /tmp/mrpc_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jthaCf1Z7r9M"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from google.colab import auth\n",
    "from googleapiclient.discovery import build\n",
    "import io\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "def save_file_to_google_drive(local_filename, dest_filename, mimetype = 'application/octet-stream'):\n",
    "  auth.authenticate_user()\n",
    "  drive_service = build('drive', 'v3')\n",
    "\n",
    "  file_metadata = {\n",
    "    'name': dest_filename,\n",
    "    'mimeType': mimetype\n",
    "  }\n",
    "  media = MediaFileUpload(local_filename, \n",
    "                          mimetype=mimetype,\n",
    "                          resumable=True)\n",
    "  created = drive_service.files().create(body=file_metadata,\n",
    "                                         media_body=media,\n",
    "                                         fields='id').execute()\n",
    "  print('File ID: {}'.format(created.get('id')))\n",
    "  return created.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "xWuvsF80KOEr",
    "outputId": "75396455-0a42-489d-88dc-ccba4bd768c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbin\u001b[0m/                          checkpoint0.7266935812437497  README.md\n",
      "checkpoint0.7070812895852183  checkpoint0.7285084632764176  requirements.txt\n",
      "checkpoint0.7087956569360446  \u001b[01;34mexamples\u001b[0m/                     \u001b[01;34msamples\u001b[0m/\n",
      "checkpoint0.7151292918710415  LICENSE                       setup.py\n",
      "checkpoint0.7192247249869042  \u001b[01;34mnotebooks\u001b[0m/                    \u001b[01;34mtests\u001b[0m/\n",
      "checkpoint0.7245083151227824  \u001b[01;34mpytorch_pretrained_bert\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "eodThZ0IKRUy",
    "outputId": "2d24d593-3b79-4695-9296-94e0dc317e19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ID: 1nBbgbjxSp8MPHH9AAHe-_Mcxm6vMJZVb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1nBbgbjxSp8MPHH9AAHe-_Mcxm6vMJZVb'"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_file_to_google_drive('checkpoint0.7245083151227824', 'bert_finetuned_3_epochs_5e-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XwPF0jf4Kc9G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Bert Training.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
