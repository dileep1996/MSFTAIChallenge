{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT with margin maximization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "sLU0izgQU3vE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Download and loda data**"
      ]
    },
    {
      "metadata": {
        "id": "EA2uY88lU2nH",
        "colab_type": "code",
        "outputId": "9b4e619e-37a1-4905-f59b-16521d713036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://competitions.codalab.org/my/datasets/download/69a3e8d0-b836-48b8-8795-36a6865a1c04"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-10 04:43:03--  https://competitions.codalab.org/my/datasets/download/69a3e8d0-b836-48b8-8795-36a6865a1c04\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 134.158.75.178\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|134.158.75.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/ec355/data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=3e4d04e79b7641926159fcc3fef9d9dd22c719b7ccb76d1f8a0877fc567fb5e1&X-Amz-Date=20181210T044259Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20181210%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2018-12-10 04:43:04--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/ec355/data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=3e4d04e79b7641926159fcc3fef9d9dd22c719b7ccb76d1f8a0877fc567fb5e1&X-Amz-Date=20181210T044259Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20181210%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 610505204 (582M) [application/zip]\n",
            "Saving to: ‘69a3e8d0-b836-48b8-8795-36a6865a1c04’\n",
            "\n",
            "69a3e8d0-b836-48b8- 100%[===================>] 582.22M  19.3MB/s    in 31s     \n",
            "\n",
            "2018-12-10 04:43:36 (18.7 MB/s) - ‘69a3e8d0-b836-48b8-8795-36a6865a1c04’ saved [610505204/610505204]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jrF0nHQmVa0N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv 69a3e8d0-b836-48b8-8795-36a6865a1c04 data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FNE9e-O5Vhfh",
        "colab_type": "code",
        "outputId": "33bcbf85-5b93-4299-fcd9-5f65ce2917f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install zipfile36"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting zipfile36\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/8a/3b7da0b0bd87d1ef05b74207827c72d348b56a0d6d83242582be18a81e02/zipfile36-0.1.3-py3-none-any.whl\n",
            "Installing collected packages: zipfile36\n",
            "Successfully installed zipfile36-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "km_iDLqCVhiy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir msaic\n",
        "!mv data.zip msaic/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UbAPkPrBVhce",
        "colab_type": "code",
        "outputId": "18776241-f536-4b80-9de2-30e4c7332c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd msaic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/msaic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "55OSVNeLVoor",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zipref = zipfile.ZipFile('data.zip', 'r')\n",
        "zipref.extractall()\n",
        "zipref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ITF_RrByVosM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iaEviMZAveIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oWy73P4WVo8H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data.tsv\", sep= '\\t',header=None)\n",
        "df.columns = ['index','Question', 'Sentence', 'Label','seq']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2B5BKtWEVpCG",
        "colab_type": "code",
        "outputId": "37e891f0-ac78-40a5-a9c2-7dd67c2e5647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Question</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>A company is incorporated in a specific nation...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>Today, there is a growing community of more th...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>Corporation definition, an association of indi...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>Examples of corporation in a Sentence. 1  He w...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>1: a government-owned corporation (as a utilit...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                  Question  \\\n",
              "0    131  . what is a corporation?   \n",
              "1    131  . what is a corporation?   \n",
              "2    131  . what is a corporation?   \n",
              "3    131  . what is a corporation?   \n",
              "4    131  . what is a corporation?   \n",
              "\n",
              "                                            Sentence  Label  seq  \n",
              "0  A company is incorporated in a specific nation...      0    0  \n",
              "1  Today, there is a growing community of more th...      0    1  \n",
              "2  Corporation definition, an association of indi...      0    2  \n",
              "3  Examples of corporation in a Sentence. 1  He w...      0    3  \n",
              "4  1: a government-owned corporation (as a utilit...      0    4  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "WjdB8-jMbBVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unique_question_list = df.Question.unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R5_XzQ2WZugB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rand_seed = 200\n",
        "import numpy as np\n",
        "np.random.seed(rand_seed)\n",
        "train_len = 30000\n",
        "dev_len = 4000\n",
        "idlist = np.arange(len(unique_question_list))\n",
        "np.random.shuffle(idlist)\n",
        "shuffled_questions = unique_question_list[idlist]\n",
        "train, dev = shuffled_questions[:train_len], shuffled_questions[train_len:train_len+dev_len],"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UBVGP3Jt8FAY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#shuffle df\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K9fhm8GMZuk9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_pos_neg(qdf, odf):\n",
        "    result = []\n",
        "    for item in qdf:\n",
        "      qs = odf[odf.Question == item]\n",
        "      pos = list(qs[qs.Label == 1][:1]['Sentence'])[0]\n",
        "      neg = list(qs[qs.Label == 0][:1]['Sentence'])[:1]\n",
        "      for i in neg:\n",
        "        result.append([item, pos, i])\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "balHlJxCb02x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_list = get_pos_neg(train, df[df.Question.isin(train)])\n",
        "dev_list = get_pos_neg(dev, df[df.Question.isin(dev)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dXaZ9xjOb0xt",
        "colab_type": "code",
        "outputId": "86a164f8-657b-40e8-eb32-7e6bb68a96c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "d4QTcLc8jzd6",
        "colab_type": "code",
        "outputId": "52b4a364-500e-403e-963a-1ebeb0369e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1102
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.2.0\n",
        "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "#!pip3 install allennlp\n",
        "!pip install tqdm\n",
        "!pip install spacy\n",
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/6e/5084627fee802fa6a13741ff988e34f2d2ee25e8a6a276b4832f278c5654/Pillow-4.2.0-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.8MB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.2.0) (0.46)\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed Pillow-4.2.0\n",
            "Collecting torch==0.4.1 from http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl (512.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 512.6MB 36.1MB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x58a04000 @  0x7f5b8f8672a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Collecting numpy>=1.15.0 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.11.29)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (4.28.1)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed numpy-1.15.4\n",
            "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 37.4MB 52.8MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "  Running setup.py install for en-core-web-sm ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AErqYBlKjza4",
        "colab_type": "code",
        "outputId": "55422997-4cb3-471e-c1d3-8b9cc111a0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert==0.2.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/24/47/057e7998e5ac9c9a1b1f1c5a65895accec23ed414ae264af7db4fe2d5b2f/pytorch_pretrained_bert-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.2.0) (1.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.2.0) (2.18.4)\n",
            "Collecting boto3 (from pytorch-pretrained-bert==0.2.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/b9/7df67f1775d240ac8d111211f967fa75ecc9968ae79ffa0594e36345445f/boto3-1.9.62-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.2.0) (0.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.2.0) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.2.0) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.2.0) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.2.0) (2018.11.29)\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->pytorch-pretrained-bert==0.2.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 19.9MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->pytorch-pretrained-bert==0.2.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting botocore<1.13.0,>=1.12.62 (from boto3->pytorch-pretrained-bert==0.2.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/77/35e82076e3beb506280f94213a258819378115f174e516ce69b3a2336e1c/botocore-1.12.62-py2.py3-none-any.whl (5.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.1MB 6.2MB/s \n",
            "\u001b[?25hCollecting docutils>=0.10 (from botocore<1.13.0,>=1.12.62->boto3->pytorch-pretrained-bert==0.2.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 25.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->pytorch-pretrained-bert==0.2.0) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.62->boto3->pytorch-pretrained-bert==0.2.0) (1.11.0)\n",
            "Installing collected packages: docutils, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.9.62 botocore-1.12.62 docutils-0.14 jmespath-0.9.3 pytorch-pretrained-bert-0.2.0 s3transfer-0.1.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yvE5x7n2jzIK",
        "colab_type": "code",
        "outputId": "ab880ac5-cde5-49b1-ee2d-49ba29b81154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dileep1996/pytorch-pretrained-BERT.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-pretrained-BERT'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)   \u001b[K\rremote: Counting objects:  22% (2/9)   \u001b[K\rremote: Counting objects:  33% (3/9)   \u001b[K\rremote: Counting objects:  44% (4/9)   \u001b[K\rremote: Counting objects:  55% (5/9)   \u001b[K\rremote: Counting objects:  66% (6/9)   \u001b[K\rremote: Counting objects:  77% (7/9)   \u001b[K\rremote: Counting objects:  88% (8/9)   \u001b[K\rremote: Counting objects: 100% (9/9)   \u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  11% (1/9)   \u001b[K\rremote: Compressing objects:  22% (2/9)   \u001b[K\rremote: Compressing objects:  33% (3/9)   \u001b[K\rremote: Compressing objects:  44% (4/9)   \u001b[K\rremote: Compressing objects:  55% (5/9)   \u001b[K\rremote: Compressing objects:  66% (6/9)   \u001b[K\rremote: Compressing objects:  77% (7/9)   \u001b[K\rremote: Compressing objects:  88% (8/9)   \u001b[K\rremote: Compressing objects: 100% (9/9)   \u001b[K\rremote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "Receiving objects:   0% (1/922)   \rReceiving objects:   1% (10/922)   \rReceiving objects:   2% (19/922)   \rReceiving objects:   3% (28/922)   \rReceiving objects:   4% (37/922)   \rReceiving objects:   5% (47/922)   \rReceiving objects:   6% (56/922)   \rReceiving objects:   7% (65/922)   \rReceiving objects:   8% (74/922)   \rReceiving objects:   9% (83/922)   \rReceiving objects:  10% (93/922)   \rReceiving objects:  11% (102/922)   \rReceiving objects:  12% (111/922)   \rReceiving objects:  13% (120/922)   \rReceiving objects:  14% (130/922)   \rReceiving objects:  15% (139/922)   \rReceiving objects:  16% (148/922)   \rReceiving objects:  17% (157/922)   \rReceiving objects:  18% (166/922)   \rReceiving objects:  19% (176/922)   \rReceiving objects:  20% (185/922)   \rReceiving objects:  21% (194/922)   \rReceiving objects:  22% (203/922)   \rReceiving objects:  23% (213/922)   \rReceiving objects:  24% (222/922)   \rReceiving objects:  25% (231/922)   \rReceiving objects:  26% (240/922)   \rReceiving objects:  27% (249/922)   \rReceiving objects:  28% (259/922)   \rReceiving objects:  29% (268/922)   \rReceiving objects:  30% (277/922)   \rReceiving objects:  31% (286/922)   \rReceiving objects:  32% (296/922)   \rReceiving objects:  33% (305/922)   \rReceiving objects:  34% (314/922)   \rReceiving objects:  35% (323/922)   \rReceiving objects:  36% (332/922)   \rReceiving objects:  37% (342/922)   \rReceiving objects:  38% (351/922)   \rReceiving objects:  39% (360/922)   \rReceiving objects:  40% (369/922)   \rReceiving objects:  41% (379/922)   \rReceiving objects:  42% (388/922)   \rReceiving objects:  43% (397/922)   \rReceiving objects:  44% (406/922)   \rReceiving objects:  45% (415/922)   \rReceiving objects:  46% (425/922)   \rReceiving objects:  47% (434/922)   \rReceiving objects:  48% (443/922)   \rReceiving objects:  49% (452/922)   \rReceiving objects:  50% (461/922)   \rReceiving objects:  51% (471/922)   \rReceiving objects:  52% (480/922)   \rReceiving objects:  53% (489/922)   \rReceiving objects:  54% (498/922)   \rReceiving objects:  55% (508/922)   \rReceiving objects:  56% (517/922)   \rReceiving objects:  57% (526/922)   \rReceiving objects:  58% (535/922)   \rReceiving objects:  59% (544/922)   \rReceiving objects:  60% (554/922)   \rReceiving objects:  61% (563/922)   \rReceiving objects:  62% (572/922)   \rReceiving objects:  63% (581/922)   \rReceiving objects:  64% (591/922)   \rReceiving objects:  65% (600/922)   \rReceiving objects:  66% (609/922)   \rReceiving objects:  67% (618/922)   \rReceiving objects:  68% (627/922)   \rReceiving objects:  69% (637/922)   \rReceiving objects:  70% (646/922)   \rReceiving objects:  71% (655/922)   \rReceiving objects:  72% (664/922)   \rReceiving objects:  73% (674/922)   \rReceiving objects:  74% (683/922)   \rReceiving objects:  75% (692/922)   \rReceiving objects:  76% (701/922)   \rReceiving objects:  77% (710/922)   \rReceiving objects:  78% (720/922)   \rReceiving objects:  79% (729/922)   \rReceiving objects:  80% (738/922)   \rReceiving objects:  81% (747/922)   \rReceiving objects:  82% (757/922)   \rReceiving objects:  83% (766/922)   \rReceiving objects:  84% (775/922)   \rReceiving objects:  85% (784/922)   \rReceiving objects:  86% (793/922)   \rReceiving objects:  87% (803/922)   \rReceiving objects:  88% (812/922)   \rReceiving objects:  89% (821/922)   \rReceiving objects:  90% (830/922)   \rReceiving objects:  91% (840/922)   \rReceiving objects:  92% (849/922)   \rReceiving objects:  93% (858/922)   \rReceiving objects:  94% (867/922)   \rremote: Total 922 (delta 2), reused 1 (delta 0), pack-reused 913\u001b[K\n",
            "Receiving objects:  95% (876/922)   \rReceiving objects:  96% (886/922)   \rReceiving objects:  97% (895/922)   \rReceiving objects:  98% (904/922)   \rReceiving objects:  99% (913/922)   \rReceiving objects: 100% (922/922)   \rReceiving objects: 100% (922/922), 552.37 KiB | 14.16 MiB/s, done.\n",
            "Resolving deltas:   0% (0/574)   \rResolving deltas:   1% (7/574)   \rResolving deltas:   2% (13/574)   \rResolving deltas:   3% (20/574)   \rResolving deltas:   5% (32/574)   \rResolving deltas:   6% (35/574)   \rResolving deltas:   7% (41/574)   \rResolving deltas:   8% (46/574)   \rResolving deltas:  18% (107/574)   \rResolving deltas:  19% (110/574)   \rResolving deltas:  25% (147/574)   \rResolving deltas:  35% (202/574)   \rResolving deltas:  36% (209/574)   \rResolving deltas:  37% (217/574)   \rResolving deltas:  38% (220/574)   \rResolving deltas:  41% (238/574)   \rResolving deltas:  42% (244/574)   \rResolving deltas:  43% (250/574)   \rResolving deltas:  56% (327/574)   \rResolving deltas:  57% (328/574)   \rResolving deltas:  59% (339/574)   \rResolving deltas:  63% (363/574)   \rResolving deltas:  65% (376/574)   \rResolving deltas:  66% (380/574)   \rResolving deltas:  67% (386/574)   \rResolving deltas:  68% (396/574)   \rResolving deltas:  69% (400/574)   \rResolving deltas:  73% (423/574)   \rResolving deltas:  75% (434/574)   \rResolving deltas:  78% (449/574)   \rResolving deltas:  79% (458/574)   \rResolving deltas:  95% (547/574)   \rResolving deltas:  97% (557/574)   \rResolving deltas:  98% (563/574)   \rResolving deltas: 100% (574/574)   \rResolving deltas: 100% (574/574), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E6ZF6tZNk0HM",
        "colab_type": "code",
        "outputId": "f70527d1-3db6-4713-e218-91d80d8c6436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd pytorch-pretrained-BERT/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/msaic/pytorch-pretrained-BERT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3IXqENOepoGI",
        "colab_type": "code",
        "outputId": "077e9d1b-d0e7-4d99-b49d-3ccf316c4ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/dileep1996/pytorch-pretrained-BERT\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RjnNrpz1k2hV",
        "colab_type": "code",
        "outputId": "39ceafc9-aba9-44a2-b20f-7bce3154b381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd examples/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/msaic/pytorch-pretrained-BERT/examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nPW5l6syk2vW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from run_classifier import InputExample, convert_examples_to_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nRoRV-VLk0CS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_training_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(train_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[0]\n",
        "  text_b = row[1]\n",
        "  label = 0\n",
        "  pos_training_list.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "  \n",
        "neg_training_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(train_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[0]\n",
        "  text_b = row[2]\n",
        "  label = 0\n",
        "  neg_training_list.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7s3cer3Jkz9v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_dev_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(dev_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[0]\n",
        "  text_b = row[1]\n",
        "  label = 0\n",
        "  pos_dev_list.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "  \n",
        "neg_dev_list = []\n",
        "set_type = 'train'\n",
        "for i, row in enumerate(dev_list):\n",
        "  guid = \"%s-%s-%s\" % (set_type, i, i)\n",
        "  text_a = row[0]\n",
        "  text_b = row[2]\n",
        "  label = 0\n",
        "  neg_dev_list.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JCxJZ5hmlqtV",
        "colab_type": "code",
        "outputId": "785610fa-1398-470c-a9e4-4a143f520108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "cell_type": "code",
      "source": [
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/10/2018 05:05:17 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpkpmx5fyw\n",
            "100%|██████████| 231508/231508 [00:00<00:00, 1170378.35B/s]\n",
            "12/10/2018 05:05:18 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpkpmx5fyw to cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/10/2018 05:05:18 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/10/2018 05:05:18 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpkpmx5fyw\n",
            "12/10/2018 05:05:18 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8CB0C8R2l5Tm",
        "colab_type": "code",
        "outputId": "4f7eabf6-6986-4359-c1c7-2229e117ae24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2608
        }
      },
      "cell_type": "code",
      "source": [
        "pos_training_features = convert_examples_to_features(pos_training_list, [0], 128, tokenizer)\n",
        "neg_training_features = convert_examples_to_features(neg_training_list, [0], 128, tokenizer)\n",
        "pos_dev_features = convert_examples_to_features(pos_dev_list, [0], 128, tokenizer)\n",
        "neg_dev_features = convert_examples_to_features(neg_dev_list, [0], 128, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/10/2018 05:05:18 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   guid: train-0-0\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   tokens: [CLS] you best way to clean paint brushes [SEP] the best way to determine if there is any residual paint in the brush is to suspend it in a clear container after you think it is clean . use a string or thin wire through the hole at the end of the brush handle to suspend just the br ##istles in clean water . let it sit in the water for about four hours . he best way to determine if there is any residual paint in the brush is to suspend it in a clear container after you think it is clean . use a string or thin wire through the hole at the end of the brush handle to suspend just the br ##istles in [SEP]\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   input_ids: 101 2017 2190 2126 2000 4550 6773 22569 102 1996 2190 2126 2000 5646 2065 2045 2003 2151 21961 6773 1999 1996 8248 2003 2000 28324 2009 1999 1037 3154 11661 2044 2017 2228 2009 2003 4550 1012 2224 1037 5164 2030 4857 7318 2083 1996 4920 2012 1996 2203 1997 1996 8248 5047 2000 28324 2074 1996 7987 28738 1999 4550 2300 1012 2292 2009 4133 1999 1996 2300 2005 2055 2176 2847 1012 2002 2190 2126 2000 5646 2065 2045 2003 2151 21961 6773 1999 1996 8248 2003 2000 28324 2009 1999 1037 3154 11661 2044 2017 2228 2009 2003 4550 1012 2224 1037 5164 2030 4857 7318 2083 1996 4920 2012 1996 2203 1997 1996 8248 5047 2000 28324 2074 1996 7987 28738 1999 102\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   guid: train-1-1\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   tokens: [CLS] what team did earl campbell play for [SEP] running back earl campbell of the new orleans saints retired monday after nine seasons in pro football . he ended his career with 9 , 407 yards rushing . i ' m a man ; i ' m not a little boy , campbell said during a news conference at the saints ' training camp in hammond , la . i believe this is the best thing - - not only for myself , but for the saints . . saints ' coach jim mora said : he ' s a ci ##nch for the hall of fame . . campbell , 31 , spent six seasons with the houston oilers after winning the he ##isman trophy in [SEP]\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   input_ids: 101 2054 2136 2106 4656 6063 2377 2005 102 2770 2067 4656 6063 1997 1996 2047 5979 6586 3394 6928 2044 3157 3692 1999 4013 2374 1012 2002 3092 2010 2476 2007 1023 1010 28941 4210 8375 1012 1045 1005 1049 1037 2158 1025 1045 1005 1049 2025 1037 2210 2879 1010 6063 2056 2076 1037 2739 3034 2012 1996 6586 1005 2731 3409 1999 11309 1010 2474 1012 1045 2903 2023 2003 1996 2190 2518 1011 1011 2025 2069 2005 2870 1010 2021 2005 1996 6586 1012 1012 6586 1005 2873 3958 26821 2056 1024 2002 1005 1055 1037 25022 12680 2005 1996 2534 1997 4476 1012 1012 6063 1010 2861 1010 2985 2416 3692 2007 1996 5395 19778 2044 3045 1996 2002 20257 5384 1999 102\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   guid: train-2-2\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   tokens: [CLS] what is the original nu ##ma nu ##ma [SEP] americas . 1 a popular video named nu ##ma nu ##ma originally posted on new ##grounds features a man named gary bro ##ls ##ma performing a lip - sync to the song while dancing . 2 in brazil , singer latino replaced all the lyrics to create his reviewed version of drag ##ost ##ea din te ##i ( the song still resembles the original one in rhythm and melody ) . [SEP]\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   input_ids: 101 2054 2003 1996 2434 16371 2863 16371 2863 102 10925 1012 1015 1037 2759 2678 2315 16371 2863 16371 2863 2761 6866 2006 2047 28951 2838 1037 2158 2315 5639 22953 4877 2863 4488 1037 5423 1011 26351 2000 1996 2299 2096 5613 1012 1016 1999 4380 1010 3220 7402 2999 2035 1996 4581 2000 3443 2010 8182 2544 1997 8011 14122 5243 11586 8915 2072 1006 1996 2299 2145 12950 1996 2434 2028 1999 6348 1998 8531 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   guid: train-3-3\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   tokens: [CLS] types of he ##pa ##to ##cellular car ##cino ##ma [SEP] his ##to ##logic classification is as follows : 1 he ##pa ##to ##cellular car ##cino ##ma ( hc ##c ; liver cell car ##cino ##ma ) . 2 fi ##bro ##lam ##ella ##r variant of hc ##c . 3 cho ##lang ##io ##car ##cino ##ma ( intra ##he ##pati ##c bile duct car ##cino ##ma ) . 4 mixed he ##pa ##to ##cellular cho ##lang ##io ##car ##cino ##ma . 5 und ##iff ##ere ##nti ##ated . he ##pa ##to ##bla ##sto ##ma . [SEP]\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   input_ids: 101 4127 1997 2002 4502 3406 16882 2482 21081 2863 102 2010 3406 27179 5579 2003 2004 4076 1024 1015 2002 4502 3406 16882 2482 21081 2863 1006 16731 2278 1025 11290 3526 2482 21081 2863 1007 1012 1016 10882 12618 10278 8411 2099 8349 1997 16731 2278 1012 1017 16480 25023 3695 10010 21081 2863 1006 26721 5369 24952 2278 23974 23245 2482 21081 2863 1007 1012 1018 3816 2002 4502 3406 16882 16480 25023 3695 10010 21081 2863 1012 1019 6151 13355 7869 16778 4383 1012 2002 4502 3406 28522 16033 2863 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   guid: train-4-4\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   tokens: [CLS] what does do mean martial arts [SEP] although the term martial art has become associated with the fighting arts of eastern asia , it originally referred to the combat systems of europe as early as the 1550 ##s . the term is derived from latin , and means arts of mars , the roman god of war . [SEP]\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   input_ids: 101 2054 2515 2079 2812 7761 2840 102 2348 1996 2744 7761 2396 2038 2468 3378 2007 1996 3554 2840 1997 2789 4021 1010 2009 2761 3615 2000 1996 4337 3001 1997 2885 2004 2220 2004 1996 26245 2015 1012 1996 2744 2003 5173 2013 3763 1010 1998 2965 2840 1997 7733 1010 1996 3142 2643 1997 2162 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:05:18 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   guid: train-0-0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   tokens: [CLS] you best way to clean paint brushes [SEP] don ' t clean the brush with dish soap ; it will gum up the fe ##rr ##ule and br ##istles . and there ' s no need to ri ##nse the tool in fresh water . the more often you clean it with the soft ##ener solution , the better it gets . fabric soft ##ener coats the handle , fe ##rr ##ule , and br ##istles , allowing paint to flow effortlessly off the tool . . to dry your paint ##brush quickly , use a paint ##brush spin ##ner to fling water from the brush . spin the brush in a wet waste bucket . to make one , start with an empty 5 - [SEP]\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   input_ids: 101 2017 2190 2126 2000 4550 6773 22569 102 2123 1005 1056 4550 1996 8248 2007 9841 7815 1025 2009 2097 16031 2039 1996 10768 12171 9307 1998 7987 28738 1012 1998 2045 1005 1055 2053 2342 2000 15544 12325 1996 6994 1999 4840 2300 1012 1996 2062 2411 2017 4550 2009 2007 1996 3730 24454 5576 1010 1996 2488 2009 4152 1012 8313 3730 24454 15695 1996 5047 1010 10768 12171 9307 1010 1998 7987 28738 1010 4352 6773 2000 4834 29483 2125 1996 6994 1012 1012 2000 4318 2115 6773 18623 2855 1010 2224 1037 6773 18623 6714 3678 2000 27655 2300 2013 1996 8248 1012 6714 1996 8248 1999 1037 4954 5949 13610 1012 2000 2191 2028 1010 2707 2007 2019 4064 1019 1011 102\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   guid: train-1-1\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   tokens: [CLS] what team did earl campbell play for [SEP] in 1981 the legislature en ##sh ##rine ##d earl campbell as an official state hero of texas . only three other favorite sons — davy cr ##ock ##ett , stephen f . austin , and sam houston — had been previous recipients of that honor , so the proclamation was a fair measure of campbell ’ s popularity and fame at the time . [SEP]\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   input_ids: 101 2054 2136 2106 4656 6063 2377 2005 102 1999 3261 1996 6372 4372 4095 11467 2094 4656 6063 2004 2019 2880 2110 5394 1997 3146 1012 2069 2093 2060 5440 4124 1517 23255 13675 7432 6582 1010 4459 1042 1012 5899 1010 1998 3520 5395 1517 2018 2042 3025 15991 1997 2008 3932 1010 2061 1996 16413 2001 1037 4189 5468 1997 6063 1521 1055 6217 1998 4476 2012 1996 2051 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   guid: train-2-2\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   tokens: [CLS] what is the original nu ##ma nu ##ma [SEP] nu ##ma nu ##ma is in romanian . it is actually called drag ##ost ##ea din te ##i ( love from the linden trees ) . [SEP]\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   input_ids: 101 2054 2003 1996 2434 16371 2863 16371 2863 102 16371 2863 16371 2863 2003 1999 7056 1012 2009 2003 2941 2170 8011 14122 5243 11586 8915 2072 1006 2293 2013 1996 22066 3628 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   guid: train-3-3\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   tokens: [CLS] types of he ##pa ##to ##cellular car ##cino ##ma [SEP] what is he ##pa ##to ##cellular car ##cino ##ma ? he ##pa ##to ##cellular car ##cino ##ma is a type of liver cancer that usually affects people whose liver ##s have been under extra strain for a long time because of infections , metabolic diseases or prolonged use of certain drugs , including : infections with viral hepatitis b or c . [SEP]\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   input_ids: 101 4127 1997 2002 4502 3406 16882 2482 21081 2863 102 2054 2003 2002 4502 3406 16882 2482 21081 2863 1029 2002 4502 3406 16882 2482 21081 2863 2003 1037 2828 1997 11290 4456 2008 2788 13531 2111 3005 11290 2015 2031 2042 2104 4469 10178 2005 1037 2146 2051 2138 1997 15245 1010 21453 7870 2030 15330 2224 1997 3056 5850 1010 2164 1024 15245 2007 13434 28389 1038 2030 1039 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   guid: train-4-4\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   tokens: [CLS] what does do mean martial arts [SEP] sometimes , training with one specific weapon will be considered a style of martial arts in its own right , which is especially the case in japanese martial arts with disciplines such as ken ##ju ##tsu and ken ##do ( sword ) , bo ##ju ##tsu ( staff ) , and ky ##ud ##o ( archery ) . [SEP]\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   input_ids: 101 2054 2515 2079 2812 7761 2840 102 2823 1010 2731 2007 2028 3563 5195 2097 2022 2641 1037 2806 1997 7761 2840 1999 2049 2219 2157 1010 2029 2003 2926 1996 2553 1999 2887 7761 2840 2007 12736 2107 2004 6358 9103 10422 1998 6358 3527 1006 4690 1007 1010 8945 9103 10422 1006 3095 1007 1010 1998 18712 6784 2080 1006 21383 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:05 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   guid: train-0-0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   tokens: [CLS] what the airport code dallas , tx [SEP] dallas fort worth international airport . dallas , united states ; iata airport code d ##f ##w ; icao airport code k ##df ##w ; dallas fort worth international airport ( d ##f ##w ) [SEP]\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   input_ids: 101 2054 1996 3199 3642 5759 1010 19067 102 5759 3481 4276 2248 3199 1012 5759 1010 2142 2163 1025 9833 3199 3642 1040 2546 2860 1025 18055 3199 3642 1047 20952 2860 1025 5759 3481 4276 2248 3199 1006 1040 2546 2860 1007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   guid: train-1-1\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   tokens: [CLS] cost for brace ##s [SEP] the cost range for brace ##s can vary greatly for each type : metal brace ##s ( traditional brace ##s ) : $ 3 , 000 - 7 , 000 . ceramic brace ##s : $ 4 , 000 - 8 , 000 . ling ##ual brace ##s : $ 8 , 000 - 10 , 000 . in ##vis ##ali ##gn : $ 4 , 000 - 7 , 400 . prices depend on where you live – or ##th ##odon ##tist ##s in more rural areas are often less expensive than ones in larger cities - and may be at the or ##th ##odon ##tist ' s discretion . [SEP]\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   input_ids: 101 3465 2005 17180 2015 102 1996 3465 2846 2005 17180 2015 2064 8137 6551 2005 2169 2828 1024 3384 17180 2015 1006 3151 17180 2015 1007 1024 1002 1017 1010 2199 1011 1021 1010 2199 1012 14692 17180 2015 1024 1002 1018 1010 2199 1011 1022 1010 2199 1012 17002 8787 17180 2015 1024 1002 1022 1010 2199 1011 2184 1010 2199 1012 1999 11365 11475 16206 1024 1002 1018 1010 2199 1011 1021 1010 4278 1012 7597 12530 2006 2073 2017 2444 1516 2030 2705 28716 16774 2015 1999 2062 3541 2752 2024 2411 2625 6450 2084 3924 1999 3469 3655 1011 1998 2089 2022 2012 1996 2030 2705 28716 16774 1005 1055 19258 1012 102 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   guid: train-2-2\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   tokens: [CLS] what is meant by drop ship [SEP] drop shipping . drop shipping is a supply chain management method in which the retailer does not keep goods in stock but instead transfers customer orders and shipment details to either the manufacturer , another retailer , or a wholesale ##r , who then ships the goods directly to the customer . [SEP]\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   input_ids: 101 2054 2003 3214 2011 4530 2911 102 4530 7829 1012 4530 7829 2003 1037 4425 4677 2968 4118 1999 2029 1996 20196 2515 2025 2562 5350 1999 4518 2021 2612 15210 8013 4449 1998 22613 4751 2000 2593 1996 7751 1010 2178 20196 1010 2030 1037 17264 2099 1010 2040 2059 3719 1996 5350 3495 2000 1996 8013 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   guid: train-3-3\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   tokens: [CLS] what is the largest amp ##hi ##bian in the world [SEP] chinese giant sal ##aman ##der is the largest sal ##aman ##der and the largest amp ##hi ##bian in the world . it can reach up to 180 cm ##s ( that is taller than me if it ever decides to stand , ph ##ew ) : p . the species is critically endangered today and lives in china . [SEP]\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   input_ids: 101 2054 2003 1996 2922 23713 4048 15599 1999 1996 2088 102 2822 5016 16183 23093 4063 2003 1996 2922 16183 23093 4063 1998 1996 2922 23713 4048 15599 1999 1996 2088 1012 2009 2064 3362 2039 2000 8380 4642 2015 1006 2008 2003 12283 2084 2033 2065 2009 2412 7288 2000 3233 1010 6887 7974 1007 1024 1052 1012 1996 2427 2003 11321 10193 2651 1998 3268 1999 2859 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   guid: train-4-4\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   tokens: [CLS] what happens when a hedge ##hog bites you [SEP] how to react when your hedge ##hog bites you . hedge ##hog ##s make adorable pets but they have a little habit that makes owning them a little tricky - they bite when they are alarmed or unfamiliar with a situation or a person . if you happen to be the recipient of a hedge ##hog bite , it will be painful and the main bodily regions affected are the hand , arm , foot , ankle or leg . edge ##hog ##s make adorable pets but they have a little habit that makes owning them a little tricky - they bite when they are alarmed or unfamiliar with a situation or a person . [SEP]\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   input_ids: 101 2054 6433 2043 1037 17834 25852 15424 2017 102 2129 2000 10509 2043 2115 17834 25852 15424 2017 1012 17834 25852 2015 2191 23677 18551 2021 2027 2031 1037 2210 10427 2008 3084 19273 2068 1037 2210 24026 1011 2027 6805 2043 2027 2024 19260 2030 16261 2007 1037 3663 2030 1037 2711 1012 2065 2017 4148 2000 2022 1996 7799 1997 1037 17834 25852 6805 1010 2009 2097 2022 9145 1998 1996 2364 20445 4655 5360 2024 1996 2192 1010 2849 1010 3329 1010 10792 2030 4190 1012 3341 25852 2015 2191 23677 18551 2021 2027 2031 1037 2210 10427 2008 3084 19273 2068 1037 2210 24026 1011 2027 6805 2043 2027 2024 19260 2030 16261 2007 1037 3663 2030 1037 2711 1012 102 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "12/10/2018 05:06:51 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   guid: train-0-0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   tokens: [CLS] what the airport code dallas , tx [SEP] plan ##o , tx 750 ##7 ##4 city hours : monday - friday , 8 a . m . - 5 p . m . main telephone : 97 ##2 - 94 ##1 - 700 ##0 [SEP]\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   input_ids: 101 2054 1996 3199 3642 5759 1010 19067 102 2933 2080 1010 19067 9683 2581 2549 2103 2847 1024 6928 1011 5958 1010 1022 1037 1012 1049 1012 1011 1019 1052 1012 1049 1012 2364 7026 1024 5989 2475 1011 6365 2487 1011 6352 2692 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   guid: train-1-1\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   tokens: [CLS] cost for brace ##s [SEP] 1 time : typically with brace ##s , you will need to visit your or ##th ##odon ##tist every 4 weeks for an adjustment . comfort : not surprisingly , brace ##s will take getting used to . and sometimes they require an extra visit if wires or brackets are uncomfortable a couple days after an adjustment . [SEP]\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   input_ids: 101 3465 2005 17180 2015 102 1015 2051 1024 4050 2007 17180 2015 1010 2017 2097 2342 2000 3942 2115 2030 2705 28716 16774 2296 1018 3134 2005 2019 19037 1012 7216 1024 2025 10889 1010 17180 2015 2097 2202 2893 2109 2000 1012 1998 2823 2027 5478 2019 4469 3942 2065 14666 2030 19719 2024 8796 1037 3232 2420 2044 2019 19037 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   guid: train-2-2\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   tokens: [CLS] what is meant by drop ship [SEP] the term drop - ship basically means to deliver a product to a customer without having to physically see , pack or ship the item yourself . items sold are delivered directly to the customer by the manufacturer rather than by the retailer , with no cash and carry option . [SEP]\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   input_ids: 101 2054 2003 3214 2011 4530 2911 102 1996 2744 4530 1011 2911 10468 2965 2000 8116 1037 4031 2000 1037 8013 2302 2383 2000 8186 2156 1010 5308 2030 2911 1996 8875 4426 1012 5167 2853 2024 5359 3495 2000 1996 8013 2011 1996 7751 2738 2084 2011 1996 20196 1010 2007 2053 5356 1998 4287 5724 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   guid: train-3-3\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   tokens: [CLS] what is the largest amp ##hi ##bian in the world [SEP] the largest living amp ##hi ##bian is the chinese giant sal ##aman ##der ( and ##ria ##s david ##ian ##us ) . the maximum size of this river - dwell ##er is 64 kg ( 140 lb ) and 1 . 83 m ( 6 ft ) . before amino ##tes became the dominant te ##tra ##pods , several giant amp ##hi ##bian - like te ##tra ##pods existed . [SEP]\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   input_ids: 101 2054 2003 1996 2922 23713 4048 15599 1999 1996 2088 102 1996 2922 2542 23713 4048 15599 2003 1996 2822 5016 16183 23093 4063 1006 1998 4360 2015 2585 2937 2271 1007 1012 1996 4555 2946 1997 2023 2314 1011 23120 2121 2003 4185 4705 1006 8574 6053 1007 1998 1015 1012 6640 1049 1006 1020 3027 1007 1012 2077 13096 4570 2150 1996 7444 8915 6494 22925 1010 2195 5016 23713 4048 15599 1011 2066 8915 6494 22925 5839 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   *** Example ***\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   guid: train-4-4\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   tokens: [CLS] what happens when a hedge ##hog bites you [SEP] when you find your hedge ##hog biting , there are several ways you can gently rep ##rim ##and him to train him not to bite in the future . 1 firmly yell “ no ” when the bite happens – hedge ##hog ##s do not like loud noises . 2 push your fingers against the hedge ##hog ’ s mouth as he bites rather than pulling your fingers away . hen you find your hedge ##hog biting , there are several ways you can gently rep ##rim ##and him to train him not to bite in the future . 1 firmly yell “ no ” when the bite happens – hedge ##hog ##s do not like loud [SEP]\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   input_ids: 101 2054 6433 2043 1037 17834 25852 15424 2017 102 2043 2017 2424 2115 17834 25852 12344 1010 2045 2024 2195 3971 2017 2064 5251 16360 20026 5685 2032 2000 3345 2032 2025 2000 6805 1999 1996 2925 1012 1015 7933 14315 1523 2053 1524 2043 1996 6805 6433 1516 17834 25852 2015 2079 2025 2066 5189 14950 1012 1016 5245 2115 3093 2114 1996 17834 25852 1521 1055 2677 2004 2002 15424 2738 2084 4815 2115 3093 2185 1012 21863 2017 2424 2115 17834 25852 12344 1010 2045 2024 2195 3971 2017 2064 5251 16360 20026 5685 2032 2000 3345 2032 2025 2000 6805 1999 1996 2925 1012 1015 7933 14315 1523 2053 1524 2043 1996 6805 6433 1516 17834 25852 2015 2079 2025 2066 5189 102\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/10/2018 05:06:58 - INFO - run_classifier -   label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QClNY2g-nki-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qav4k5BHl5fb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_input_ids1 = torch.tensor([f.input_ids for f in pos_training_features], dtype=torch.long)\n",
        "all_input_mask1 = torch.tensor([f.input_mask for f in pos_training_features], dtype=torch.long)\n",
        "all_segment_ids1 = torch.tensor([f.segment_ids for f in pos_training_features], dtype=torch.long)\n",
        "#all_label_ids1 = torch.tensor([f.label_id for f in pos_training_features], dtype=torch.long)\n",
        "\n",
        "all_input_ids2 = torch.tensor([f.input_ids for f in neg_training_features], dtype=torch.long)\n",
        "all_input_mask2 = torch.tensor([f.input_mask for f in neg_training_features], dtype=torch.long)\n",
        "all_segment_ids2 = torch.tensor([f.segment_ids for f in neg_training_features], dtype=torch.long)\n",
        "#all_label_ids2 = torch.tensor([f.label_id for f in neg_training_features], dtype=torch.long)\n",
        "\n",
        "train_data = TensorDataset(all_input_ids1, all_input_mask1, all_segment_ids1, all_input_ids2, all_input_mask2, all_segment_ids2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MumtzaMAl5x0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_dev_input_ids1 = torch.tensor([f.input_ids for f in pos_dev_features], dtype=torch.long)\n",
        "all_dev_input_mask1 = torch.tensor([f.input_mask for f in pos_dev_features], dtype=torch.long)\n",
        "all_dev_segment_ids1 = torch.tensor([f.segment_ids for f in pos_dev_features], dtype=torch.long)\n",
        "#all_dev_label_ids1 = torch.tensor([f.label_id for f in pos_dev_features], dtype=torch.long)\n",
        "\n",
        "all_dev_input_ids2 = torch.tensor([f.input_ids for f in neg_dev_features], dtype=torch.long)\n",
        "all_dev_input_mask2 = torch.tensor([f.input_mask for f in neg_dev_features], dtype=torch.long)\n",
        "all_dev_segment_ids2 = torch.tensor([f.segment_ids for f in neg_dev_features], dtype=torch.long)\n",
        "#all_dev_label_ids2 = torch.tensor([f.label_id for f in neg_dev_features], dtype=torch.long)\n",
        "\n",
        "eval_data = TensorDataset(all_dev_input_ids1, all_dev_input_mask1, all_dev_segment_ids1, all_dev_input_ids2, all_dev_input_mask2, all_dev_segment_ids2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cou5NZrqtPkd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import logging\n",
        "import argparse\n",
        "import random\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "from pytorch_pretrained_bert.tokenization import printable_text, BertTokenizer\n",
        "from pytorch_pretrained_bert.modeling import PreTrainedBertModel, BertModel\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "\n",
        "import os\n",
        "import copy\n",
        "import json\n",
        "import math\n",
        "import logging\n",
        "import tarfile\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "from torch import optim\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, L1Loss\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "loss_fct = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3EpHRMYftLly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BertForAnswerSelection(PreTrainedBertModel):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "\n",
        "    Params:\n",
        "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
        "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
        "\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
        "            with indices selected in [0, ..., num_labels].\n",
        "\n",
        "    Outputs:\n",
        "        if `labels` is not `None`:\n",
        "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
        "        if `labels` is `None`:\n",
        "            Outputs the classification logits.\n",
        "\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 2, 0]])\n",
        "    # Logits 1 is positive and 2 is negative\n",
        "    config = BertConfig(vocab_size=32000, hidden_size=512,\n",
        "        num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)\n",
        "\n",
        "    num_labels = 2\n",
        "\n",
        "    model = BertForAnswerSelection(config, num_labels)\n",
        "    logits = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels=2):\n",
        "        super(BertForAnswerSelection, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier =  nn.Linear(config.hidden_size, 1)\n",
        "        self.apply(self.init_bert_weights)\n",
        "        self.margin = 2\n",
        "\n",
        "    def forward(self, input_ids1, token_type_ids1, attention_mask1, input_ids2, token_type_ids2,\n",
        "                attention_mask2):\n",
        "        _, pooled_output1 = self.bert(input_ids1, token_type_ids1, attention_mask1, output_all_encoded_layers=False)\n",
        "        _, pooled_output2 = self.bert(input_ids2, token_type_ids2, attention_mask2, output_all_encoded_layers=False)\n",
        "        pooled_output1 = self.dropout(pooled_output1)\n",
        "        pooled_output2 = self.dropout(pooled_output2)\n",
        "        logits1 = self.classifier(pooled_output1)\n",
        "        logits2 = self.classifier(pooled_output2)\n",
        "        criterion = torch.log(Variable(torch.ones(logits1.size(0)).cuda()) + torch.exp(logits2 - logits1))\n",
        "        #criterion = torch.max(Variable(torch.zeros(logits1.size(0)).cuda()), Variable(self.margin*torch.ones(logits1.size(0)).cuda()) + logits2 - logits1)\n",
        "        err1 = torch.mean(criterion)\n",
        "        err2 = torch.mean(loss_fct(torch.stack((logits1,logits2),1), Variable(torch.zeros(logits1.size(0),1).cuda().long())))\n",
        "        err = err1 + 0.005*err2\n",
        "        return err, logits1, logits2\n",
        "\n",
        "    def pos_forward(self, input_ids1, token_type_ids1=None, attention_mask1=None):\n",
        "        _, pooled_output1 = self.bert(input_ids1, token_type_ids1, attention_mask1, output_all_encoded_layers=False)\n",
        "        pooled_output1 = self.dropout(pooled_output1)\n",
        "        logits1 = self.classifier(pooled_output1)\n",
        "        return logits1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M2uxvAtOrV8F",
        "colab_type": "code",
        "outputId": "036f13eb-da09-4ded-efc7-e9c44cd7ef12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "model = BertForAnswerSelection.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/10/2018 05:07:05 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpp92f_q94\n",
            "100%|██████████| 407873900/407873900 [00:12<00:00, 33400348.19B/s]\n",
            "12/10/2018 05:07:18 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpp92f_q94 to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "12/10/2018 05:07:20 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "12/10/2018 05:07:20 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpp92f_q94\n",
            "12/10/2018 05:07:20 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "12/10/2018 05:07:20 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp42kad081\n",
            "12/10/2018 05:07:25 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/10/2018 05:07:29 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForAnswerSelection not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "12/10/2018 05:07:29 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForAnswerSelection: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_w4i4cN41Nx2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bert_model = 'bert-base-uncased'\n",
        "train_batch_size = 8\n",
        "learning_rate = 2e-5\n",
        "warmup_proportion = 0.1\n",
        "eval_batch_size = 8\n",
        "num_train_epochs = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KgjCNy2F3QJp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(logits1, logits2):\n",
        "    return np.sum(logits1 > logits2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j4eGHmk24Hrc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
        "eval_sampler = SequentialSampler(eval_data)\n",
        "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xzD_OpFJl5u_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main(train_data = train_data, eval_data = eval_data):\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n_gpu = 1\n",
        "    \n",
        "\n",
        "    random.seed(200)\n",
        "    np.random.seed(200)\n",
        "    torch.manual_seed(200)\n",
        "    torch.cuda.manual_seed_all(200)\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "\n",
        "    # Prepare model\n",
        "    model = BertForAnswerSelection.from_pretrained(bert_model)\n",
        "    model.to(device)\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
        "        ]\n",
        "    total_steps = int(len(train_dataloader)/train_batch_size/num_train_epochs)\n",
        "    #optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "    #optimizer = optim.Adagrad(model.parameters(), lr = learning_rate,weight_decay = 1e-2)\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters, lr=learning_rate, warmup=warmup_proportion)#, t_total=total_steps)\n",
        "\n",
        "    global_step = 0\n",
        "    if True:\n",
        "        for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
        "            # Training model\n",
        "            model.train()\n",
        "            tr_loss = 0\n",
        "            nb_tr_examples, nb_tr_steps = 0, 0\n",
        "            for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\", position = 0)):\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "                input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2 = batch\n",
        "                loss, _, _ = model(input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2)\n",
        "                loss.backward()\n",
        "                tr_loss += loss.item()\n",
        "                nb_tr_examples += input_ids1.size(0)\n",
        "                nb_tr_steps += 1\n",
        "                optimizer.step()\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "            # evaluating on validation set\n",
        "            model.eval()\n",
        "            eval_loss, eval_accuracy = 0, 0\n",
        "            nb_eval_steps, nb_eval_examples = 0, 0\n",
        "            for input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2 in eval_dataloader:\n",
        "                input_ids1 = input_ids1.to(device)\n",
        "                input_mask1 = input_mask1.to(device)\n",
        "                segment_ids1 = segment_ids1.to(device)\n",
        "\n",
        "                input_ids2 = input_ids2.to(device)\n",
        "                input_mask2 = input_mask2.to(device)\n",
        "                segment_ids2 = segment_ids2.to(device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    tmp_eval_loss, logits1, logits2 = model(input_ids1, input_mask1, segment_ids1, input_ids2, input_mask2, segment_ids2)\n",
        "\n",
        "                logits1 = logits1.detach().cpu().numpy()\n",
        "                logits2 = logits2.detach().cpu().numpy()\n",
        "                tmp_eval_accuracy = accuracy(logits1, logits2)\n",
        "\n",
        "                eval_loss += tmp_eval_loss.item()\n",
        "                eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "                nb_eval_examples += input_ids1.size(0)\n",
        "                nb_eval_steps += 1\n",
        "\n",
        "            eval_loss = eval_loss / nb_eval_steps\n",
        "            eval_accuracy = eval_accuracy / nb_eval_examples\n",
        "\n",
        "            result = {'eval_loss': eval_loss,\n",
        "                      'eval_accuracy': eval_accuracy,\n",
        "                      'global_step': global_step,\n",
        "                      'loss': tr_loss/nb_tr_steps}\n",
        "\n",
        "            output_eval_file = \"eval_results.txt\"\n",
        "            print(result)\n",
        "            torch.save(model, 'checkpoint' + str(eval_accuracy))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z1V-VrSKl5sA",
        "colab_type": "code",
        "outputId": "12ad7c1b-0c25-4772-a32c-b168556ef9b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/10/2018 05:07:30 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/10/2018 05:07:30 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "12/10/2018 05:07:30 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpvjh_qkv2\n",
            "12/10/2018 05:07:36 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/10/2018 05:07:39 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForAnswerSelection not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "12/10/2018 05:07:39 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForAnswerSelection: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "Iteration: 100%|██████████| 3750/3750 [1:03:48<00:00,  1.02s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5539567990750074, 'eval_accuracy': 0.71225, 'global_step': 3750, 'loss': 0.5808644431153933}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BertForAnswerSelection. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "Iteration: 100%|██████████| 3750/3750 [1:04:11<00:00,  1.03s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5650104464888572, 'eval_accuracy': 0.70375, 'global_step': 7500, 'loss': 0.44581959296862284}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 3750/3750 [1:04:03<00:00,  1.03s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8190022428706288, 'eval_accuracy': 0.686, 'global_step': 11250, 'loss': 0.23382125617048394}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 3750/3750 [1:03:57<00:00,  1.02s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.388338225231506, 'eval_accuracy': 0.684, 'global_step': 15000, 'loss': 0.09125294257136798}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch: 100%|██████████| 4/4 [4:25:18<00:00, 3976.97s/it]  \n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}